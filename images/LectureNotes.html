<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Brandon McKinzie" />
  <title>Fall 2016 Course Notes</title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<div id="header">
<h1 class="title"><p><strong>Fall 2016 Course Notes</strong></p></h1>
<h2 class="author">Brandon McKinzie</h2>
</div>
<p>[Machine Learning]</p>
<ul>
<li><p>Want to prove that <span class="math inline"><em>w</em></span> is normal to decision boundary.</p>
<ul>
<li><p>Starting axiom: Any vector <span class="math inline"><em>x</em></span> along the decision boundary satisfies, by definition, <br /><span class="math display"><em>w</em> ⋅ <em>x</em> + <em>β</em> = 0</span><br /></p></li>
<li><p>Let <span class="math inline"><em>x</em></span> and <span class="math inline"><em>x</em>′</span> be two such vectors that lie on the decision boundary. Then the vector <span class="math inline"><em>x</em>′−<em>x</em></span> points from <span class="math inline"><em>x</em></span> to <span class="math inline"><em>x</em>′</span> and is parallel to the decision boundary. If <span class="math inline"><em>w</em></span> really is normal to the decision boundary line, then <br /><span class="math display">$$\begin{aligned}
        \begin{split}
        w \cdot (x' - x) &amp;= 0 \\
        &amp;= w \cdot x' - w \cdot x \\
        &amp;= (w \cdot x' + \beta) - (w \cdot x + \beta) \\
        &amp;= 0 + 0
        \end{split}
        \end{aligned}$$</span><br /></p></li>
<li><p>Euclidean distance of <span class="math inline"><em>x</em></span> to decision boundary: <br /><span class="math display">$$\tau = - \frac{(w \cdot x + \beta)}{||w||} = - \frac{f(x)}{||w||}$$</span><br /></p></li>
<li><p>The is can be found as the minimum over all training data <span class="math inline"><em>τ</em></span>: <br /><span class="math display">$$M = \min_{i \in 1 \cdots n} \frac{|f(x_i)|}{||w||}$$</span><br /></p></li>
</ul></li>
</ul>
<ul>
<li><p>maximize goals/minimize cost, subject to constraints. However, can model a lot while ignoring constraints.</p></li>
<li><p>Main optimization algorithm is .</p></li>
<li><p>The <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> is just another cost function. Want to minimize<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <br /><span class="math display">$$C \displaystyle\sum_{i=1}^{n} \big(1 - y_i ( w \cdot x_i + \beta) \big)_+ + ||w||^2$$</span><br /> with respect to the <span class="math inline">(<em>w</em>, <em>β</em>)</span>; Note that <span class="math inline"><em>C</em></span> is a .</p></li>
</ul>
<ul>
<li><p>Review: minimize cost function <span class="math inline"><em>f</em>(<em>w</em>)</span> over w. Take gradient; set to zero to solve for <span class="math inline"><em>w</em></span>.</p></li>
<li><p>If can’t solve analytically, then Gradient Descent: <br /><span class="math display"><em>w</em><sub><em>k</em> + 1</sub> = <em>w</em><sub><em>k</em></sub> − <em>α</em><sub><em>k</em></sub>∇<em>f</em>(<em>w</em><sub><em>k</em></sub>)</span><br /></p></li>
<li><p>For convex <span class="math inline"><em>f</em></span>, can always find solution. Guaranteed global minimum.</p></li>
<li><p>Cost functions of form: <span class="math inline">minimize ∑loss(<em>w</em><sub><em>i</em></sub>(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)) + penalty (<em>w</em>)</span>.</p></li>
<li><p>SVM example: <br /><span class="math display">min <em>C</em>/<em>n</em>∑(1 − <em>y</em><sub><em>i</em></sub><em>w</em><sup><em>T</em></sup><em>x</em><sub><em>i</em></sub>)<sub>+</sub> + ||<em>w</em>||<sup>2</sup></span><br />. Add squared norm because better margins and better classifications. Also, because algorithms converge faster. C is the . “Do I fit the data, or make w simple?”. Doesn’t change optimal set, just changes the “Cost” (wat).</p></li>
<li><p>Want algorithm constant in number of data points <span class="math inline"><em>n</em></span><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>.</p></li>
<li><p>Unbiased estimate of the gradient:</p>
<ul>
<li><p>Want expected vlaue of <span class="math inline"><em>g</em></span> to be gradient of cost function.</p></li>
<li><p>Sample <span class="math inline"><em>i</em></span> uniformly at random from <span class="math inline">{1, …, <em>n</em>}</span>.</p></li>
<li><p>Then set <span class="math inline"><em>g</em></span> to gradient of loss at ith data point.</p></li>
</ul></li>
<li><p>SGD:</p>
<ul>
<li><p>initialize <span class="math inline"><em>w</em><sub>0</sub></span>, <span class="math inline"><em>k</em></span> = 0.</p></li>
<li><p>(Repeat) sample <span class="math inline"><em>i</em></span> at uniform. Do weight update on the loss for <span class="math inline"><em>i</em></span> term. Until converged.</p></li>
<li><p>Follow the expected value of the gradient (rather than the true gradient) until converge. Following a noisy version. As long as variance is bounded, direction will be more or less correct. For large number of data points <span class="math inline"><em>n</em></span>, will be pretty good.</p></li>
</ul></li>
<li><p>Numerical example:</p>
<ul>
<li><p><span class="math inline"><em>f</em>(<em>w</em>)=1/2<em>n</em>∑(<em>w</em> − <em>y</em><sub><em>i</em></sub>)<sup>2</sup></span>. Assumes x always 1.</p></li>
<li><p>Solve <span class="math inline">∇<em>f</em>(<em>w</em>)=0 = 1/<em>n</em>∑(<em>w</em> − <em>y</em><sub><em>i</em></sub>)=0</span>.</p></li>
<li><p>Optimal <span class="math inline"><em>w</em> = 1/<em>n</em>∑<em>y</em><sub><em>i</em></sub></span>. The empirical mean.</p></li>
<li><p>Init <span class="math inline"><em>w</em><sub>1</sub> = 0</span>. Set <span class="math inline"><em>α</em><sub><em>k</em></sub> = 1/<em>k</em></span>. Where <span class="math inline"><em>k</em></span> is <span class="math inline"><em>k</em><em>t</em><em>h</em></span> update reference.</p></li>
<li><p><span class="math inline"><em>w</em><sub>2</sub> = <em>w</em><sub>1</sub> − <em>α</em><sub><em>k</em></sub>∇loss () = <em>y</em><sub>1</sub></span>. Where loss the grad of f.</p></li>
<li><p><span class="math inline">$w_3 = w_2 - \alpha_2 (w_2 - y_2) = y_1 -\frac{1}{2}(y_1 - y_2) = \frac{y_1 + y_2}{2}$</span>.</p></li>
<li><p><span class="math inline"><em>w</em><sub>4</sub> = ⋯=</span>. idk</p></li>
<li><p>Lesson: order we passed through data didn’t matter. One pass over all data points leads to optimal <span class="math inline"><em>w</em></span>. Why advocate randomness then? He uses sum of trig function example to illustrate how SGD can struggle if done in order, but converge much quicker when randomly sampled.</p></li>
</ul></li>
<li><p>Illustrates “”. Coined by Bertsekas. Different convex functions along w. Rapid decrease in error early on iterations means we are far outside this region. Constant <span class="math inline"><em>α</em></span> means you’ll jiggle around later iterations. That is why you do diminishing <span class="math inline"><em>α</em></span>; helps in region of confusion.</p></li>
<li><p>Most important rules of SGD: (buzzwords)</p>
<ul>
<li><p>shuffle! Can speed up by as much as 20x.</p></li>
<li><p>diminishing stepsize (<span class="math inline"><em>α</em></span> learning rate decay). After <span class="math inline"><em>n</em></span> steps, set <span class="math inline"><em>α</em> = <em>β</em> ⋅ <em>α</em></span>.</p></li>
<li><p>. <span class="math inline"><em>w</em><sub><em>k</em> + 1</sub> = <em>w</em><sub><em>k</em></sub> − <em>α</em>∇<em>l</em><sub><em>i</em></sub>(<em>w</em><sub><em>k</em></sub>)+<em>β</em><sub><em>k</em></sub>(<em>w</em><sub><em>k</em></sub> − <em>w</em><sub><em>k</em> − 1</sub>)</span>. Momentum is in final term. Typical value is 0.9.</p></li>
</ul></li>
<li><p>Notation: <span class="math inline"><em>e</em>(<em>z</em>)=(<em>z</em> &lt; 1)</span>. Evaluates to 1 or 0.</p></li>
</ul>
<ul>
<li><p>Where do these optimization problems come from?</p>
<ul>
<li><p>General framework: minimizing an average loss + <span class="math inline"><em>λ</em></span> penalty.</p></li>
<li><p>Loss: measures data fidelity.</p></li>
<li><p>Penalty: Controls model complexity.</p></li>
<li><p>Features/representation: How to write <span class="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span>.</p></li>
<li><p>Algorithms: <span class="math inline">∇</span> cost(w) = 0.</p></li>
<li><p>: Integral of loss over probability(x, y).</p></li>
<li><p>Empirical risk: Sample average. Converges to true Risk with more points; variance decreases.</p></li>
</ul></li>
<li><p>Begins discussion of splitting up data.</p>
<ul>
<li><p>Let some large portion be the and the small remaining data points be the . <br /><span class="math display">$$\begin{aligned}
        R_T &amp;= \frac{1}{n_T} \sum_{train} loss(w, (x_i, y_i)) \\
        R_V  &amp;= \frac{1}{n_V} \sum_{val} loss(w, (x_i, y_i))
        \end{aligned}$$</span><br /></p></li>
<li><p>By law of large numbers, can say the <span class="math inline"><em>R</em><sub><em>V</em></sub></span> will go like <span class="math inline">$\frac{1}{n_V}$</span>. Looking lots of times at validation set becomes a problem with <span class="math inline"><em>n</em><sub><em>V</em></sub> ≈ 10<sup>4</sup></span>.</p></li>
</ul></li>
<li><p>Classification example:</p>
<ul>
<li><p>loss: <span class="math inline">(1 − <em>y</em><em>w</em><sup><em>T</em></sup><em>x</em>)<sub>+</sub></span>. Means you’re solving a SVM.</p></li>
<li><p>Least-Squares: <span class="math inline">(1 − <em>y</em><em>w</em><sup><em>T</em></sup><em>x</em>)<sup>2</sup></span>. Bayes classifiers.</p></li>
<li><p>In practice, hinge and LS perform basically the same.</p></li>
<li><p>Logistic loss useful for MLE.</p></li>
</ul></li>
<li><p>Most important theorem in machine learning: Relates risk with empirical risk: <br /><span class="math display">$$\begin{aligned}
    R[w] &amp;=  \frac{R[w] - R_T[w]}{\text{generalization err}} + \frac{R_T[w]}{\text{train err}} \\
    &amp;\approx R_V[w] - R_T[w] + R_T[w]
    \end{aligned}$$</span><br /></p></li>
<li><p>One vs. all classifation MNIST example: Have a classifier for each digit that treats as (their digit) vs. (everything else). Choose classifier with highest margin when classifying digit.</p></li>
<li><p>:</p>
<ul>
<li><p>Have <span class="math inline"><em>p</em>(<em>x</em>, <em>y</em>; <em>w</em>)</span>. Pick the <span class="math inline"><em>w</em></span> that makes data set have highest probability.</p></li>
<li><p>Assumes data points come independently.</p></li>
<li><p>Can get same result by minimizing the negative log avg.</p></li>
</ul></li>
<li><p>More than most things (like loss functions) are choosing the . <strong>LIFT THE D</strong>. Conic sections because why not.</p></li>
<li><p>N-grams. .</p>
<ul>
<li><p><span class="math inline"><em>x</em><sub><em>i</em></sub>=</span> number occurrences of term <span class="math inline"><em>i</em></span>. Count number of times each word appears in some document.</p></li>
<li><p>The two-gram is the <em>lifted</em> version. <span class="math inline"><em>x</em><sub><em>i</em><em>j</em></sub>=</span> number occurrences of terms <span class="math inline"><em>i</em></span>, <span class="math inline"><em>j</em></span> in same context. Count number of terms two words, e.g. appear in the same sentence, or next to each other. Like a quadratic model.</p></li>
</ul></li>
<li><p>Histograms</p>
<ul>
<li><p><span class="math inline">$\hat{x}_{ij} = 1$</span> if <span class="math inline"><em>x</em><sub><em>i</em></sub> ∈ <em>b</em><em>i</em><em>n</em>(<em>j</em>)</span> else 0.</p></li>
<li><p>e.g. histograms of image gradients in the notes.</p></li>
</ul></li>
<li><p>“If you have too many features, then you have to have a penalty.” - D.J. Khaled. i.e. if <span class="math inline"><em>d</em> &gt; <em>n</em></span>, must use pen<span class="math inline">(<em>w</em>)</span>. Never need to have <span class="math inline"><em>d</em> &gt; <em>n</em></span>, becaues of .</p></li>
</ul>
<ul>
<li><ul>
<li><p>Given feature distributions conditioned on class values (e.g. <span class="math inline">±</span>1).</p></li>
<li><p>Goes over Bayes rule like a pleb.</p></li>
<li><p>Classification depends on loss function.</p></li>
</ul></li>
<li><p>Loss function can be . e.g. would rather misclassify as cancer | normal rather than misclassify normal | cancer. So to minimize expected loss, may prefer to be wrong more on some misclassification than another.</p></li>
<li><p>Can minimize on probability of error. <br /><span class="math display">$$\begin{aligned}
    \min \bigg[  Pr(\text{error}) = \int Pr(\text{error} | x) Pr(x) dx \bigg]
    \end{aligned}$$</span><br /> The area (under) of overlap between conditionals (think hw problem w/Gaussians) is Pr(error). If <span class="math inline"><em>K</em></span> classes, similarly, classify as the maximum conditional, and error is 1 - Pr()<span class="math inline"><em></em><sub><em>m</em><em>a</em><em>x</em></sub></span>.</p></li>
<li><p>: <br /><span class="math display">$$\begin{aligned}
        \min \sum_k L_{kj} P(c_k |x)
    \end{aligned}$$</span><br /> where <span class="math inline"><em>L</em><sub><em>k</em><em>j</em></sub></span> is loss where true class is <span class="math inline"><em>k</em></span> but classify as <span class="math inline"><em>j</em></span>. “by integrating over x, we can compute the expected loss.”</p></li>
<li><p>Loss function in regression pretty clear (e.g. least squared loss). Classification is less so. Can use the <strong>“Doubt option”</strong>. Classifier humility (lolololol)<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>. In some range of inputs near the decision boundary, just say “idk”.</p></li>
<li><p>Good classifiers have expected loss closer to Bayes risk, given certain choice of features.</p></li>
<li><p><strong>NOTE:</strong> Jitendra praises to the lord Gauss. Note 2: Jitendra makes another god joke.</p></li>
<li><p>Three ways of building classifiers:</p>
<ul>
<li><p>Model the class conditional distribution <span class="math inline">$P(\widetilde{x} | c_k)$</span>. Model priors <span class="math inline"><em>P</em>(<em>c</em><sub><em>k</em></sub>)</span>. Use bayes duh. Want to understand distributions under which data were <em>generated</em>. Physicists can get away with this shit. They have “models” <a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p></li>
<li><p>“Fuck it” method. Model <span class="math inline">$P(c_k | \widetilde{x})$</span> directly.</p></li>
<li><p>Find decision boundaries.</p></li>
</ul></li>
<li><p>Posterior for Gaussian class-conditional densities :</p>
<ul>
<li><p><span class="math inline"><em>P</em>(<em>x</em>|<em>c</em><sub>1</sub>)</span> and <span class="math inline"><em>P</em>(<em>x</em>|<em>c</em><sub>2</sub>)∼𝒩(<em>μ</em><sub><em>i</em></sub>, <em>σ</em><sup>2</sup>)</span>.</p></li>
<li><p>Univariate gaussian example <em>like a bitch</em>.</p></li>
<li><p>Posterior probabilities <span class="math inline"><em>P</em>(<em>c</em><sub><em>i</em></sub>|<em>x</em>)</span> turn out to be logistic <span class="math inline"><em>σ</em></span> functions.</p></li>
</ul></li>
</ul>
<ul>
<li><p>Recht’s Decision notation: <span class="math inline"><em>P</em>(<em>x</em>|<em>H</em><sub>0</sub>)</span>. <strong>RECHT CAN’T GET THE MIC ON HERE WE GO</strong></p></li>
<li><p>Want to discuss case of <span class="math inline"><em>x</em></span> being non-scalar.</p>
<ul>
<li><p>Def: vector <span class="math inline"><em>x</em></span> with probability density <span class="math inline"><em>p</em>(<em>x</em>):ℝ<sup><em>n</em></sup> → ℝ</span>.</p></li>
<li><p>Example density is the .</p></li>
<li><p>Usually want to know <span class="math inline"><em>P</em><em>r</em>(<em>x</em> ∈ <em>A</em>)=∫<sub><em>A</em></sub><em>p</em>(<em>x</em>)<em>d</em><em>x</em><sub>1</sub>…<em>d</em><em>x</em><sub><em>n</em></sub></span>, the prob that x lives in set <span class="math inline"><em>A</em></span>.</p></li>
<li><p>Properties of random vectors: .</p></li>
</ul></li>
<li><p>Let <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>m</em></sup></span>. Expected value of f: <br /><span class="math display">𝔼[<em>f</em>(<em>x</em>)] = ∫∫<em>f</em>(<em>x</em>)<em>p</em>(<em>x</em>)<em>d</em><em>x</em><sub>1</sub>…<em>d</em><em>x</em><sub><em>n</em></sub></span><br /></p></li>
<li><p><strong>Covariance Matrix</strong>. A matrix. <span class="math inline"><em>Λ</em> = <em>Λ</em><sup><em>T</em></sup></span>. <br /><span class="math display"><em>Λ</em> = 𝔼[(<em>x</em> − <em>μ</em>)(<em>x</em> − <em>μ</em>)<sup><em>T</em></sup>]=𝔼[<em>x</em><em>x</em><sup><em>T</em></sup>]−<em>μ</em><sub><em>x</em></sub><em>μ</em><sub><em>x</em></sub><sup><em>T</em></sup></span><br /> <br /><span class="math display"><em>v</em><em>a</em><em>r</em>(<em>x</em><sub>1</sub>)=𝔼[(<em>x</em><sub>1</sub> − <em>μ</em><sub><em>x</em><sub>1</sub></sub>)2]=<em>Λ</em><sub>11</sub></span><br /></p></li>
<li><p>Let <span class="math inline"><em>v</em> ∈ ℝ<sup><em>n</em></sup></span>. Then <span class="math inline"><em>v</em><em>a</em><em>r</em>(<em>v</em><sup><em>T</em></sup><em>x</em>)=<em>v</em><sup><em>T</em></sup><em>Λ</em><em>v</em> ≥ 0 ⇒ <em>Λ</em><sub><em>x</em></sub></span> is</p>
<ul>
<li><p>Suppose <span class="math inline"><em>A</em></span> is some square matrix, <span class="math inline"><em>λ</em></span> is an eigval of <span class="math inline"><em>A</em></span> with corresponding eigvec <span class="math inline"><em>x</em></span> if <span class="math inline"><em>A</em><em>x</em> = <em>λ</em><em>x</em></span>. Larger eigenvalues tell about how much variance in a given direction.</p></li>
<li><p>Eigenvectors are, like, eigen<em>directions</em>, man.</p></li>
<li><p>: If <span class="math inline"><em>A</em> = <em>A</em><sup><em>T</em></sup></span>, then <span class="math inline">∃<em>S</em> = <em>v</em><sub>1</sub>, …, <em>v</em><sub><em>n</em></sub> ∈ ℝ<sup><em>n</em></sup></span> such that <span class="math inline"><em>v</em><sub><em>i</em></sub><sup><em>T</em></sup><em>v</em><sub><em>j</em></sub> = 0</span> , <span class="math inline"><em>i</em> ≠ <em>j</em></span>, and <span class="math inline"><em>A</em><em>v</em><sub><em>i</em></sub> = <em>λ</em><sub><em>i</em></sub><em>v</em><sub><em>i</em></sub></span> and <span class="math inline"><em>λ</em><sub><em>i</em></sub> ∈ ℝ</span>.</p></li>
<li><p>Because matrix of eigenvectors has vectors linearly independent, invertible.</p></li>
<li><p><span class="math inline"><em>A</em></span> p.d <span class="math inline">⇒<em>B</em><sup><em>T</em></sup><em>A</em><em>B</em></span> is p.s.d. <span class="math inline">∀<em>B</em></span>.</p></li>
<li><p>If <span class="math inline"><em>A</em></span> is p.s.d., then <span class="math inline"><em>f</em>(<em>x</em>)=<em>x</em><sup><em>T</em></sup><em>A</em><em>x</em></span> is <em>convex.</em></p></li>
</ul></li>
<li><p><strong>Multivariate Gaussian</strong> <br /><span class="math display">$$p(x) = \frac{1}{det(2 \pi \Lambda_x)^{1/2}}\exp\big[ {-\frac{1}{2}(x - \mu_x)^T\Lambda_x^{-1} (x - \mu_x)} \big]$$</span><br /> If <span class="math inline"><em>μ</em><sub><em>x</em></sub> ∈ ℝ<sup><em>n</em></sup>,  <em>Λ</em><sub><em>x</em></sub></span> p.d. <span class="math inline">⇒</span> p(x) is a density.</p></li>
<li><p>What happens if covariance is diagonal? Then the the vars are indepenedent.</p>
<ul>
<li><p><span class="math inline"><em>Λ</em><sub><em>x</em></sub></span> diagonal,</p></li>
<li><p><span class="math inline"><em>x</em></span> Gaussian</p></li>
<li><p><span class="math inline">⇒<em>x</em><sub>1</sub>, …, <em>x</em><sub><em>n</em></sub></span> independent.</p></li>
</ul></li>
</ul>
<ul>
<li><p>: hypothesis testing on the continuum.</p></li>
<li><p>Pick the model so that <span class="math inline"><em>p</em>(data|model)</span>, the likelihood function, is maximized.</p></li>
<li><p>Treat model as random var. Then maximize p(model|data), ‘’’. Assume uniform priors over all models. Flaw is assuming model is a random variable.</p></li>
<li><p>ML examples:</p>
<ul>
<li><p><em>Biased Coin.</em> Flipping a coid. <br /><span class="math display">$$P(X = x) = {n \choose x} p^x (1 - p)^{n-x} = P(x | p)$$</span><br /> See <span class="math inline"><em>n</em> = 10, 8</span> heads. Choose estimate <span class="math inline">$\hat{p} = \frac{4}{5}$</span>. Binomial is not concave, when you take the log it becomes concave.</p></li>
</ul></li>
<li><p>Gaussians. <br /><span class="math display"><em>x</em>1, …, <em>x</em><sub><em>n</em></sub> ∼ 𝒩(<em>μ</em>, <em>σ</em><sup>2</sup>)</span><br /> independent samples. <br /><span class="math display"><em>P</em>({<em>x</em><sub><em>i</em></sub>}|<em>μ</em>, <em>σ</em><sup>2</sup>)=∏<em>P</em>(<em>x</em><sub><em>i</em></sub>|<em>μ</em>, <em>σ</em><sup>2</sup>)</span><br /> where each term in prod is standard Gaussian PDF. Next, take the log. <br /><span class="math display">$$\log P(\{x_i\} | \mu, \sigma^2) = \sum - \frac{ x_i - \mu}{2 \sigma^2} - \log \sigma - 1/2 \log 2\pi$$</span><br /> Ideally, best estimates for mean and variance: <br /><span class="math display">$$\begin{aligned}
    \hat{\mu} &amp;= \frac{1}{n} \sum_i x_i \\
    \hat{\sigma}^2 &amp;= \frac{1}{n} \sum_i \big(x_i -  \hat{\mu} \big)^2 
    \end{aligned}$$</span><br /></p></li>
<li><p>Multivariate Gaussian: <br /><span class="math display">$$P(x | \mu, \Lambda) = \frac{1}{\det 2 \pi \Lambda^{1/2}} \exp(-\frac{1}{2} (x - \mu)^T \Lambda^{-1} (x - \mu)$$</span><br /></p></li>
</ul>
<ul>
<li><p>How do we build classifiers?</p>
<ul>
<li><p>ERM. Minimize <br /><span class="math display">$$\begin{aligned}
        \frac{1}{n} \sum \text{(loss)} + \lambda \text{pen}
        \end{aligned}$$</span><br /> <em>Equivalent to discriminative</em></p></li>
<li><p>Generative models. Fit model to data, use that model to classify. For each class <span class="math inline"><em>C</em></span>, fit <span class="math inline"><em>p</em>(<em>x</em>|<em>y</em> = <em>C</em>)</span>. Estimate <span class="math inline"><em>p</em>(<em>y</em> = <em>C</em>)</span>. To minimize <span class="math inline"><em>P</em><em>r</em>(<em>e</em><em>r</em><em>r</em>)</span>, pick y that maximizes <span class="math inline"><em>P</em>(<em>y</em>|<em>x</em>)</span> via Bayes rule.</p></li>
<li><p>Discriminative. Fit <span class="math inline"><em>p</em>(<em>y</em>|<em>x</em>)</span>. Function fitting. Fitting each data point. For cost function, want to maximize <span class="math inline">∏<em>P</em>(<em>y</em><sub><em>i</em></sub>|<em>x</em><sub><em>i</em></sub>)≡max1/<em>n</em>∑log<em>p</em>(<em>y</em><sub><em>i</em></sub>|<em>x</em><sub><em>i</em></sub>)</span>. <em>Equivalent to ERM</em>.</p></li>
</ul></li>
<li><p>Generative example: What is a good model of <span class="math inline"><em>x</em></span> given <span class="math inline"><em>y</em></span>. Fit blobs of data given their labels.</p>
<ul>
<li><p>Let <br /><span class="math display"><em>p</em>(<em>x</em>|<em>y</em> = <em>C</em>)=𝒩(<em>μ</em><sub><em>c</em></sub>, <em>Λ</em><sub><em>c</em></sub>)</span><br /> where <span class="math inline">$\hat{\mu}_c = 1/n_c \sum_{i \in I_C} X_i$</span>, and <span class="math inline">$\Lambda_c = 1/n_c \sum (x_i - \hat{\mu}_c)  (x_i - \hat{\mu}_c)^T$</span>. Only have one index <span class="math inline"><em>i</em></span> because it is a <span class="math inline"><em>d</em><em>x</em><em>d</em></span> sum of matrices.</p></li>
<li><p>Decision rule: <br /><span class="math display">$$\begin{aligned}
        \operatorname*{arg\,max}_c -1/2 (x - \hat{\mu}_c)^T \hat{\Lambda}^{-1} (x - \hat{\mu}_c) - 1/2 \log \det \hat{\Lambda}_c - \log \hat{\pi}_c 
        \end{aligned}$$</span><br /> where last two terms are apparently constant. First term is a quadratic. <span class="math inline"><em>Q</em><sub><em>c</em></sub>(<em>x</em>)</span> denotes the whole thing. Decision boundary is set <span class="math inline">{<em>x</em> : <em>Q</em><sub><em>c</em> = −1</sub>(<em>x</em>)=<em>Q</em><sub><em>c</em> = 1</sub>(<em>x</em>)}</span>.</p></li>
<li><p>Need to make sure <span class="math inline"><em>n</em> &gt; &gt;<em>d</em><sup>2</sup></span> in order to avoid overfitting.</p></li>
<li><p>called .</p></li>
</ul></li>
<li><p>. Assume <span class="math inline"><em>Λ</em><sub><em>c</em></sub></span> same for every class. They all have the same covariance matrix.</p>
<ul>
<li><p>How to find <span class="math inline"><em>Λ</em></span>? <br /><span class="math display">$$\begin{aligned}
        \hat{\Lambda}_c &amp;= \sum_C \frac{n_c}{n} \frac{1}{n}\sum_{i\in C} (x_i - \hat{\mu}_c) (x_i - \hat{\mu}_c)^T \\
        &amp;= \frac{1}{n}\sum_i^n (x_i - \hat{\mu}_{y_i}) (x_i - \hat{\mu}_{y_i})^T 
        \end{aligned}$$</span><br /></p></li>
<li><p>Extremely similar to QDA, have (sort of; don’t rely on this) <br /><span class="math display">$$\begin{aligned}
        \operatorname*{arg\,max}_c  -  (x - \hat{\mu}_c)^T \hat{\Lambda}^{-1} (x - \hat{\mu}_c) - 1/2 \log \det \hat{\Lambda} - \log \hat{\pi}_c 
        \end{aligned}$$</span><br /></p></li>
<li><p>end up with linear boundaries.</p></li>
</ul></li>
<li><p>Did something called <strong>method of centroids</strong></p></li>
<li><p>ppl like LDA bc fuck optimization</p></li>
</ul>
<ul>
<li><p>Model <span class="math inline"><em>p</em>(<em>y</em>|<em>x</em>)∼𝒩(<em>w</em><sup><em>T</em></sup><em>x</em>, <em>σ</em><sup>2</sup>)</span>, where <span class="math inline"><em>y</em> = <em>w</em><sup><em>T</em></sup><em>x</em> + <em>ϵ</em></span>. Epsilon is noise causing data points to fluctuate about hyperplane. Assume noise is gaussian with zero mean, some variance. Variance of <span class="math inline"><em>y</em></span> is the variance of the noise <span class="math inline"><em>ϵ</em></span>.</p></li>
<li><p>Unknown we want to estimate: <span class="math inline"><em>w</em></span>. Estimate by using maximum likelihood. says this maximizes <span class="math inline"><em>p</em>(<em>y</em>|<em>x</em>)</span>. Figure out how this is same as maximizing <span class="math inline"><em>p</em>(<em>x</em>|<em>y</em>)</span>...</p></li>
<li><p><span class="math inline"><em>P</em>(<em>d</em><em>a</em><em>t</em><em>a</em>|<em>θ</em>)=<em>p</em>(<em>y</em><sub>1</sub>, …, <em>y</em><sub><em>n</em></sub>|<em>x</em><sub>1</sub>, …, <em>x</em><sub><em>n</em></sub>, <em>θ</em>)=∏<em>p</em>(<em>y</em><sub><em>i</em></sub>|<em>x</em><sub><em>i</em></sub>, <em>θ</em>)</span>.</p></li>
<li><p>“Hit that bitch with a log so she split.” - Jitendra</p></li>
<li><p>Use matrices so you can express as <br /><span class="math display">$$\begin{aligned}
    \sum (y_i - w^T x_i)^2 = ||y - Aw||^2
    \end{aligned}$$</span><br /> where <span class="math inline"><em>A</em></span> is typically denoted as the designed matrix <span class="math inline"><em>X</em></span>.</p></li>
<li><p>Take gradient of loss like usual... <br /><span class="math display">$$\begin{aligned}
    \nabla_W \mathcal{L} &amp;= -A^T y + A^T A w
    \end{aligned}$$</span><br /> where, if we differentiate again, yields the hessian <span class="math inline"><em>H</em> = <em>A</em><sup><em>T</em></sup><em>A</em></span>.</p></li>
<li><p>Implicitly want <span class="math inline"><em>y</em> ≈ <em>A</em><em>w</em></span> here. Re-interpret <span class="math inline"><em>A</em></span> as a bunch of columns now (rather than a bunch of rows). <br /><span class="math display">$$\begin{aligned}
    A =
    \begin{bmatrix}
    a_1 &amp; \cdots &amp; a_d \\
    \end{bmatrix}
    \end{aligned}$$</span><br /> and so <br /><span class="math display">$$\begin{aligned}
    ||y - Aw||^2 = ||y -( w_1 a_1 + \cdots + w_d a_d)||^2
    \end{aligned}$$</span><br /></p></li>
<li><p>of A refers to this type of linear combination of columns <span class="math inline"><em>a</em><sub><em>i</em></sub></span>.</p></li>
<li><p>References 3.2 figure in ESL. Error is vertical component of y in figure. This “error vector” is perpendicular to the subspace spanned by the x’s.</p></li>
<li><p>y - Aw is perpendicular to each and every column of A. <span class="math inline">$A^T (y - Aw) = \bm{0}$</span>.</p></li>
</ul>
<ul>
<li><p>Fitting the data to model is called . Bias summarizes the fact that the model is wrong, but we want to know how wrong.</p></li>
<li><p>is robustness to changes in data.</p></li>
<li><p>Good model has both low bias and low variance.</p></li>
<li><p>Example:</p>
<ul>
<li><p>Sample one point <span class="math inline"><em>x</em> ∼ 𝒩(<em>μ</em>, <em>σ</em><sup>2</sup><em>I</em><sub><em>d</em></sub>)</span>.</p></li>
<li><p>What is most likely estimate for <span class="math inline">$\hat{\mu}$</span>? Just <span class="math inline"><em>x</em></span> (only have one point).</p></li>
<li><p>Since, the expected value of <span class="math inline"><em>x</em></span> is (by definition) <span class="math inline"><em>μ</em></span>, we have that <br /><span class="math display">$$\begin{aligned}
            {\mathbb{E}[\hat{\mu} - \mu]} = 0
        \end{aligned}$$</span><br /></p></li>
<li><p>How about squared error <br /><span class="math display">$$\begin{aligned}
            {\mathbb{E}[||\hat{\mu} - \mu ||^2]} &amp;= {\mathbb{E}[(\hat{\mu} - \mu )^(\hat{\mu} - \mu )]} \\
            &amp;= {\mathbb{E}[Tr(x-\mu)(x-\mu)^T]} \\
            &amp;= Tr(\Lambda)
        \end{aligned}$$</span><br /> which uses the <strong></strong>: if dot product is scalar, then it is equal to trace of outer product<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>.</p></li>
<li><p>What is the trace of the covariance matrix <span class="math inline"><em>Λ</em></span>? Here (only) it is <span class="math inline"><em>d</em><em>σ</em><sup>2</sup></span>.</p></li>
<li><p>What if I’m bored and I define <span class="math inline">$\hat{\mu} = \alpha x$</span>, where <span class="math inline">0 &lt; <em>α</em> &lt; 1</span>? Then <br /><span class="math display">$$\begin{aligned}
            {\mathbb{E}[\hat{\mu}]} &amp;= \alpha \mu \\
            {\mathbb{E}[\hat{\mu} - \mu]} &amp;= (\alpha - 1) \mu 
        \end{aligned}$$</span><br /> which isn’t zero (woaAHhhh!)</p></li>
<li><p>Variance won’t go down. <br /><span class="math display">$$\begin{aligned}
            {\mathbb{E}[||\hat{\mu} - \mu||^2]} &amp;= {\mathbb{E}[||\hat{\mu} - {\mathbb{E}[\hat{\mu}]} + {\mathbb{E}[\hat{\mu} -  \mu||^2]}]} 
        \end{aligned}$$</span><br /></p></li>
</ul></li>
<li><p>Me making sense of (as defined in this lecture):</p>
<ul>
<li><p>Slow for high dimensional probs; Better than gradient descent though.</p></li>
<li><p>Gradient descent models func with first order taylor approx. Newton’s method uses <em>second order</em>. <br /><span class="math display">$$\begin{aligned}
            f(x) \approx f(x_k) + \nabla f(x_k)^T(x-x_k) +
             {\frac{1}{2}}(x - x_k)^T \nabla^2 f(x_k) (x - x_k)
        \end{aligned}$$</span><br /> where grad-squared is the <strong>Hessian</strong>.</p></li>
<li><p>: <br /><span class="math display">$$\begin{aligned}
            \textsc{Let } f(\alpha) &amp;= 0 \\
            f(\alpha) &amp;= f(x_n) + f'(x_n)(\alpha - x_n) + R_1 \\
            \textsc{where } R_1 &amp;= {\frac{1}{2}}f''(\xi_n) (\alpha - x_n)^2 \\
            \frac{f(x_n)}{f'(x_n)} + (\alpha - x_n) &amp;= -\frac{f''(\xi_n)}{2 f'(x_n)}(\alpha - x_n)^2 \\
        \end{aligned}$$</span><br /> and all the <span class="math inline"><em>x</em><sub><em>n</em></sub></span> represent the <span class="math inline"><em>n</em></span>th approximation of some root of <span class="math inline"><em>f</em>(<em>x</em>)</span>.</p></li>
</ul></li>
<li><p>Oh I get it now:</p>
<ul>
<li><p><strong>Gradient descent</strong>: Find optimal <span class="math inline"><em>w</em></span> iteratively by assuming first-order taylor expansion of <span class="math inline">∇<em>J</em>(<em>w</em> * )</span>: <br /><span class="math display">$$\begin{aligned}
            {\nabla J(w^*)} &amp;\approx {\nabla J(w_k)} \\
        \end{aligned}$$</span><br /> where <span class="math inline"><em>w</em><sub><em>k</em></sub></span> is the current best guess for the minimum of <span class="math inline"><em>J</em></span>. If this gradient is zero, we are done. If it is not, then we continue to iterate closer and closer via the update <br /><span class="math display">$$\begin{aligned}
            w_{k+1} &amp;= w_k - \eta {\nabla J(w_k)}
        \end{aligned}$$</span><br /> until our first-order approximation (appears) valid.</p></li>
<li><p><strong>Newton’s method</strong> goes a step further and expands to second order: <br /><span class="math display">$$\begin{aligned}
            {\nabla J(w*)} &amp;\approx {\nabla J(w_k)} + {\nabla J(w_k)}^2  (w^*-w_k) \\ 
            &amp;= {\nabla J(w_k)} +  {\mathbf{H}}(w^*-w_k)
        \end{aligned}$$</span><br /> where<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>, implicit in all these optimization algorithms, is the hope that <span class="math inline"><em>w</em><sub><em>k</em> + 1</sub> ≈ <em>w</em><sup>*</sup></span>, and so we can set this derivative to 0 to “solve” for <span class="math inline"><em>w</em><sub><em>k</em> + 1</sub> = <em>w</em><sup>*</sup></span> as <br /><span class="math display">$$\begin{aligned}
            (w_{k+1} - w_k) &amp;= - {\mathbf{H}}^{-1} {\nabla J(w_k)} \\
            w_{k + 1} &amp;= w_k - {\mathbf{H}}^{-1} {\nabla J(w_k)} \label{Newton1}
        \end{aligned}$$</span><br /> where equatoin [Newton1] is . It is computationally better to compute <span class="math inline"><em>e</em></span>, where <br /><span class="math display">$$\begin{aligned}
            {\mathbf{H}} e &amp;= -{\nabla J(w_k)} \longrightarrow e = - {\mathbf{H}}^{-1} {\nabla J(w_k)}
        \end{aligned}$$</span><br /></p></li>
</ul></li>
</ul>
<ul>
<li><p>bias = <span class="math inline">𝔼[<em>f</em>(<em>x</em>)−<em>y</em>]</span></p></li>
<li><p>Risk = <span class="math inline">𝔼[loss(<em>f</em>(<em>x</em>),<em>y</em>)]</span></p></li>
<li><p>Variance = <span class="math inline">𝔼[(<em>f</em>(<em>x</em>)−𝔼[<em>f</em>(<em>x</em>)])<sup>2</sup>]</span></p></li>
<li><p>Regularization: Minimize empirical loss + penalty term.</p></li>
</ul>
<p><span> </span>. Outputs can be computed for, say, a basic neuron to output 2 as <span class="math inline"><em>S</em><sub>2</sub> = ∑<sub><em>i</em></sub><em>w</em><sub>2<em>i</em></sub><em>x</em><sub><em>i</em></sub></span>. We can also feed this through <span class="math inline"><em>g</em></span> such as the logistic or RELU. Why shouldn’t we connect linear layers to linear layers? <em>Because that is equivalent to one linear layer</em>. If we want to stack (multilayer) need some nonlinearity. Want to find good weights so that output can perform classification/regression.<br />
<span> </span>. Goal: Find w such that <span class="math inline"><em>O</em><sub><em>i</em></sub></span> is as close as possible to <span class="math inline"><em>y</em><sub><em>i</em></sub></span> (the labeled/desired output). Approach:</p>
<p>[<span class="math inline">→</span>]</p>
<p>Define loss function <span class="math inline">ℒ(<em>w</em>)</span>.</p>
<p>Compute <span class="math inline">∇<sub><em>w</em></sub>ℒ</span>.</p>
<p>Update <span class="math inline"><em>w</em><sub><em>n</em><em>e</em><em>w</em></sub> ← <em>w</em><sub><em>o</em><em>l</em><em>d</em></sub> − <em>η</em>∇<sub><em>w</em></sub>ℒ</span>.</p>
<p>and so training is all about <em>computing the gradient</em>. Amounts to computing partial derivatives like <span class="math inline">$ {\frac{\partial \mathcal{L}}{\partial w_{jk}}} $</span>. Approach for <strong>training a 2-layer neural network</strong>:</p>
<p>[<span class="math inline">→</span>]</p>
<p>Compute <span class="math inline">∇<sub><em>w</em></sub>ℒ</span> for all weights from input to hidden, hidden output.</p>
<p>Use SGD. Loss function <strong>no longer convex</strong> so can only find local minima.</p>
<p>Naive gradient computation is quadratic in num. weights. is a trick to compute it in linear time.<br />
</p>
<p><span> </span> [for a two layer net]. The value of the <span class="math inline"><em>i</em></span>th output neuron can be computed as <br /><span class="math display">$$\begin{aligned}
        O_i = g\bigg(\sum_j W_{ij} ~ g\big( \sum_k W_{jk} x_k \big)\bigg)
    \end{aligned}$$</span><br /> where let’s focus on the weight <span class="math inline"><em>W</em><sub>12</sub></span>. <em>Simple idea:</em></p>
<ul>
<li><p>Consider some situation where we have value for output <span class="math inline"><em>O</em><sub><em>i</em></sub></span> as well as another value <span class="math inline"><em>O</em><sub><em>i</em></sub>′</span> which is the same as <span class="math inline"><em>O</em><sub><em>i</em></sub></span> except one of the weights is slightly changed: <br /><span class="math display">$$\begin{aligned}
        O_i &amp;= g(\ldots, w_{jk}, \ldots, x  ) \\
        O_i'&amp;= g(\ldots, w_{jk} + \Delta w_{jk}, \ldots, x  ) 
    \end{aligned}$$</span><br /></p></li>
<li><p>Then we can compute numerical approx to derivative for <em>one</em> of the weights: <br /><span class="math display">$$\begin{aligned}
        \dfrac{{\mathcal{L}}(O_i') - {\mathcal{L}}(O_i)}{ \Delta w_{jk} }
    \end{aligned}$$</span><br /> a process typically called the <a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> This is <span class="math inline">𝒪(<em>n</em>)</span> if there are <span class="math inline"><em>n</em></span> weights in the network. But since this is just the derivative for <em>one</em> of the weights, the total cost over all weights is <span class="math inline">𝒪(<em>n</em><sup>2</sup>)</span>.</p></li>
<li><p>This is why we need backprop: to lower complexity from <span class="math inline">𝒪(<em>n</em><sup>2</sup>)</span> to <span class="math inline">𝒪(<em>n</em>)</span>.<br />
</p></li>
</ul>
<p><span> </span>. Big picture: A lot of these computations [gradients] seem to be shared. Want to find some way of avoiding computing quantities more than once.</p>
<p>[<span class="math inline">→</span>]</p>
<p><strong>Idea:</strong> Want to compute some quantity <span class="math inline"><em>δ</em><sup><em>i</em></sup></span> at output layer for each of the <span class="math inline"><em>i</em></span> output neurons. Then, find the <span class="math inline"><em>δ</em><sup><em>i</em> − 1</sup></span> for the layer below, repeat until reach <em>back</em> to input layer [hence name backprop]. Key idea is the .</p>
<p>Notation:<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> <br /><span class="math display"><em>x</em><sub><em>j</em></sub><sup>(<em>l</em>)</sup> = <em>g</em>(∑<sub><em>i</em></sub><em>w</em><sub><em>i</em><em>j</em></sub><sup>(<em>l</em>)</sup><em>x</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup>) ≡ <em>g</em>(<em>S</em><sub><em>j</em></sub><sup>(<em>l</em>)</sup>)</span><br /> where now <span class="math inline"><em>w</em><sub><em>i</em><em>j</em></sub></span> is <em>from</em> <span class="math inline"><em>i</em></span> <em>to</em> <span class="math inline"><em>j</em></span>. <strong>We will also denote <span class="math inline"><em>e</em></span> for ’error’.</strong></p>
<p>Define partial derivative of error with respect to the linear combination input to neuron <span class="math inline"><em>j</em></span> as <span> </span> which carry the information we want about the partial derivatives along the way.</p>
<p>Consider simple case of <br /><span class="math display"><em>x</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup> → <em>w</em><sub><em>i</em><em>j</em></sub><sup>(<em>l</em>)</sup> → <em>x</em><sub><em>j</em></sub><sup>(<em>l</em>)</sup></span><br /> and we want to calculate <br /><span class="math display">$$\begin{aligned}
    {\frac{\partial e}{\partial w_{ij}^{(l)}}} &amp;=     {\frac{\partial e}{\partial S_{j}^{(l)}}} {\frac{\partial S_j^{(l)}}{\partial w_{ij}^{(l)}}}  \\
    &amp;=   \delta_j^{(l)}  {\frac{\partial S_j^{(l)}}{\partial w_{ij}^{(l)}}}  
    \end{aligned}$$</span><br /></p>
<p>“Inductive step” for calculating <span class="math inline"><em>δ</em></span> with chain rule [for <strong>regression problem using squared error loss of <span class="math inline">$e = {\frac{1}{2}}\big( g(S_i^{(l)}) - y\big)^2$</span> corresponds to a given example</strong>]: <br /><span class="math display">$$\begin{aligned}
        \delta_i^{(l)}   &amp;= {\frac{\partial e}{\partial S_i^{(l)}}} \\
        &amp;= {\frac{1}{2}}\bigg[ 2 ~ \big( g(S_i^{(l)}) - y\big) ~ g'(S_i^{(l)}) \bigg]
    \end{aligned}$$</span><br /> Don’t confuse the above expression for sigmoid deriv. It is not assuming anything about the functional form of <span class="math inline"><em>g</em></span>.</p>
<p><span> </span> Cross-entropy loss derivation uses the following. Note that we are defining all <span class="math inline"><em>y</em><sub><em>i</em></sub> = 0</span> or <span class="math inline"><em>y</em><sub><em>i</em></sub> = 1</span>. <br /><span class="math display">$$\begin{aligned}
    O_i^{y_i} (1 - O_i)^{1-y_i} \quad \rightarrow \quad y_i  \ln O_i + (1 - y_i) \ln (1 - O_i)\end{aligned}$$</span><br /> where the expression on the RHS is the log (likelihood) of the LHS. We want to take partial derivatives of loss function with respect to weights. The <span class="math inline"><em>δ</em></span> terms represent layer-specific derivatives of error with respect to the <span class="math inline"><em>S</em></span> values (the summed input). See previous lecture note for more details on this. Note that, in order to get the values of the error in the first place, need to first perform the <strong>forward pass</strong>.</p>
<p><span> </span> In the last lecture, we barely scratched the surface of actually calculating <span class="math inline"><em>δ</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup></span>, the partial of the error with respect to <span class="math inline"><em>S</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup></span>. Recall that the subscript on <span class="math inline"><em>S</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup></span> means the weighted sum <em>into</em> the <span class="math inline"><em>i</em></span>th neuron at layer. Specifically <br /><span class="math display">$$\begin{aligned}
    S_j^{(l - 1)} =  \sum_i w_{ij}^{(l)} x_i^{(l - 2)} \quad \rightarrow \quad x_j^{(l - 1)}\end{aligned}$$</span><br /></p>
<p><span> </span>. <strong>Setup</strong>: Only consider the following portion of the network: A summation value <span class="math inline"><em>S</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup></span> is fed into a single neuron <span class="math inline"><em>x</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup></span> at the <span class="math inline"><em>l</em> − 1</span> layer. From this neuron, <span class="math inline"><em>g</em>(<em>S</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup>)</span> is fed to the neurons at the layer above <span class="math inline">(<em>l</em>)</span> by connection weights <span class="math inline"><em>w</em></span>. We calculate the partial derivative of the error <em>corresponding to these particular weights</em> with respect to the summation fed to <span class="math inline"><em>x</em><sub><em>i</em></sub><sup>(<em>l</em> − 1)</sup></span> as <br /><span class="math display">$$\begin{aligned}
    \delta_i^{(l - 1)} &amp;= {\frac{\partial err(w)}{\partial S_i^{(l - 1)}}} \\
    &amp;= \sum_j {\frac{\partial err(w)}{\partial S_j^{(l)}}}  {\frac{\partial S_j^{(l)}}{\partial x_i^{(l - 1)}}}  {\frac{\partial x_i^{(l - 1)}}{\partial S_i^{(l - 1)}}} \\
    &amp;= \sum_j \delta_j^{(l)} w_{ij}^{(l)} g'(S_i^{(l - 1)}) \end{aligned}$$</span><br /> where we’ve already calculated all <span class="math inline"><em>δ</em></span> value in the layers above (i.e. we are somewhere along the backward pass).</p>
<p><span> </span>. [1 hr into lec]. Reviews biology of brain/neuron/eye. Rods and cones are the eye’s pixels. Think of as 2D sheet of inputs. Such sheets can be thought of as 1D layers. Bipolar cell gets direct input (center input) from two photo-receptors, and gets indirect input (surround input) from horizontal cell. “Disc where you’re getting indirect input from horizontal cell.” Weights between neurons can be positive (excitatory) or negative (inhibitory). Assume center input is excitatory, surround input in inhibitory.</p>
<ul>
<li><p>Very small spot of light means neuron fires, as you increase size of spot, inhibition from surround cells kick in, and its output is diminished. Uses example of ON/OFF cells in retinal ganglia. Neurons can only individually communicate positive values, but multiple neurons can “encode” negative values.</p></li>
<li><p>. The receptive field of a receptor is simply the area of the visual field from which light strikes that receptor. For any other cell in the visual system, the receptive field is determined by which receptors connect to the cell in question.</p></li>
<li><p>Relation to <strong>Convolution</strong>. Consider convolving an image with a filter.</p>
<p><img src="Conv.PNG" alt="image" style="width:30.0%" /></p>
<p>Each output unit gets the weighted sum of image pixels. The [-1, 0, 1] is a “weighting mask.”</p></li>
</ul>
<p>[Shewchuck Notes]</p>
<h3 id="section"></h3>
<ul>
<li><p>Consider <span class="math inline"><em>n</em></span> sample points <span class="math inline"><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>n</em></sub></span>.</p></li>
<li><p>For each sample point, let <br /><span class="math display">$$y_i = \begin{cases}
    1   &amp; X_i \in \text{class C} \\
    -1  &amp; X_i \notin \text{class C}
    \end{cases}$$</span><br /></p></li>
<li><p>: Find weights <span class="math inline"><em>w</em></span> that satisfy the <em>constraint</em> <br /><span class="math display"><em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> ≥ 0</span><br /></p></li>
<li><p>In order to minimize the number of constraint violations, need a way to quantify how “good” we are doing. Do this with the <br /><span class="math display">$$L(z,~y_i) =
    \begin{cases}
    0 &amp; y_i z \ge 0 \\
    -y_i z &amp; \text{otherwise}
    \end{cases}$$</span><br /> Notice that this can only be <span class="math inline">≥0</span> by definition. The larger <span class="math inline"><em>L</em></span> is, the worse you are as a human being.</p></li>
<li><p>The function is a sum total of your losses. <br /><span class="math display">$$R(w) = \sum_{i=1}^{n} L(X_i \cdot w, y_i) = \sum_{i \in V} ( -y_i ~ X_i \cdot w)$$</span><br /> where <span class="math inline">(∀<em>i</em> ∈ <em>V</em>)(<em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> &lt; 0)</span>.</p></li>
<li><p>: Find <span class="math inline"><em>w</em></span> that minimizes <span class="math inline"><em>R</em>(<em>w</em>)</span>.</p></li>
</ul>
<h3 id="section-1"></h3>
<ul>
<li><p>Notice the different between the two (purple) Goals stated in the previous subsection. We went from constraining <span class="math inline"><em>w</em></span> to certain in x-space (<span class="math inline"><em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> ≥ 0</span>) to constraining <span class="math inline"><em>w</em></span> to certain in w-space (<span class="math inline">min<sub><em>w</em></sub><em>R</em>(<em>w</em>)</span>).</p></li>
<li><p>Figure  [XSpaceWSpace] illustrates how the data points constrain the possible values for <span class="math inline"><em>w</em></span> in our optimization problem. For each sample point <span class="math inline"><em>x</em></span>, the constraints can be stated as</p>
<ul>
<li><p><span class="math inline"><em>x</em></span> in the “positive” class <span class="math inline">⇒</span> <span class="math inline"><em>x</em></span> and <span class="math inline"><em>w</em></span> must be on the <strong>same</strong> side of the hyperplane that <span class="math inline"><em>x</em></span> transforms into<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>.</p></li>
<li><p><span class="math inline"><em>x</em></span> in the “negative” class <span class="math inline">⇒</span> <span class="math inline"><em>x</em></span> and <span class="math inline"><em>w</em></span> must be on the <strong>opposite</strong> side of <span class="math inline"><em>x</em></span>’s hyperplane.</p></li>
</ul>
<p><img src="XSpaceWSpace.PNG" title="fig:" alt="Illustration of how three sample points in x-space (left) can constrain the possible values for w in w space (right)." style="width:40.0%" /> [XSpaceWSpace]</p></li>
</ul>
<h3 id="section-2"></h3>
<ul>
<li><p>GD on our risk function <span class="math inline"><em>R</em></span> is an example of an . We want to <em>minimize</em> our risk, so we take successive steps in the <em>opposite</em> direction of <span class="math inline">∇<em>R</em>(<em>w</em>)</span>.<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> <br /><span class="math display">$$\begin{aligned}
    \nabla R(w) &amp;= \nabla \sum_{i \in V} ( -y_i ~ X_i \cdot w) \\
    &amp;=  -\sum_{i \in V} (y_i ~ X_i )
    \end{aligned}$$</span><br /></p></li>
<li><ul>
<li><p><span class="math inline"><em>w</em>←</span> arbitrary nonzero (e.g. any <span class="math inline"><em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub></span> )</p></li>
<li><p>while <span class="math inline"><em>R</em>(<em>w</em>)&gt;0</span></p>
<ul>
<li><p><span class="math inline"><em>V</em>←</span> all <span class="math inline"><em>i</em></span> for which <span class="math inline"><em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> &lt; 0</span></p></li>
<li><p><span class="math inline"><em>w</em> ← <em>w</em> + <em>ϵ</em>∑<sub><em>i</em> ∈ <em>V</em></sub>(<em>y</em><sub><em>i</em></sub> <em>X</em><sub><em>i</em></sub>)</span></p></li>
</ul></li>
</ul>
<p>where <span class="math inline"><em>ϵ</em></span> is the . Each step is <span class="math inline"><em>O</em>(<em>n</em><em>d</em>)</span> time.</p></li>
</ul>
<h3 id="section-3"></h3>
<ul>
<li><p>Procedure is simply GD on one data point only per step, i.e. no summation symbol. Called the .</p></li>
<li><ul>
<li><p>while some <span class="math inline"><em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> &lt; 0</span></p>
<ul>
<li><p><span class="math inline"><em>w</em> ← <em>w</em> + <em>ϵ</em><em>y</em><sub><em>i</em></sub><em>X</em><sub><em>i</em></sub></span></p></li>
</ul></li>
<li><p>return <span class="math inline"><em>w</em></span>.</p></li>
</ul></li>
<li><p>If data is linearly separable, perfect linear classifier will be found in at most <span class="math inline"><em>O</em>(<em>R</em><sup>2</sup>/<em>γ</em><sup>2</sup>)</span> iterations, where</p>
<ul>
<li><p><span class="math inline"><em>R</em> = max<sub><em>i</em></sub>|<em>X</em><sub><em>i</em></sub>|</span> is radius of the data</p></li>
<li><p><span class="math inline"><em>γ</em></span> is the maximum margin.</p></li>
</ul></li>
</ul>
<h3 id="section-4"></h3>
<ul>
<li><p>: (of a linear classifier) the distance from the decision boundary to the nearest sample point.</p></li>
<li><p>: Make the margin as large as possible.</p>
<ul>
<li><p>Recall that the margin is defined as <span class="math inline">|<em>τ</em><sub><em>m</em><em>i</em><em>n</em></sub>|</span>, the magnitude of the smallest euclidean distance from a sample point to the decision boundary, where for some <span class="math inline"><em>x</em><sub><em>i</em></sub></span>, <br /><span class="math display">$$\tau_i = \frac{|f(x_i)|}{||w||}$$</span><br /> and our goal is to <em>maximize</em> the value of the <em>smallest</em> <span class="math inline"><em>τ</em></span> in the dataset.</p></li>
<li><p>Enforce the (seemingly arbitrary) constraints that <span class="math inline">|<em>f</em>(<em>x</em><sub><em>i</em></sub>)| ≥ 1</span>, or equivalently <br /><span class="math display">$$\begin{aligned}
        y_i (w \cdot x_i + \alpha) \ge 1
        \end{aligned}$$</span><br /> which can also be stated as requiring all <span class="math inline"><em>τ</em><sub><em>i</em></sub> ≥ 1/||<em>w</em>||</span>.</p></li>
<li><p><strong>Optimize:</strong> Find <span class="math inline"><em>w</em></span> and <span class="math inline"><em>α</em></span> that minimize <span class="math inline">||<em>w</em>||<sup>2</sup></span>, subject to <span class="math inline"><em>y</em><sub><em>i</em></sub>(<em>w</em> ⋅ <em>x</em><sub><em>i</em></sub> + <em>α</em>)≥1</span> for all <span class="math inline"><em>i</em> ∈ [1, <em>n</em>]</span>. “Called a in d+1 dimensions and n constraints. It has <strong>one unique solution.</strong>”</p></li>
</ul></li>
<li><p>The solution is a aka a .</p></li>
</ul>
<ul>
<li><p>Hard-margin SVMs fail if not linearly separable.</p></li>
<li><p>Allow some points to violate the margin, with <span class="math inline"><em>ξ</em></span> <br /><span class="math display"><em>y</em><sub><em>i</em></sub>(<em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> + <em>α</em>)≥1 − <em>ξ</em><sub><em>i</em></sub></span><br /> where <span class="math inline"><em>ξ</em><sub><em>i</em></sub> ≥ 0</span>. Note that each sample point is <em>assigned</em> a value of <span class="math inline"><em>ξ</em><sub><em>i</em></sub></span>, which is only nonzero iff <span class="math inline"><em>x</em><sub><em>i</em></sub></span> violates the margin.</p></li>
<li><p>To prevent abuse of slack, add a <strong></strong> to our objective function<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a>.</p>
<ul>
<li><p>Find <span class="math inline"><em>w</em></span>, <span class="math inline"><em>α</em></span>, and <span class="math inline"><em>ξ</em><sub><em>i</em></sub></span> that minimize our objective function, <br /><span class="math display">$$\begin{aligned}
        |w|^2 + C \sum_{i = 1}^n \xi_i
        \end{aligned}$$</span><br /> subject to <br /><span class="math display">$$\begin{aligned}
        y_i (X_i \cdot w + \alpha) \ge 1 - \xi_i \quad &amp;\text{for all } i \in [1,n] \\
        \xi_i \ge 0 \quad &amp;\text{for all } i \in [1,n]
        \end{aligned}$$</span><br /> a quadratic program in d + n + 1 dimensions and 2n constraints. The relative size of <span class="math inline"><em>C</em></span>, the determines whether you are more concerned with getting a large margin (small <span class="math inline"><em>C</em></span>) or keeping the slack variables as small as possible (large <span class="math inline"><em>C</em></span>).</p></li>
</ul></li>
</ul>
<ul>
<li><p>For when “a sample point in feature space doesn’t have just one class”. Solution is to classify with probabilities.</p></li>
<li><ul>
<li><p><strong>Loss Function</strong> <span class="math inline"><em>L</em>(<em>z</em>, <em>y</em>)</span>: Specifies badness of classifying as <span class="math inline"><em>z</em></span> when the true class is <span class="math inline"><em>y</em></span>. Can be . We are typically used to the <em>0-1 loss function</em> which is symmetric: 1 if incorrect, 0 if correct.</p></li>
<li><p><strong>Decision rule (classifier)</strong> <span class="math inline"><em>r</em> : ℝ<sup><em>d</em></sup> → ±1</span>. Maps feature vector <span class="math inline"><em>x</em></span> to a class (1 if in class, -1 if not in class for binary case).</p></li>
<li><p><strong>Risk</strong>: Expected loss over <em>all</em> values of <span class="math inline"><em>x</em></span>, <span class="math inline"><em>y</em></span>: <br /><span class="math display">$$\begin{aligned}
            R(r) &amp;= \mathbb{E} \big[ L(r(X), Y) \big]  \\
            &amp;= \sum_y P(Y = y) \sum_x P(X = x | Y = y) L(r(x), y)
        \end{aligned}$$</span><br /> In ESL Chapter 2.4, this is denoted as the .</p></li>
<li><p><strong>Bayes decision rule/classifier</strong> <span class="math inline"><em>r</em>*</span>: Defined as the decision rule <span class="math inline"><em>r</em> = <em>r</em>*</span> that minimizes <span class="math inline"><em>R</em>(<em>r</em>)</span>. If we assume <span class="math inline"><em>L</em>(<em>z</em>, <em>y</em>)=0</span> when <span class="math inline"><em>z</em> = <em>y</em></span>, then <br /><span class="math display">$$r^*(x) = \begin{cases}
                1 &amp; L(-1, 1) P(1 | x) &gt; L(1, 1) P(-1 | x) \\
                -1 &amp; \text{otherwise}
            \end{cases}$$</span><br /> which has <em>optimal risk</em>, also called the <span class="math inline"><em>R</em>(<em>r</em><sup>*</sup>)</span>.</p></li>
</ul></li>
<li><p>Three ways to build classifiers:</p>
<ul>
<li><p>: Assume sample points come frome class-conditioned probability distributions <span class="math inline"><em>P</em>(<em>x</em>|<em>c</em>)</span>, different for each class. Guess the form of these dists. For each class <span class="math inline"><em>C</em></span>, fit (guessed) distributions to points labeled as class <span class="math inline"><em>C</em></span>. Also need to estimate (basically make up?) <span class="math inline"><em>P</em>(<em>C</em>)</span>. Use bayes rule and classify on <span class="math inline">max<sub><em>C</em></sub><em>P</em>(<em>Y</em> = <em>C</em>|<em>X</em> = <em>x</em>)</span>. : Can diagnose outliers (small P(x)). Can know the probability that prediction is wrong. : A full probabilistic model of all variables.</p></li>
<li><p>. Model <span class="math inline"><em>P</em>(<em>Y</em>|<em>X</em>)</span> directly. (I guess this means don’t bother with modelling all the other stuff like X|Y, just go for it bruh.) Can know probability of prediction being wrong. : A model only for the target variables.</p></li>
<li><p>: e.g. SVMs. Model <span class="math inline"><em>r</em>(<em>x</em>)</span> directly. : Easier; always works if linearly separable; don’t have to guess explicit distributions.</p></li>
</ul></li>
</ul>
<ul>
<li><p>Each class C comes from a normal distribution.</p></li>
<li><p>For a given <span class="math inline"><em>x</em></span>, want to maximize <span class="math inline"><em>P</em>(<em>X</em> = <em>x</em>|<em>Y</em> = <em>C</em>)<em>π</em><sub><em>C</em></sub></span>, where <span class="math inline"><em>π</em><sub><em>C</em></sub></span> prior probability of class c. Easier to maximize <span class="math inline"><em>l</em><em>n</em>(<em>z</em>)</span> since increases monotonically for <span class="math inline"><em>z</em> &gt; 0</span>. The following gives the “quadratic in x” function <span class="math inline"><em>Q</em><sub><em>C</em></sub>(<em>x</em>)</span>, <br /><span class="math display">$$\begin{aligned}
        Q_C(x)
        &amp;= \ln \bigg( (\sqrt{2 \pi})^d P(x) \pi_C \bigg) \\
        &amp;= -\frac{|x - \mu_C|^2}{2 \sigma_C^2} - d \ln \sigma_C + \ln \pi_C
    \end{aligned}$$</span><br /> where <span class="math inline"><em>P</em>(<em>x</em>)</span>, a normal distribution, is what we use to estimate the class conditional <span class="math inline"><em>P</em>(<em>x</em>|<em>C</em>)</span>.</p></li>
<li><p>The Bayes decision rule <span class="math inline"><em>r</em><sup>*</sup></span> returns the class <span class="math inline"><em>C</em></span> that maximizes <span class="math inline"><em>Q</em><sub><em>C</em></sub>(<em>x</em>)</span> above.</p></li>
</ul>
<h3 id="section-5"></h3>
<ul>
<li><p>Suppose only 2 classes, C and D. Then <br /><span class="math display">$$r^*(x) =
        \begin{cases}
            C &amp; Q_C(x) - Q_D(x) &gt; 0 \\
            D &amp; \text{otherwise}
        \end{cases}$$</span><br /> which is quadratic in x. The Baye’s Decision Boundary (BDB) is the solution of <span class="math inline"><em>Q</em><sub><em>C</em></sub>(<em>x</em>)−<em>Q</em><sub><em>D</em></sub>(<em>x</em>)=0</span>.</p></li>
<li><p>In 1D, BDB may have 1 or 2 points (solution to quadratic equation)</p></li>
<li><p>In 2D, BDB is a (e.g. for d=2, conic section).</p></li>
<li><p>In 2-class problems, naturally leads to function for determining <span class="math inline"><em>P</em>(<em>Y</em>|<em>X</em>)</span>.</p></li>
</ul>
<h2 id="newtons-method">Newton’s Method</h2>
<ul>
<li><p>Iterative optimization for some smooth function <span class="math inline"><em>J</em>(<em>w</em>)</span>.</p></li>
<li><p>Can Taylor expand gradient about <span class="math inline"><em>v</em></span>: <br /><span class="math display">$$\begin{aligned}
        \nabla J(w) = \nabla J(v) + (w - v)\nabla^2 J(v) + \mathcal{O}(|w-v|^2)
    \end{aligned}$$</span><br /> where <span class="math inline">∇<sup>2</sup><em>J</em>(<em>v</em>)</span> is the of <span class="math inline"><em>J</em>(<em>w</em>)</span> at <span class="math inline"><em>v</em></span>, which I’ll denote <span class="math inline"><strong>H</strong></span>.</p></li>
<li><p>Find critical point <span class="math inline"><em>w</em></span> where <span class="math inline">∇<em>J</em>(<em>w</em>)=0</span>: <br /><span class="math display">$$\begin{aligned}
        w = v - H^{-1} \nabla J(v)
    \end{aligned}$$</span><br /></p></li>
<li><p>Shewchuck defines algorithm as:</p>
<ol>
<li><p>Initialize <span class="math inline"><em>w</em></span>.</p></li>
<li><p>until convergence do: <span class="math inline"><em>e</em> := <em>s</em><em>o</em><em>l</em><em>v</em><em>e</em>_<em>l</em><em>i</em><em>n</em><em>e</em><em>a</em><em>r</em>_<em>s</em><em>y</em><em>s</em><em>t</em><em>e</em><em>m</em>(<strong>H</strong><em>e</em> = −∇<em>J</em>(<em>w</em>))</span>. <span class="math inline"><em>w</em> := <em>w</em> + <em>e</em></span>.</p></li>
</ol>
<p>where starting <span class="math inline"><em>w</em></span> must be “close enough” to desired solution.</p></li>
</ul>
<h2 id="justifications-bias-variance-12">Justifications &amp; Bias-Variance (12)</h2>
<ul>
<li><p>Overview: Describes models, how they lead to optimization problems, and how they contribute to underfitting/overfitting.</p></li>
<li><p>Typical model of reality: <br /><span class="math display">$$\begin{aligned}
        y_i = f(X_i) + \epsilon_i
    \end{aligned}$$</span><br /> where <span class="math inline"><em>ϵ</em><sub><em>i</em></sub> ∼ <em>D</em>′</span> has mean zero.</p></li>
<li><p>Goal of regression: find <span class="math inline"><em>h</em></span> that estimates <span class="math inline"><em>f</em></span>.</p></li>
</ul>
<p>[sec:Probability Review]</p>
<p><span> </span><span><strong><em></em></strong></span>:</p>
<ul>
<li><p><span class="math inline"><em>Ω</em></span>: Set of all outcomes of a random experiment. For six-sided die, <span class="math inline"><em>Ω</em> = {1, …, 6}</span>.</p></li>
<li><p><span class="math inline">ℱ</span>: Set whose <em>elements</em> are <em>subsets</em> of <span class="math inline"><em>Ω</em></span>. Appears that <span class="math inline">ℱ</span> is required to be complete in a certain sense, i.e. that it should contain <em>all</em> possible events (combinations of possible individual outcomes).</p></li>
<li><p>: Function <span class="math inline"><em>P</em> : ℱ → ℝ</span>. Intuitively, it tells you what fraction of the total space of possibilities that <span class="math inline">ℱ</span> is in, where if <span class="math inline">ℱ</span> <em>is</em> the full space, <span class="math inline"><em>P</em>(<em>F</em>)=<em>P</em>(<em>Ω</em>)=1</span>. Also required: <span class="math inline"><em>P</em>(<em>A</em>)≥0  ∀<em>A</em> ∈ ℱ</span>.</p></li>
</ul>
<p><span> </span><span><strong><em></em></strong></span>:<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></p>
<ul>
<li><p>Consider experiment: Flip 10 coins. An example element of <span class="math inline"><em>Ω</em></span> would be of the form <br /><span class="math display">$$\begin{aligned}
        \omega_0 = (H, H, T, H, T, H, H, T, H, T) \in \Omega
    \end{aligned}$$</span><br /> which is typically a quantity too specific for us to really care about. Instead, we prefer real-valued <em>functions</em> of outcomes, known as .</p></li>
<li><p>R.V. <span class="math inline"><em>X</em></span> is defined as a function <span class="math inline"><em>X</em> : <em>Ω</em> → ℝ</span>. They are denoted as <span class="math inline"><em>X</em>(<em>ω</em>)</span>, or simply <span class="math inline"><em>X</em></span> if <span class="math inline"><em>ω</em></span> dependence is obvious.</p></li>
<li><p>Using our definition of the probability measure, we define the probability that <span class="math inline"><em>X</em> = <em>k</em></span> as the probability measure over the space containing all outcomes <span class="math inline"><em>ω</em></span> where <span class="math inline"><em>X</em>(<em>ω</em>)=<em>k</em></span>.<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a></p></li>
<li><p><span class="math inline"><em>F</em><sub><em>X</em></sub> : ℝ → [0, 1]</span> defined as<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> <br /><span class="math display">$$\begin{aligned}
        F_X(x) \triangleq P(X \le x)
    \end{aligned}$$</span><br /></p></li>
<li><p>: When <span class="math inline"><em>X</em></span> is a <em>discrete</em> RV, it is simpler to represent the probability measure by directly saying the probability of each possible value <span class="math inline"><em>X</em></span> can assume. It is a function <span class="math inline"><em>p</em><sub><em>X</em></sub> : <em>Ω</em> → ℝ</span> such that <br /><span class="math display">$$\begin{aligned}
        p_X (x) \triangleq P(X = x)
    \end{aligned}$$</span><br /></p></li>
<li><p>: The derivative of the CDF. <br /><span class="math display">$$\begin{aligned}
        f_X (x) &amp;\triangleq {\frac{\mathrm{d}F_X(x)}{\mathrm{d}x}} \\
        P(x \le X \le x + \delta x) &amp;\approx f_x(x) \delta x
    \end{aligned}$$</span><br /></p></li>
</ul>
<p><span> </span><span><strong><em></em></strong></span></p>
<ul>
<li><p>Discrete <span class="math inline"><em>X</em></span>: (PMF <span class="math inline"><em>p</em><sub><em>X</em></sub>(<em>x</em>)</span>) Can either take expectations of <span class="math inline"><em>X</em></span> (the mean) or of some function <span class="math inline"><em>g</em>(<em>X</em>):ℝ → ℝ</span>, also a random variable.<span> </span></p></li>
<li><p>Continuous <span class="math inline"><em>X</em></span>: (PDF <span class="math inline"><em>f</em><sub><em>X</em></sub>(<em>x</em>)</span>), then <br /><span class="math display">$$\begin{aligned}
        {\mathbb{E}[g(X)]} \triangleq \int_{-\infty}^{\infty} g(x) f_X(x) \mathrm{d}x
    \end{aligned}$$</span><br /></p></li>
<li><p><strong>Properties</strong>: <br /><span class="math display">$$\begin{aligned}
        {\mathbb{E}[a]}        &amp;= a \quad \forall a \in {\mathbb{R}}\\
        {\mathbb{E}[a~f(X)]}   &amp;= a {\mathbb{E}[f(X)]} \\
        {\mathbb{E}[f(X) + g(X)]} &amp;= {\mathbb{E}[f(X)]} + {\mathbb{E}[g(X)]} \\
        {\mathbb{E}[bool(X == k)]} &amp;= P(X = k)
    \end{aligned}$$</span><br /></p></li>
</ul>
<p><span> </span>: Measure of how concentrated the dist of a RV is around its mean. <br /><span class="math display">$$\begin{aligned}
    Var[X] &amp;\triangleq {\mathbb{E}[(X - {\mathbb{E}[X]})^2]} \\
    &amp;= {\mathbb{E}[X^2]} - {\mathbb{E}[X]}^2\end{aligned}$$</span><br /> with properties: <br /><span class="math display">$$\begin{aligned}
    Var[a] &amp;= 0 \quad \forall a \in {\mathbb{R}}\\
    \varDelta[a f(X)] &amp;= a^2 Var[f(X)]\end{aligned}$$</span><br /></p>
<p><img src="CommonRandomVariables.PNG" alt="image" style="width:30.0%" /></p>
<p><span> </span><span><strong><em></em></strong></span></p>
<ul>
<li><p>Recognize that the covariance of two random variables <span class="math inline"><em>X</em></span> and <span class="math inline"><em>Y</em></span> can be described as a <em>function</em> <span class="math inline"><em>g</em> : ℝ<sup>2</sup> → ℝ</span>. Below we define the expectation value for some multivariable function<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a>, and then we can define the covariance as a particular example. <span> </span></p></li>
<li><p>Properties: <br /><span class="math display">$$\begin{aligned}
        Cov[X, Y] &amp;= {\mathbb{E}[XY]} - {\mathbb{E}[X]}{\mathbb{E}[Y]} \\
        Var[X + Y] &amp;= Var[X] + Var[Y] + 2Cov[X, Y]
    \end{aligned}$$</span><br /></p></li>
</ul>
<p><span> </span><span><strong><em></em></strong></span></p>
<ul>
<li><p>Suppose we have <span class="math inline"><em>n</em></span> random variables <span class="math inline"><em>X</em><sub><em>i</em></sub> = <em>X</em><sub><em>i</em></sub>(<em>ω</em>)</span> all over the same general sample space <span class="math inline"><em>Ω</em></span>. Convenient to put them into a <span class="math inline"><em>X</em></span>, defined as <span class="math inline"><em>X</em> : <em>Ω</em> → ℝ<sup><em>n</em></sup></span> and with <span class="math inline"><em>X</em> = [<em>X</em><sub>1</sub><em>X</em><sub>2</sub>…<em>X</em><sub><em>n</em></sub>]<sup><em>T</em></sup></span>.</p></li>
<li><p>Let <span class="math inline"><em>g</em></span> be some function <span class="math inline"><em>g</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>m</em></sup></span>. We can define expectations with notation laid out below. <br /><span class="math display">$$\begin{aligned}
\begin{split}
    g(X) = 
    \begin{bmatrix}
        g_1(X) \\
        g_2(X) \\
        \vdots \\
        g_m(X)
    \end{bmatrix}
\end{split}
\begin{split}
    {\mathbb{E}[g(X)]} = 
    \begin{bmatrix}
        {\mathbb{E}[g_1(X)]} \\
        {\mathbb{E}[g_2(X)]} \\
        \vdots \\
        {\mathbb{E}[g_m(X)]}
    \end{bmatrix}
\end{split}\end{aligned}$$</span><br /></p>
<p><br /><span class="math display">$$\begin{aligned}
    {\mathbb{E}[g_i(X)]} = \int_{{\mathbb{R}}^n} g(x_1,\ldots, x_n)f_{X_1, \ldots, X_n} dx_1\ldots dx_n\end{aligned}$$</span><br /></p></li>
<li><p>For a given <span class="math inline"><em>X</em> : <em>Ω</em> → ℝ<sup><em>n</em></sup></span>, its <span style="font-variant: small-caps;"></span> is the <span class="math inline"><em>n</em> × <em>n</em></span> matrix with <span class="math inline"><em>Σ</em><sub><em>i</em><em>j</em></sub> = <em>C</em><em>o</em><em>v</em>[<em>X</em><sub><em>i</em></sub>, <em>X</em><sub><em>j</em></sub>]</span>. Also, <span> </span> and it satisfies: (1) <span class="math inline"><em>Σ</em> ≽ 0</span> (pos semi-def), (2) <span class="math inline"><em>Σ</em></span> is symmetric.</p></li>
</ul>
<p><span> </span>The eigenvalues of a matrix are the zeros of its , defined as <span class="math inline"><em>f</em>(<em>λ</em>)=det(<em>A</em> − <em>λ</em><em>I</em>)</span>. A vector <span class="math inline"><em>v</em> ≠ 0</span> is an iff <span class="math inline"><em>v</em> ∈ <em>N</em><em>u</em><em>l</em><em>l</em>(<em>A</em> − <em>λ</em><em>I</em>)</span>.<br />
<span> </span>Regardless of offset of plane, the normal vector to ax + by + cz = d is <span class="math inline"><em>w</em> = (<em>a</em>, <em>b</em>, <em>c</em>)</span>. For any point <span class="math inline"><em>A</em></span> not on the plane, closest point <span class="math inline"><em>B</em></span> to <span class="math inline"><em>P</em></span> where <span class="math inline"><em>B</em></span> <em>is</em> on the plane, is determined by the value of <span class="math inline"><em>α</em></span> that solves <br /><span class="math display">$$\begin{aligned}
    (A - \alpha (a, b, c)) \cdot (a, b, c) = d\end{aligned}$$</span><br /> since, given <span class="math inline"><em>α</em></span> satisfies the equation, <span class="math inline"><em>B</em> = (<em>A</em> − <em>α</em>(<em>a</em>, <em>b</em>, <em>c</em>))</span> is a point on the plane, constructed by following the direction of <span class="math inline"><em>w</em></span> “backwards” from <span class="math inline"><em>A</em></span>.<br />
<span> </span>Direct comparison between MLE and :<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a></p>
<p><br /><span class="math display">$$\begin{aligned}
    \begin{split}
        \theta_{MLE} &amp;= \operatorname*{arg\,max}_\theta \sum_i \log\big( {\text{{\textcolor{OliveGreen}{\textbf{$p_X(x|\theta)$}}}}} \big) 
    \end{split}
    \begin{split}
        p(\theta|x) &amp;\propto  {\text{{\textcolor{OliveGreen}{\textbf{$p_X(x|\theta)$}}}}}  p(\theta) \\
        \theta_{MAP} &amp;= \operatorname*{arg\,max}_\theta \sum_i \log\bigg({\text{{\textcolor{OliveGreen}{\textbf{$p_X(x|\theta)$}}}}}p(\theta)\bigg) \\
     &amp;= \operatorname*{arg\,max}_\theta  \{\log\big[{\text{{\textcolor{OliveGreen}{\textbf{$p_X(x|\theta)$}}}}}\big] + p(\theta) \}
    \end{split}
    \end{aligned}$$</span><br /></p>
<h2 id="support-vector-machines">Support Vector Machines</h2>
<p><a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a></p>
<ul>
<li><p>Note that (logistic regression) <br /><span class="math display">$$\begin{aligned}
        g(\theta^T) \ge 0.5 \iff \theta^Tx \ge 0
    \end{aligned}$$</span><br /></p></li>
<li><p>Switch to perceptron algorithm where <br /><span class="math display">$$\begin{aligned}
         h_{w, b}(x) = g(w^T x + b) = 
         \begin{cases}
             1 &amp;  w^Tx + b \ge 0 \\
             -1 &amp; \text{otherwise} 
         \end{cases}
         \label{perceptron}
    \end{aligned}$$</span><br /></p></li>
<li><p>Given a training example <span class="math inline">(<em>x</em><sup>(<em>i</em>)</sup>, <em>y</em><sup>(<em>i</em>)</sup>)</span>, define the of <span class="math inline">(<em>w</em>, <em>b</em>)</span> w.r.t the training example as <span> </span> where <span class="math inline">$\hat{\gamma}^{(i)} &gt; 0$</span> means prediction is correct.<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a> We can also define with respect to <span class="math inline"><em>S</em> = {(<em>x</em><sup>(<em>i</em>)</sup>, <em>y</em><sup>(<em>i</em>)</sup>):<em>i</em> = 1, …, <em>m</em>}</span> to be the <em>smallest</em> of the individual functional margins: <br /><span class="math display">$$\begin{aligned}
        \hat{\gamma} &amp;= \min_{i=1,\ldots,m} \hat{\gamma}^{(i)}
    \end{aligned}$$</span><br /></p></li>
<li><p>Now we move to . First, consider figure [Hyperplane]<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a></p>
<div class="figure">
<img src="Hyperplane.PNG" alt="Decision boundary" style="width:20.0%" />
<p class="caption">Decision boundary<span data-label="Hyperplane"></span></p>
</div></li>
<li><p>If we consider <span class="math inline"><em>A</em></span> as the <span class="math inline"><em>i</em></span>th data point, what is value of <span class="math inline"><em>γ</em><sup>(<em>i</em>)</sup></span>? The point <span class="math inline"><em>B</em></span> that is closest to <span class="math inline"><em>A</em></span> on the plane is given by <span class="math inline"><em>A</em> − <em>τ</em> ⋅ <em>w</em>/||<em>w</em>||</span> where <span class="math inline"><em>τ</em></span> is the distance <span class="math inline">|<em>A</em><em>B</em>|</span> that we want to solve for. Since <span class="math inline"><em>B</em></span> is on the plane, we can solve for <span class="math inline"><em>τ</em></span> via <br /><span class="math display">$$\begin{aligned}
        0 &amp;= w^T \bigg(x^{(i)} - \tau \frac{w}{||w||} \bigg) + b  \\
        \tau &amp;= \frac{w^T x^{(i)}+ b}{||w||}
    \end{aligned}$$</span><br /> which leads to the general definition for the <strong></strong>, denoted <em>without the hat</em> <span class="math inline"><em>γ</em><sup>(<em>i</em>)</sup></span> as <span> </span> where clearly if <span class="math inline">||<em>w</em>|| = 1</span> is the same as the functional margin. Also can define the geometric over the whole training set similarly as was done for the functional margin.</p></li>
<li><p><span><strong><em></em></strong></span>.</p>
<ul>
<li><p>Pose the following optimization problem <br /><span class="math display">$$\begin{aligned}
            \max_{\gamma, w, b}&amp; ~ \frac{\hat{\gamma}}{||w||} ~~ {\footnotesize{\text{{\textcolor{Maroon}{\textbf{$S.T.$}}}}}} \\
            y^{(i)} \bigg(w^T x^{(i)}+ b\bigg)&amp; \ge \hat{\gamma} 
        \end{aligned}$$</span><br /></p></li>
<li><p>Due to reasons primarily regarding how computing <span class="math inline">||<em>w</em>||</span> is non-convex/hard, we translate the problem as follows: (1) impose (on the <em>functional margin</em><a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a>) constraint that<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a>, <span class="math inline">$\hat{\gamma} = 1$</span> which we can always satisfy with some scaling of <span class="math inline"><em>w</em></span> and <span class="math inline"><em>b</em></span>; (2) Instead of maximizing <span class="math inline">1/||<em>w</em>||</span>, minimize <span class="math inline">||<em>w</em>||<sup>2</sup></span>. <br /><span class="math display">$$\begin{aligned}
            \min_{\gamma, w, b}&amp; ~ {\frac{1}{2}}||w||^2 ~~ {\footnotesize{\text{{\textcolor{Maroon}{\textbf{$S.T.$}}}}}} \\
            y^{(i)} \bigg(w^T x^{(i)}+ b\bigg)&amp; \ge 1
        \end{aligned}$$</span><br /> which gives us the .</p></li>
<li><p>Lot of subtleties: For SVM (at least in this class) we want maximize the margin, which we <strong>define</strong> to be <span class="math inline">2/||<em>w</em>||</span>. Note that this is <em>not</em> a fixed scalar value, it changes as <span class="math inline">||<em>w</em>||</span> changes! The are any points <span class="math inline"><em>x</em><sup>(<em>i</em>)</sup></span> such that <span class="math inline"><em>y</em><sup>(<em>i</em>)</sup>(<em>w</em><sup><em>T</em></sup><em>x</em><sup>(<em>i</em>)</sup> + <em>b</em>)=1</span>.</p></li>
</ul></li>
</ul>
<p><span> </span></p>
<p><strong></strong></p>
<ul>
<li><p>Claim: If <span class="math inline"><em>w</em></span> is a vector that classifies according to perceptron algorithm (equation [perceptron]), then <span class="math inline"><em>w</em></span> is orthogonal to the separating hyperplane.</p></li>
<li><p>Proof: We proceed, using only the definition of a plane, by finding the plane that <span class="math inline"><em>w</em></span> is orthogonal to, and show that this plane must be the separating hyperplane.</p></li>
<li><p>If we plug in <span class="math inline"><em>w</em></span> to the <em>point-normal form</em> of the equation of a plane, <strong>defined</strong> as the plane containing all points <span class="math inline">$\bm{r }= (x, y, z)$</span> such that <span class="math inline"><em>w</em></span> is orthogonal to the <strong>PLANE</strong><a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a> <br /><span class="math display">$$\begin{aligned}
        w_x x + w_y y + w_z z + d &amp;= 0 \\
        \bm{w}^T \bm{r} + d &amp;= 0 \\
    \end{aligned}$$</span><br /> where, denoting <span class="math inline">$\bm{r}_0= (x_0, y_0, z_0)$</span> as the vector pointing to some arbitrary point <span class="math inline"><em>P</em><sub>0</sub></span> in the plane, <br /><span class="math display">$$\begin{aligned}
        d &amp;= -(w_x x_0 + w_y y_0 + w_z z_0 ) \\
        &amp;=  - (\bm{w}^T \bm{r}_0)
    \end{aligned}$$</span><br /> which means that <br /><span class="math display">$$\begin{aligned}
        0 &amp;= \bm{w}^T \bm{r} + d\\
        &amp;= \bm{w}^T \bm{r} - (\bm{w}^T \bm{r}_0)  \\
        &amp;= \bm{w}^T (\bm{r} -  \bm{r}_0)
    \end{aligned}$$</span><br /> QED</p></li>
</ul>
<h2 id="spring-2016-midterm">Spring 2016 Midterm</h2>
<ul>
<li><p>Hard-margin SVM and perceptron will <em>not</em> return a classifier if data not linearly separable.</p></li>
<li><p>Soft-margin SVM uses <span class="math inline"><em>y</em><sub><em>i</em></sub>(<em>X</em><sub><em>i</em></sub> ⋅ <em>w</em> + <em>α</em>)≥1 − <em>ξ</em><sub><em>i</em></sub></span>, so <span class="math inline"><em>ξ</em><sub><em>i</em></sub> ≠ 0</span> for both (1) misclassified samples and (2) all samples inside the margin.</p></li>
<li><p><em>Large</em> value of C in (Soft-margin SVM) <span class="math inline">|<em>w</em>|<sup>2</sup> + <em>C</em>∑<em>ξ</em><sub><em>i</em></sub></span> is prone to <strong>overfitting training</strong> data. Interp: Large C means we want most <span class="math inline"><em>ξ</em><sub><em>i</em></sub> → 0</span> or small, and therefore the <strong>decision boundary will be sinuous</strong>, something we currently don’t know how to do.</p></li>
<li><p>classifies to the most probable class, using the conditional (discrete) distribution <span class="math inline"><em>P</em>(<em>G</em>|<em>X</em>)</span>. <br /><span class="math display">$$\begin{aligned}
        \hat{G}(x) = \operatorname*{arg\,max}_{g\in G} Pr(g | X = x)
    \end{aligned}$$</span><br /></p></li>
<li><p><span class="math inline"><em>Σ</em><sup>1/2</sup> = <em>U</em><em>Λ</em><sup>1/2</sup><em>U</em><sup><em>T</em></sup></span>.</p></li>
</ul>
<h2 id="multivariate-gaussians">Multivariate Gaussians</h2>
<ul>
<li><p>The covariance matrix <span class="math inline"><em>Σ</em> ∈ <strong>S</strong><sub>+</sub><sup><em>n</em></sup>+</span>, the space of all symmetric, positive definite <span class="math inline"><em>n</em><em>x</em><em>n</em></span> matrices.</p></li>
<li><p>Due to this, and since the inverse of any pos. def matrix is also pos. def, we can say that, for all <span class="math inline"><em>x</em> ≠ <em>μ</em></span>: <br /><span class="math display">$$\begin{aligned}
        -{\frac{1}{2}}(x - \mu)^T \Sigma^{-1} (x - \mu) &lt; 0
    \end{aligned}$$</span><br /></p></li>
<li><p><span> <em></em></span><em>For any random vector X with mean <span class="math inline"><em>μ</em></span> and covariance matrix <span class="math inline"><em>Σ</em></span></em> <a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> <span> </span></p></li>
<li><p><span> <em></em></span><em>The covariance matrix <span class="math inline"><em>Σ</em></span> of any random vector <span class="math inline"><em>X</em></span> is symmetric positive semidefinite.</em></p>
<ul>
<li><p>In the particular case of <em>Gaussians</em>, which require existence of <span class="math inline"><em>Σ</em><sup>−1</sup></span>, we also have that <span class="math inline"><em>Σ</em></span> is then full rank. “Since any full rank symmetric positive semidefinite matrix is necessarily symmetric positive definite, it follows that <span class="math inline"><em>Σ</em></span> must be <strong>symmetric positive definite</strong>.</p></li>
</ul></li>
<li><p>The <span style="font-variant: small-caps;">diagonal covariance matrix</span> case. An <span class="math inline"><em>n</em></span>-dimensional Gaussian with mean <span class="math inline"><em>μ</em> ∈ ℝ<sup><em>n</em></sup></span> and diagonal <span class="math inline"><em>Σ</em> = diag(<em>σ</em><sub>1</sub><sup>2</sup>,  <em>σ</em><sub>2</sub><sup>2</sup>, …, <em>σ</em><sub><em>n</em></sub><sup>2</sup>)</span> is the same as <span class="math inline"><em>n</em></span> independent Gaussian random variables with mean <span class="math inline"><em>μ</em><sub><em>i</em></sub></span> and <span class="math inline"><em>σ</em><sub><em>i</em></sub><sup>2</sup></span>, respectively. (i.e. <span class="math inline"><em>P</em>(<em>X</em>)=<em>P</em>(<em>x</em><sub>1</sub>)⋅<em>P</em>(<em>x</em><sub>2</sub>)⋯<em>P</em>(<em>x</em><sub><em>n</em></sub>)</span> where each <span class="math inline"><em>P</em>(<em>x</em><sub><em>i</em></sub>)</span> is a univariate Gaussian PDF.</p></li>
<li><p>. General intuitions listed below<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a></p>
<ul>
<li><p>For random vector <span class="math inline"><em>X</em> ∈ ℝ<sup>2</sup></span> with <span class="math inline"><em>μ</em> ∈ ℝ<sup>2</sup></span>, isocontours are <strong>ellipses</strong> centered on <span class="math inline">(<em>μ</em><sub>1</sub>, <em>μ</em><sub>2</sub>)</span>.</p></li>
<li><p><em>If</em> <span class="math inline"><em>Σ</em></span> diagonal, then principal axes lie along <span class="math inline"><em>x</em></span> and <span class="math inline"><em>y</em></span> axis. Otherwise, in more general case, they are along the covariance eigenvects. (right?)</p></li>
</ul></li>
<li><p><span> <em></em></span><em>Let <span class="math inline"><em>X</em> ∼ 𝒩(<em>μ</em>, <em>Σ</em>)</span> for some <span class="math inline"><em>μ</em> ∈ ℝ<sup><em>n</em></sup></span> and <span class="math inline"><em>Σ</em> ∈ <strong>S</strong><sub>++</sub><sup><em>n</em></sup></span>. Then there exists a matrix <span class="math inline"><em>B</em> ∈ ℝ<sup><em>n</em><em>x</em><em>n</em></sup></span> such that if we define <span class="math inline"><em>Z</em> = <em>B</em><sup>−1</sup>(<em>X</em> − <em>μ</em>)</span>, then <span class="math inline"><em>Z</em> ∼ 𝒩(0, <em>I</em>)</span>.</em></p></li>
</ul>
<h2 id="misc.-facts">Misc. Facts</h2>
<ul>
<li><p>The sum of absolute residuals is less sensitive to outliers than the residual sum of squares. [Todo: study the flaws of least-squares regression.]</p></li>
<li><p>In LDA, the discriminant functions <span class="math inline"><em>δ</em><sub><em>k</em></sub>(<em>x</em>)</span> are an <em>equivalent</em> description of the decision rule, classifying as <span class="math inline">$G(x) = \operatorname*{arg\,max}_k \delta_k(x)$</span>, where (for LDA), <br /><span class="math display">$$\begin{aligned}
        \delta_k(x) = x^T \Sigma^{-1} \mu_k - {\frac{1}{2}}\mu_k^T \Sigma^{-1} \mu_k + \log\pi_k
    \end{aligned}$$</span><br /></p></li>
<li><p>Large value of <span class="math inline"><em>C</em></span> in soft-margin SVM objective function <span class="math inline">|<em>w</em>|<sup>2</sup> + <em>C</em>∑<em>ξ</em><sub><em>i</em></sub></span> is likely to <strong>overfit</strong> training data. This is because it will drive the <span class="math inline"><em>ξ</em><sub><em>i</em></sub></span> very low/zero, which means <em>it constructed a (likely nonlinear) decision boundary such that most points were either on or outside the margin</em>. The key here is that changing the <span class="math inline"><em>ξ</em><sub><em>i</em></sub></span> associated with points doesn’t mean you’re ignoring them or something, it means you are manipulating the decision boundary to more closely resemble your training distribution.</p></li>
<li><p>Can’t believe this is necessary, but remember that the sum in the following denominator is over <span class="math inline"><em>y</em></span> (not <span class="math inline"><em>x</em></span>): <br /><span class="math display">$$\begin{aligned}
        P(Y=y_i | X = x_i) = \dfrac{f_i(x_i) \pi_i}{\sum_{y_j \in Y} f_j(x_i) \pi_j}
    \end{aligned}$$</span><br /> If binary class classification, decision boundary is at <span class="math inline"><em>x</em> = <em>x</em>*</span> where <span class="math inline">$P(Y=1|x*) = P(Y=0|x*) = {\frac{1}{2}}$</span>. If logistic regression, this occurs when the argument <span class="math inline"><em>h</em>(<em>x</em> * )</span> to the exponential in denominator is <span class="math inline">exp(<em>h</em>(<em>x</em> * ))=exp(0)=1</span>. So, to find the values of <span class="math inline"><em>x</em></span> along decision boundary, in this particular case, you’d solve <span class="math inline"><em>h</em>(<em>x</em>)=0</span>.</p></li>
<li><p>Ok. First, never forget that <br /><span class="math display">$$\begin{aligned}
         1 = \int_{x\in X|Y_i} f_{X|Y=Y_i} (x) dx
    \end{aligned}$$</span><br /> and, therefore, if you’re told that <span class="math inline"><em>x</em><sub><em>n</em></sub></span> sampled</p>
<blockquote>
<p>iid and uniformly at random from 2 equiprobable classes, a disk of radius 1 (Y = +1) and a ring from 1 to 2 (Y = -1)</p>
</blockquote>
<p>then you should be able to see why (hint: the equation I just wrote) <span class="math inline"><em>f</em><sub><em>x</em>|<em>Y</em> = +1</sub> = 1/<em>π</em></span> for <span class="math inline">||<em>X</em>|| ≤ 1</span> and <span class="math inline"><em>f</em><sub><em>x</em>|<em>Y</em> = −1</sub> = 1/3<em>π</em></span> for <span class="math inline">1 ≤ ||<em>X</em>|| ≤ 2</span>. The fact that they are equiprobable mean <span class="math inline">$f_{Y} (Y = +1) =  f_{Y} (Y = -1) = {\frac{1}{2}}$</span> which means you can write the density of <span class="math inline"><em>X</em></span>, <span class="math inline"><em>f</em><sub><em>X</em></sub></span>.</p></li>
</ul>
<p>[ESL]</p>
<ul>
<li><p>Assumption: The <span class="math inline">𝔼[<em>Y</em>|<em>X</em>]</span> is linear<a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a> in the inputs <span class="math inline"><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>p</em></sub></span>.</p></li>
<li><p>Perform well for</p>
<ul>
<li><p>Small numbers of training cases.</p></li>
<li><p>Low signal/noise.</p></li>
<li><p>Sparse data.</p></li>
</ul></li>
</ul>
<h3 id="models-and-least-squares">Models and Least-Squares</h3>
<ul>
<li><p>The : <br /><span class="math display">$$\begin{aligned}
        f(X) &amp;= \beta_0 + {\sum_{j=1}^{p}}X_j \beta_j {\tag{3.1}\label{3.1}}
    \end{aligned}$$</span><br /></p></li>
<li><p>Most popular is least-squares. <br /><span class="math display">$$\begin{aligned}
        RSS(\beta) &amp;= {\sum_{i=1}^{n}}\big(y_i - f(x_i)\big)^2 {\tag{3.2}\label{3.2}} \\
        &amp;= (\bm{y} - \bm{X}\beta)^T  (\bm{y} - \bm{X}\beta)^T {\tag{3.3}\label{3.3}}
    \end{aligned}$$</span><br /> which is reasonable if training observations <span class="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span> represent independent random draws from their population<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a>.</p></li>
<li><p>First two derivatives wrt to parameter vector <span class="math inline"><em>β</em></span>: <br /><span class="math display">$$\begin{aligned}
    \begin{split}
        {\frac{\partial RSS}{\partial \beta}} &amp;= -2\bm{X}^T(\bm{y}-\bm{X}\beta) \\
        \frac{\partial^2 RSS}{\partial\beta\partial\beta^T}&amp;= 2\bm{X}^T \bm{X}
    \end{split}
        {\tag{3.4}\label{3.4}}
    \end{aligned}$$</span><br /></p></li>
<li><p>Assuming that <span class="math inline"><strong>X</strong></span> has full column rank so that <span class="math inline"><strong>X</strong><sup><em>T</em></sup><strong>X</strong></span> is positive definite<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a>, set first derive to 0 to obtain the unique solution:</p></li>
<li><p><span style="font-variant: small-caps;">i get it now!</span></p>
<ul>
<li><p>The <span class="math inline">(<em>p</em> + 1)</span> column vectors of <span class="math inline"><strong>X</strong></span> span a subspace of <span class="math inline">ℝ<sup><em>N</em></sup></span>.<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a>.</p></li>
<li><p>Minimizing <span class="math inline"><em>R</em><em>S</em><em>S</em>(<em>β</em>)=||<strong>y</strong> − <strong>X</strong><em>β</em>||<sup>2</sup></span> is choosing <span class="math inline">$\hat{\beta}$</span> such that the <span class="math inline">${\mathbf{y}}- \hat{{\mathbf{y}}}$</span> is orthogonal to this subspace<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a>. Stated another way, (the optimal) <span class="math inline">$\hat{y}$</span> is the <em>orthogonal projection of <span class="math inline"><strong>y</strong></span> onto the column space of <span class="math inline"><em>X</em></span></em>.</p></li>
<li><p>Since <span class="math inline">${\hat{\mathbf{y}}}= {\mathbf{X}}{\hat{\beta}}$</span>, we can define this projection matrix (aka hat matrix), denoted as <span class="math inline"><strong>H</strong></span>, where <br /><span class="math display">$$\begin{aligned}
        \begin{split}
            {\hat{\mathbf{y}}}&amp;= {\mathbf{X}}{\hat{\beta}}\\
            &amp;= {\mathbf{X}}({\mathbf{X}}^T{\mathbf{X}})^{-1}{\mathbf{X}}^T{\mathbf{y}}\\
            &amp;= {\mathbf{H}}{\mathbf{y}}\end{split}
        {\tag{3.7}\label{3.7}}
        \end{aligned}$$</span><br /></p></li>
</ul></li>
</ul>
<p><span> </span><span><strong><em></em></strong></span></p>
<ul>
<li><p>Note: <span class="math inline">≡</span> Covariance matrix.</p></li>
<li><p>Can express the in terms of the covariance matrix: <br /><span class="math display">$$\begin{aligned}
        corr({\mathbf{X}}) &amp;= \big( diag(\Sigma)\big)^{-1/2}  \Sigma \big( diag(\Sigma)\big)^{-1/2}
    \end{aligned}$$</span><br /> or, equivalently, the correlation matrix can be seen as the covariance matrix of the standardized random variables <span class="math inline"><em>X</em><sub><em>i</em></sub>/<em>σ</em>(<em>X</em><sub><em>i</em></sub>)</span>.</p></li>
<li><p>Recall from decision theory that, when we want find a function <span class="math inline"><em>f</em>(<em>X</em>)</span> for predicting some <span class="math inline"><em>Y</em> ∈ ℝ</span>, we can do this by <em>minimizing the risk</em> (aka the expected prediction error EPE(f)). This is accomplished first by defining a loss function. Here we will use the squared error loss <span class="math inline"><em>L</em>(<em>Y</em>, <em>f</em>(<em>X</em>)) = (<em>Y</em> − <em>f</em>(<em>X</em>))<sup>2</sup></span>. We can express <span class="math inline"><em>E</em><em>P</em><em>E</em>(<em>f</em>)</span> as an integral over all values that <span class="math inline"><em>Y</em></span> and <span class="math inline"><em>X</em></span> may take on (i.e. the joint distribution). Therefore, we can factor the joint distribution and define <span class="math inline"><em>f</em>(<em>x</em>)</span> via minimizing EPE piecewise (meaning at each value of <span class="math inline"><em>X</em> = <em>x</em></span>.) This whole description is written mathematically below. <br /><span class="math display">$$\begin{aligned}
        EPE(f) &amp;= {\mathbb{E}[Y - f(X)]}^2 {\tag{2.9}\label{2.9}} \\
        &amp;= \int \big[y - f(x) \big]^2 f_{XY}(x, y) dx dy {\tag{2.10}\label{2.10}} \\
        &amp;= \mathbb{E}_X\Big[    \mathbb{E}_{Y|X} \bigg[  (Y - f(X))^2 | X \bigg]     \Big] {\tag{2.11}\label{2.11}}
    \end{aligned}$$</span><br /> and therefore, the best predictor of <span class="math inline"><em>Y</em></span> is a function <span class="math inline"><em>f</em> : ℝ<sup><em>p</em></sup> → ℝ</span> that satisfies, for each <span class="math inline"><em>x</em></span> value separately <br /><span class="math display">$$\begin{aligned}
        f(x) &amp;= \operatorname*{arg\,min}_{c} \mathbb{E}_{Y|X}  \bigg[  (Y - c)^2 | X \bigg] {\tag{2.12}\label{2.12}} \\
        &amp;= {\mathbb{E}[Y | X = x]} {\tag{2.13}\label{2.13}}
    \end{aligned}$$</span><br /> which essentially defines what is meant by <span class="math inline">𝔼[<em>Y</em>|<em>X</em> = <em>x</em>]</span>, also referred to as the <a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a>.</p>
<p>[Bias-Variance Tradeoff]The expected test MSE, for a given value <span class="math inline"><em>x</em><sub>0</sub></span>, can always be decomposed into the sum of three fundamental quantities: <br /><span class="math display">$$\begin{aligned}
            {\mathbb{E}[y_0 - \hat{f}(x_0)]}^2 = Var\big( \hat{f}(x_0) \big) 
            + \big[ Bias(\hat{f}(x_0)) \big]^2
            + Var(\epsilon)
        \end{aligned}$$</span><br /> which is interpreted as the <em>expected test MSE</em>: the average test MSE that we would obtain if we repeatedly estimated <span class="math inline"><em>f</em></span> using a large number of training sets, and <em>tested each at <span class="math inline"><em>x</em><sub>0</sub></span></em>. The <strong>overall test MSE</strong> can be computing the average (of this average) over all possible values of <span class="math inline"><em>x</em><sub>0</sub></span> in the TEST set.</p></li>
<li><p>What means here:</p>
<p>On the other hand, bias refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model. For example, linear regression assumes that there is a linear relationship between Y and <span class="math inline"><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>p</em></sub></span>. It is unlikely that any real-life problem truly has such a simple linear relationship, and so performing linear regression will undoubtedly result in some bias in the estimate of f. In Figure 2.11, the true f is substantially non-linear, so no matter how many training observations we are given, it will not be possible to produce an accurate estimate using linear regression. In other words, linear regression results in high bias in this example. However, in Figure 2.10 the true f is very close to linear, and so given enough data, it should be possible for linear regression to produce an accurate estimate. Generally, more flexible methods result in less bias.</p></li>
<li><p>Returning now to the case where know (aka assume) that the true relationship between <span class="math inline"><em>X</em></span> and <span class="math inline"><em>Y</em></span> is linear <br /><span class="math display">$$\begin{aligned}
        Y = X^T \beta + \epsilon {\tag{2.26}\label{2.26}}
    \end{aligned}$$</span><br /> and so <em>in this particular case</em> the least squares estimates are <em>unbiased</em>.</p></li>
<li><p>oh my fucking god. This is the proof: (relies on the fact that <span class="math inline"><em>V</em><em>a</em><em>r</em>(<em>β</em>)=0</span> since <span class="math inline"><em>β</em></span> is the <em>true</em> (NON RANDOM) vector we are estimating)<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a> <br /><span class="math display">$$\begin{aligned}
        Var[\hat{\beta}] &amp;= Var\bigg[ ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T {\mathbf{y}}\bigg] \\
        &amp;= Var\bigg[ ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T \big( {\mathbf{X}}\beta + \epsilon  \big)   \bigg] \\
        &amp;= Var\bigg[ ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T  {\mathbf{X}}\beta +  ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T \epsilon      \bigg] \\
        &amp;= Var\bigg[ \beta +  ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T \epsilon      \bigg] \\
        &amp;= Var\bigg[ ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T \epsilon   \bigg] \\
        &amp;= \mathbb{E}\Big[  \bigg(  ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T \epsilon    \bigg) \bigg(   ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T \epsilon \bigg)^T   \Big] \\
        &amp;=  \bigg(  ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T  \bigg)  ~ {\mathbb{E}[\epsilon\epsilon^T]} ~ \bigg( {\mathbf{X}}({\mathbf{X}}^T {\mathbf{X}})^{-1}   \bigg) \\
        &amp;=  \bigg(  ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T  \bigg)  ~ \sigma^2 ~ \bigg( {\mathbf{X}}({\mathbf{X}}^T {\mathbf{X}})^{-1}   \bigg)  \\
        &amp;= \sigma^2 \bigg(  ({\mathbf{X}}^T {\mathbf{X}})^{-1} {\mathbf{X}}^T  \bigg)  \bigg( {\mathbf{X}}({\mathbf{X}}^T {\mathbf{X}})^{-1}   \bigg)  \\
        &amp;= \sigma^2     ({\mathbf{X}}^T {\mathbf{X}})^{-1}
    \end{aligned}$$</span><br /> where we have assumed that the <span class="math inline"><em>X</em></span> are FIXED (not random)<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a> and so the variance of (some product of <span class="math inline"><em>X</em></span>s) <span class="math inline">×</span> <span class="math inline"><em>ϵ</em></span> is like taking the variance with a constant out front. We’ve also assumed that <span class="math inline"><em>X</em><sup><em>T</em></sup><em>X</em></span> (and thus its inverse too) is symmetric, apparently.</p></li>
</ul>
<h3 id="subset-selection-3.3">Subset Selection (3.3)</h3>
<ul>
<li><p>Two reasons why we might not be satisfied with  [3.6]:</p>
<ol>
<li><p>Prediction accuracy. Often have low bias, high variance. May improve if shrink coefficients. Sacrifices some bias to reduce variance.</p></li>
<li><p>Interpretation. Sacrifices some of the small details.</p></li>
</ol></li>
<li><p>Appears that subset selection refers to retaining a subset of the <em>predictors</em> <span class="math inline">${\hat{\beta}}_i$</span> and discarding the rest.</p></li>
<li><p>Doing this can often exhibit high variance, even if lower prediction error.</p></li>
</ul>
<h3 id="shrinkage-methods-3.4">Shrinkage Methods (3.4)</h3>
<ul>
<li><p>Shrinkage methods are considered <em>continuous</em> (as opposed to subset selection) and don’t suffer as much from high variability.</p></li>
</ul>
<p><span> </span>Appropriate when dimension <span class="math inline"><em>p</em></span> of feature space is large. It assume that given a class <span class="math inline"><em>G</em> = <em>j</em></span>, the features <span class="math inline"><em>X</em><sub><em>k</em></sub></span> are independent: <br /><span class="math display">$$\begin{aligned}
    f_j(X) \equiv f_j((X_1, X_2, \ldots, X_p)^T) = \prod_{k = 1}^{p} f_{jk}(X_k)\end{aligned}$$</span><br /> which can simplify estimation [of the class-conditional probability densities <span class="math inline"><em>f</em><sub><em>j</em></sub>(<em>X</em>)</span>] dramatically: The individual class-conditional marginal densities <span class="math inline"><em>f</em><sub><em>j</em><em>k</em></sub></span> can each be estimated <em>separately</em> using 1D kernel density estimates.</p>
<p>[Neural Computation]</p>
<ul>
<li><p>Perceptron review for the plebs.</p></li>
<li><p>XOR problem not linearly separable.</p></li>
<li><p>Learning rules for two-layer network:</p>
<ul>
<li><p><span class="math inline">$E^{(\alpha)} = \frac{1}{2} \sum_i [ T_i^\alpha - z_i (x^{\alpha})]^2$</span>.</p></li>
<li><p><span class="math inline">$\Delta V_{ij} = \big[ [T_i - z_i(x) ]\big] \frac{\partial z_i}{\partial V_{ij}} = \delta_{ij} y_j$</span>.</p></li>
<li><p>That was outer layer. For hidden layer: <br /><span class="math display">$$\Delta W_{kl} =  \eta \sum_i [ T_i - z_i(x) ]\frac{\partial z_i}{\partial W_{kl}}$$</span><br /></p></li>
<li><p>Chain rule the fuck outta ur shit</p></li>
</ul></li>
<li><p>:</p>
<ul>
<li><p><span class="math inline">$E(w_0 + \Delta w) \approx E(w_0) + \Delta w^T \nabla E + \frac{1}{2} \Delta w^T H \Delta w$</span>.</p></li>
<li><p>Minimized when <span class="math inline">∇<em>E</em> + <em>H</em><em>Δ</em><em>w</em> = 0</span>, thus <span class="math inline"><em>Δ</em><em>w</em> * = − <em>H</em><sup>−1</sup>∇<em>E</em></span>. Hessian, rather than approximating function as a line (like the gradient), approximates as a quadratic function.</p></li>
<li><p>is kinda second order. <br /><span class="math display">$$\begin{aligned}
        \Delta w_{kl} (t + 1) &amp;= - \eta \frac{\partial E}{\partial w_{kl}} + \alpha \Delta w_{kl}(t) \\
        \Delta w_{kl} \approx - \frac{\eta}{d\text{fuck}en}
        \end{aligned}$$</span><br /></p></li>
</ul></li>
</ul>
<ul>
<li><p>Competitive Learning (what follows is unrelated)</p>
<ul>
<li><p>Most real data non-Gaussian. (bad for PCA/Hebbian).</p></li>
<li><p>Try . <br /><span class="math display">$$\begin{aligned}
        \Delta w_i &amp;\propto y x_i \\
        &amp;= f\bigg( \sum_j w_j x_j\bigg) x_i
        \end{aligned}$$</span><br /> where we can expand <span class="math inline"><em>f</em></span> in a taylor series.</p></li>
</ul></li>
<li><p>Winner-take-all learning.</p>
<ul>
<li><p>output neurons are connected to each other. fighting it out. <br /><span class="math display">$$\begin{aligned}
        y_i = 
        \begin{cases}
        1 &amp; u_i &gt; u_j \forall j \ne i \\
        0 &amp; \text{otherwise}
        \end{cases}
        \end{aligned}$$</span><br /> where <span class="math inline"><em>u</em></span> are standard weighted sum of inputs.</p></li>
<li><p>Learning rule: <br /><span class="math display">$$\begin{aligned}
        \Delta w_{ij} = \eta y_i (x_j - w_{ij})
        \end{aligned}$$</span><br /> where, if <span class="math inline"><em>y</em><sub><em>i</em></sub></span> wins, moves towards vector <span class="math inline"><em>x</em><sub><em>j</em></sub></span>.</p></li>
<li><p>Visually, weight vectors shift to align with clusters in data.</p></li>
<li><p>weight vector with highest inner product wins competition, and is therefore the one that moves toward the given data point (where each output has an associated weight vector).</p></li>
<li><p>Algorithm <span class="math inline">≡</span> K-means.</p></li>
<li><p>energy function: <br /><span class="math display">$$\begin{aligned}
        E(\{w_i\}) &amp;= \frac{1}{2} \sum_{i,\mu} M_i^\mu |x^{(\mu)} - w_i|^2 \\
        \Delta w_i &amp;= \eta \sum_{\mu} M_i^\mu (x^\mu - w_i)
        \end{aligned}$$</span><br /></p></li>
</ul></li>
<li><ul>
<li><p>Allow multiple units to be active.</p></li>
<li><p>Barlow paper in 1972 is genesis of the idea.</p></li>
<li><p>Sensory system is organized to achieve as complete a representation of the sensory stimulus as possible w/min number of active neurons. i.e. minimize number of neurons <span class="math inline"><em>k</em></span> constrained by wanting to preserve max amount of information as possible about the input.</p></li>
<li><p>Adapt the coding strategy to the data structure.</p></li>
<li><p>is in the middle of <em>local codes</em> (grandmother cells) and <em>dense codes</em> (e.g. ascii). i.e. in the middle of easy-to-read-out and maximum-combinatorial capacity.</p></li>
</ul></li>
<li><p>Autoencoder networks. <br /><span class="math display">$$\begin{aligned}
    \min_{W, M} |x - \hat{x} |^2
    \end{aligned}$$</span><br /> Want to train output <span class="math inline">$\hat{x}$</span> to be same as input <span class="math inline"><em>x</em></span>, where data is passed through some bottleneck <span class="math inline"><em>y</em></span> bridged by <span class="math inline"><em>W</em></span> and <span class="math inline"><em>M</em></span> from input-&gt;middle-&gt;out. Idea is to exploit correlations in the input so that can pass through smaller space while preserving most of the information, and then passed back to the original (larger) space with a more sparse encoding. Basically is a compression algorithm. Also, see ’retinal bottleneck.’</p></li>
<li><p>Bottleneck may have same number of units but with lower capacity (e.g. less bits per neuron).</p></li>
<li><p><strong>sparse code bottleneck</strong> limits the number of active units. i.e. middle space may in fact be much larger, but only allowed to use a subset of it when mapping <span class="math inline">$x \rightarrow \hat{x}$</span>.</p></li>
</ul>
<ul>
<li><p>VI simple-cell receptive fields are localized, oriented, and bandpass.</p></li>
<li><p>PCA is really bad for such situations.</p></li>
<li><p>To detect sharp edges in images, need high frequency and in-phase combinations.</p></li>
<li><p>Higher-order image statistics:</p>
<ul>
<li><p>phase alignment</p></li>
<li><p>orientation</p></li>
<li><p>motion</p></li>
</ul></li>
<li><p>want to move beyond pairwise correlations.</p></li>
<li><p>WTA is too greedy, want more distributed strategy.</p></li>
<li><p>Idea: .</p>
<ul>
<li><p>Look for low-dimensional projections that are as non-Gaussian as possible.</p></li>
<li><p>Projections tend to result in Gaussian distributions by the C.L.T.</p></li>
<li><p>Want to explore projections onto a weight vector until find something Non-Gaussian. Why? Because such a distribution <em>could not have happened by accident</em>.</p></li>
</ul></li>
<li><p>response histograms are highly non-Gaussian.</p></li>
<li><p>(Lab-related) Paper on <em>Forming sparse representations by local anti-Hebbain learning.</em></p>
<ul>
<li><p>Each neuron takes weighted input sum, as well as getting lateral inhibitaion by neighbors, but where the lateral weights are all negative. Put all through <span class="math inline"><em>f</em></span>, some sigmoidal non-linearity. ”leaky integrator”</p></li>
<li><p>Want population-sparcity, so need neurons decorrelated. Have three learning rules: anti-Hebbian, Hebbian, and threshold modification.</p></li>
<li><p>Threshold modification resembles homeostasis. <br /><span class="math display"><em>Δ</em><em>t</em><sub><em>i</em></sub> = <em>γ</em>(<em>y</em><sub><em>i</em></sub> − <em>p</em>)</span><br /> which is essentially SGD. Think about average behavior, as it relates to <span class="math inline"><em>y</em><sub><em>i</em></sub></span> output and <span class="math inline"><em>p</em></span>. <span class="math inline"><em>p</em></span> is a constant to be determined. Feedback loop. Adjusts spiking threshold.</p></li>
<li><p>Anti-hebb guarantees neurons are decorrelated. <br /><span class="math display">$$\begin{aligned}
            \Delta w_{ij} = \alpha (y_i y_j - p^2)
        \end{aligned}$$</span><br /> where <span class="math inline"><em>p</em><sup>2</sup></span> because this is what we would expected if <span class="math inline"><em>i</em></span> and <span class="math inline"><em>j</em></span> were decorrelated. There more coactive two neurons are, the more this drives them to repulse one another.</p></li>
<li><p>Standard hebbian rule <br /><span class="math display">$$\begin{aligned}
            \Delta q_{ij} = \beta y_i (x_j - q_{ij})
        \end{aligned}$$</span><br /> relates to sparsity fraction of neurons.</p></li>
</ul></li>
<li><p>Problems:</p>
<ul>
<li><p>Don’t know how to deal with graded (i.e. non-binary) input signals. Non-discrete stuff.</p></li>
<li><p>No objective function. Would like way to characterize how well system is performing.</p></li>
</ul></li>
<li><p>Led to Bruno’s work:</p>
<ul>
<li><p>Data described by <br /><span class="math display">$$\begin{aligned}
            I(x, y) &amp;= \sum_i a_i ~ \phi_i(x, y) + \epsilon(x, y)
        \end{aligned}$$</span><br /></p></li>
<li><p>basis decomposition of input. neuron i with activity <span class="math inline"><em>a</em><sub><em>i</em></sub></span> means that need feature functions <span class="math inline"><em>ϕ</em></span> to describe model. Want the .</p></li>
<li><p>Constrain sparseness of <span class="math inline"><em>a</em><sub><em>i</em></sub></span> by imposing cost function on the activity: <br /><span class="math display">$$\begin{aligned}
            E = \frac{1}{2} | I - \Phi a|^2 + \lambda \sum_i C(a_i)
        \end{aligned}$$</span><br /> where first term: preserve information and second term: I want to be sparse.</p></li>
<li><p>Penalty function C shaped like really steep parabola on zero. Or could do <span class="math inline"><em>C</em> = |<em>a</em><sub><em>i</em></sub>|</span>, v-shaped thing.</p></li>
<li><p>Energy function determines dynamics of system. Want neuron activity to be expressible as a function of the input <span class="math inline"><em>I</em></span>.</p></li>
<li><p>Compute coefficients <span class="math inline"><em>a</em><sub><em>i</em></sub></span> by gradient descent. <br /><span class="math display">$$\begin{aligned}
            \tau \dot{a_i} = - \frac{dE}{da_i}
        \end{aligned}$$</span><br /></p></li>
<li><p>Neuron i inhibited by neuron j proportioanl to their functions <span class="math inline"><em>p</em><em>h</em><em>i</em></span> inner products.</p></li>
<li><p>self-inhibition of neuron back on itself makes it sparse.</p></li>
<li><p>Learning rule: <br /><span class="math display">$$\begin{aligned}
            \Delta \phi_i &amp;= -\eta \frac{\partial E}{\partial \phi_i} \\
            &amp;= \big[I - \Phi \hat{a} \big] \hat{a_i}
        \end{aligned}$$</span><br /></p></li>
</ul></li>
</ul>
<ul>
<li><p>Abstract: A layer of simple Hebbian units connected by modifiable anti-Hebbian feed-back connections can learn to code a set of patterns in such a way that statistical dependency between the elements of the representation is reduced, while information is preserved.</p></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Input-space that is our surrounding is enormous, but most inputs are highly correlated, which the brain may exploit to transform the high-dimensional pattern inputs to symbolic representations. Objects may be defined as conjunctions of highly correlated sets of components that are relatively independent of other such conjunctions<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a></p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>The complexity of the mapping to be learnt <span class="math inline">⇐</span> complexity of the input.</p></li>
<li><p>Unsupervised learning exploits statistical regularities in input to learn a more meaningful symbolic representation.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Simple model of cell (basically perceptron) <br /><span class="math display">$$\begin{aligned}
            y = 
            \begin{cases}
                1 &amp; \sum_j w_j x_j &gt; \text{thresh} \\
                0 &amp; \text{otherwise}
            \end{cases}
        \end{aligned}$$</span><br /></p></li>
<li><p>Can be thought of as pattern matching; <span class="math inline"><em>y</em></span> is maximal when weight vector = input vector pattern.</p></li>
<li><p>Hebb proposed: connection should become stronger if the two units being connected are active simultaneously: <span class="math inline"><em>Δ</em><em>w</em><sub><em>j</em></sub> = <em>x</em><sub><em>j</em></sub><em>y</em></span>.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Out of the units receiving weighted sums of the input, only activate the unit with the <em>largest</em> weighted sum; suppress the output of all others.</p></li>
<li><p>Results in a local, ”” representation.</p></li>
<li><p>Limited in number of different inputs it can discriminate, and in ability to generalize.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Distributed coding: instead, code each input state by a <em>set</em> of active units (rather than just one).</p></li>
<li><p>Pros: combinatorics of input states increases representational capacity. Cons: situations where many units are active per input pattern, and fact that learning can be extremely slow.</p></li>
<li><p>is a compromise between distributed and local representations.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Units <em>within</em> a layer are connected by modifiable <em>inhibitory</em> weights, governed by an : if two units in same layer are active, connection becomes more inhibitory<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a>.</p></li>
</ul></li>
</ul>
<h3 id="unsupervised-learning">Unsupervised Learning</h3>
<ul>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>First, let’s get this straight. Difference between and : <br /><span class="math display">$$\begin{aligned}
            \textsc{{\textcolor{Maroon}{\textbf{COV}}}}[X, Y] &amp;\triangleq {\mathbb{E}[(X-\mu_X)(Y-\mu_Y)]} \\
            \textsc{{\textcolor{Maroon}{\textbf{CORR}}}}[X, Y] \equiv \rho_{XY} &amp;\triangleq \dfrac{Cov[X, Y]}{\sigma_X~\sigma_Y}{\tag{corr}\label{corr}}
        \end{aligned}$$</span><br /></p></li>
<li><p>Consider input stream <span class="math inline"><strong>x</strong></span> that has linear pairwise correlations<a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a> among its elements. Mathematically, correlation between elements <span class="math inline"><em>x</em><sub><em>i</em></sub></span> and <span class="math inline"><em>x</em><sub><em>j</em></sub></span> would imply that <br /><span class="math display">$$\begin{aligned}
            {\langlex_i x_j\rangle} = {\frac{{\mathbb{E}[x_i x_j]}}{ \sqrt{{\mathbb{E}[x_i]} {\mathbb{E}[x_j]} } } } \ne 0
        \end{aligned}$$</span><br /> or, equivalently, that <span class="math inline">𝔼[<em>x</em><sub><em>i</em></sub><em>x</em><sub><em>j</em></sub>] ≠ 𝔼[<em>x</em><sub><em>i</em></sub>]𝔼[<em>x</em><sub><em>j</em></sub>] = 0</span>. Bruno is correct that linear pairwise correlations imply that <span class="math inline"><em>c</em><sub><em>i</em><em>j</em></sub> ≠ 0</span>, he is <em>absolutely incorrect</em> to say that <span class="math inline"><em>c</em><sub><em>i</em><em>j</em></sub></span> is an “average over many examples.” That is nothing more than academic sloppiness at its finest.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Goal: Find a set of <span class="math inline"><em>M</em></span> orthogonal vectors in data space that account for as much as possible of the data’s variance. Projecting the data from original <span class="math inline"><em>N</em></span>-dimensional space onto the <span class="math inline"><em>M</em></span>-dimensional subspace spanned by these vectors then performs a <strong>dimensionality reduction</strong>.</p></li>
<li><p>HKP actually states accurately what Bruno meant to state: The <span class="math inline"><em>k</em></span>th principal component direction is along an eigenvector direction belonging to the <span class="math inline"><em>k</em></span>th largest eigenvalue of the full <strong>covariance matrix</strong> <br /><span class="math display">$$\begin{aligned}
            {\langle(\xi_i - \mu_i)(\xi_j - \mu_j)\rangle}
        \end{aligned}$$</span><br /></p></li>
<li></li>
<li><p>Note: I am now going to start from beginning of CH8 of HKP since I’m not understanding the stuff they are referencing FML</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Units need to learn patterns/correlations/categories in inputs and code the output. Units and connections display some degree of .</p></li>
<li><p>Redundancy provides knowledge: w/o redundancy there would be no patters to learn.</p>
<p><br /><span class="math display">$$\begin{aligned}
            \text{MaxInfoPossible}-\text{InputContent} = \text{DegreeOfRedundancy}
        \end{aligned}$$</span><br /></p></li>
<li><p><span style="font-variant: small-caps;"></span> Context: output will be continuous-valued and DO NOT have a winner-take-all character<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a>, and so the is to measure familiarity or projecting onto principal components of input data.</p></li>
<li><p>Setup: Draw at each time step an input vector <span class="math inline">$\bm{\xi}$</span> from (multivariate) probability distribution <span class="math inline">$P(\bm{\xi})$</span> that has <span class="math inline"><em>N</em></span> components<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a>. Network will learn to tell us - as output - how well an input conforms to the distribution<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a></p></li>
<li><p>(One linear output unit): Let <span class="math inline"><em>V</em></span> be a scalar-valued continuous output with a bunch of inputs pointing to it, with <br /><span class="math display">$$\begin{aligned}
            V = \sum_j w_j \xi_j = \bm{w}^T \bm{\xi} = \bm{\xi}^T \bm{w}
        \end{aligned}$$</span><br /></p></li>
<li><p>Want large (on average) <span class="math inline"><em>V</em>↔</span> more probable <span class="math inline">$\bm{\xi}$</span>. Why? Because then we can use the relative size of the output as a way of characterizing the sort of input it just received (see footnote 26 below). The weight update to do this is <br /><span class="math display">$$\begin{aligned}
            \Delta w_i = \eta V \xi_i
        \end{aligned}$$</span><br /> where it is perhaps easier to think about the situation where <span class="math inline"><em>Δ</em><em>w</em><sub><em>i</em></sub> = 0</span> when analyzing, i.e. If <span class="math inline"><em>ξ</em><sub><em>i</em></sub> = 0</span> (which means it had nothing to do with the output), then don’t increase it’s weight<a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a>.</p></li>
<li><p>Problem: <span class="math inline">$\bm{w}$</span> grows without bound. However, suppose stable equilib exists for <span class="math inline">$\bm{w}$</span>. This could happen for example, when considering that the update just performs <span class="math inline">$\bm{w} = \eta V \bm{\xi}$</span>, where eventually <span class="math inline">$||\bm{w}|| &gt;&gt; ||\bm{\xi}||$</span> in addition to the fact that <span class="math inline"><em>ξ</em></span> is quite likely to be along <span class="math inline">$\bm{w}$</span>. So at equilib, expect the updates to average to <span class="math inline">0</span>: <br /><span class="math display">$$\begin{aligned}
            0 &amp;= {\langle\Delta w_i\rangle} \\
            &amp;= {\langle\sum_j w_j \xi_j \xi_i\rangle} \\
            &amp;= \sum_j {\mathbf{C}}_{ij} w_j
        \end{aligned}$$</span><br /> where the brackets are <em>expectation values</em> in the sense that <br /><span class="math display">$$\begin{aligned}
            {\langle\xi_i \xi_j\rangle} = \iint_{-\infty}^\infty \xi_i \xi_j f_{\xi_i \xi_j}(\xi_i, \xi_j) d\xi_i d\xi_j 
        \end{aligned}$$</span><br /> where <span class="math inline"><em>f</em></span> is the PDF for the two random variables in question. I suppose that, since strictly speaking <span class="math inline">$\bm{w}$</span> isn’t a random variable, that it can be pulled out along with the summation. That satisfies me for now.</p></li>
<li><p>Given that <span class="math inline">$\bm{\xi}$</span> can be interpreted as a column vector, we have <br /><span class="math display">$$\begin{aligned}
            {\mathbf{C}}_{ij} &amp;\equiv {\langle\xi_i \xi_j\rangle} \\
            {\mathbf{C}} &amp;\equiv {\langle\bm{\xi}\bm{\xi}^T\rangle}
        \end{aligned}$$</span><br /> Now, to be perfectly clear, this is NOT the correlation, but I am so sick and tired of caring that I’m just going to accept their absolutely incorrect definition and move on.</p></li>
<li><p>Since I’ve read ahead, I know that the following property will be important to remember: <br /><span class="math display">$$\begin{aligned}
            \forall \bm{x},~ \bm{x}^T {\mathbf{C}} \bm{x} 
            &amp;= \bm{x}^T {\langle\bm{\xi}\bm{\xi}^T\rangle}\bm{x} \\
            &amp;= {\langle\bm{x}^T \bm{\xi}\bm{\xi}^T\bm{x}\rangle}\\
            &amp;=  {\langle(\bm{\xi}^T\bm{x})^2\rangle}
        \end{aligned}$$</span><br /></p></li>
<li><p>There are <em>only</em> unstable fixed points (unstable equilib) for the plain Hebbian learning procedure.</p></li>
<li><p>. Goal: Modify plain Hebb rule such that <span class="math inline">$|\bm{w}| = 1$</span>.</p></li>
<li><p>Solution: Add a proportional to <span class="math inline"><em>V</em><sup>2</sup></span>: <span> </span> and we see that <span class="math inline"><em>Δ</em><em>w</em></span> depends on the difference between the input and the back-propagated output<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a></p></li>
<li><p>Informal analysis for zero-mean data: The average component of <span class="math inline"><em>ξ</em></span> along <span class="math inline"><em>w</em></span> will be zero, but since this is an algorithm depending on an unstable equilibrium, it will tend to fall along the maximal eigenvector of <span class="math inline"><strong>C</strong></span>.</p></li>
<li><p>Oja’s rule chooses the direction of <span class="math inline">$\bm{w}$</span> to maximize <span class="math inline">⟨<em>V</em><sup>2</sup>⟩</span>.</p></li>
<li><p>. Setup: Now, instead of 1 output, have <span class="math inline"><em>M</em></span> output neurons with the hopes that they gives us the first <span class="math inline"><em>M</em></span> principal components of the input data. Architecture is ONE LAYER fully connected.</p></li>
<li><p>The ith output is a linear neuron as usual given by <br /><span class="math display">$$\begin{aligned}
            V_i = \sum_j w_{ij} \xi_j = \bm{w}_i^T \bm{\xi} = \bm{\xi}^T \bm{w}_i
        \end{aligned}$$</span><br /></p></li>
<li><p>The Sanger’s learning rule update for the connection <em>from</em> the <span class="math inline"><em>j</em></span>th input component <em>to</em> the <span class="math inline"><em>i</em></span>th output neuron (so we are only updating a single edge/line in the following) is <span> </span> where the (converged) weight vectors to the output neurons are orthonormal and converge to the normalized eigenvectors in order of largest to smallest eigvals: <br /><span class="math display">$$\begin{aligned}
            \bm{w}_i^T \bm{w}_j &amp;= \delta_{ij} \\
            \bm{w}_i &amp;\rightarrow \pm \bm{c}^{i}
        \end{aligned}$$</span><br /></p></li>
</ul></li>
</ul>
<ul>
<li><p>Want to learn a “dictionary” from data<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a></p></li>
<li><p>Encode input data such that it can be reconstructed from that code, where dim(encoding) &gt; dim(input).</p></li>
<li><p>Given <span class="math inline"><em>N</em></span>-dimensional input, build <span class="math inline"><em>N</em> × <em>M</em></span> dictionary<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a> (matrix) <span class="math inline"><strong>Φ</strong></span> where each column <span class="math inline"><em>ϕ</em><sub><em>i</em></sub></span> is a dictionary element with corresponding coefficient<a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a> <span class="math inline"><em>a</em><sub><em>i</em></sub></span>. Want to assemble <span class="math inline"><em>a</em><sub><em>i</em></sub><em>ϕ</em><sub><em>i</em></sub></span> into a vector of .</p></li>
<li><p><strong>GOAL:</strong> Minimize energy function <span class="math inline"><em>E</em></span>, defined as <span> </span> where <span class="math inline">$\hat{S} = \sum_i^M a_i \phi_i$</span> is for some reason called the image reconstruction. View this like a regularization procedure where the terms mean: (1) smallest difference between true image and reconstructed image (); and (2) limit the number of <a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a> <span class="math inline"><em>a</em><sub><em>i</em></sub></span>.</p></li>
<li><p>Want to minimize <span class="math inline"><em>E</em></span> such that reconstructs data with fewest number of active elements, expressed as <br /><span class="math display">$$\begin{aligned}
        \operatorname*{arg\,min}_{a,~{\mathbf{\Phi}}} \big( E \big) {\tag{argminE}\label{argminE}}
    \end{aligned}$$</span><br /> where I guess the double argmin means &quot;minimize E by changing <span class="math inline"><em>a</em></span> and <span class="math inline"><strong>Φ</strong></span> only and then give me the values of <span class="math inline"><em>a</em></span> and <span class="math inline"><strong>Φ</strong></span>.</p></li>
<li><p>Popular cost function is the <span class="math inline">ℓ<sub>1</sub></span> penalty: <br /><span class="math display">$$\begin{aligned}
        \sum_i^M C(a_i) = \sum_i^M  |a_i|
    \end{aligned}$$</span><br /></p></li>
<li><p>We compute coeff vector <span class="math inline"><em>a</em></span> using a “dynamic process”<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a> that minimizes [argminE].</p></li>
<li><p>Method for computing the sparse code<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a> from a given input signal <span class="math inline"><em>S</em></span> and dictionary element <span class="math inline"><em>ϕ</em><sub><em>i</em></sub></span> is the .</p>
<blockquote>
<p>The model describes an activation coefficient, <span class="math inline"><em>a</em><sub><em>k</em></sub></span>, as the thresholded output of some model neuron’s <strong>internal state</strong>, <span class="math inline"><em>u</em><sub><em>k</em></sub></span>, which is analogous to the neuron’s membrane potential.<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a></p>
</blockquote></li>
<li><p>Here we compute the equation for state transitions (updates) from the energy function. First, for grad descent on an individual neuron’s activity, <span class="math inline"><em>a</em><sub><em>k</em></sub>(<em>t</em>)</span>: <span> </span> where the constants are <span class="math inline"><em>S</em></span> and <span class="math inline"><strong>Φ</strong></span>. Want system to evolve over time to produce optimal set of activations <span class="math inline"><em>a</em>(<em>t</em>)</span>.</p></li>
<li><p>Meaning of <span class="math inline"><em>ϕ</em><sub><em>k</em></sub></span>. Associated with <span class="math inline"><em>k</em></span>th (output?) neuron. Indicates the connection strength [between that neuron and] each pixel in the input.</p></li>
<li><p>What the fuck is the following shit</p>
<blockquote>
<p>In this model, we are going to nd a sparse code for one patch of an image at a time, so that all M neurons are connected to the same image patch, S.</p>
</blockquote></li>
</ul>
<p><span> </span>Nearby (similar) outputs corresponding to nearby (similar) input patterns. Such a map (similar inputs <span class="math inline">→</span> similar outputs) is a . The conventional case: 2 continuous-valued inputs <span class="math inline"><em>x</em></span> and <span class="math inline"><em>y</em></span> map (fully-connected) to a two-dimensional x,y grid. Want nearby input values (in the actual euclidean sense) (x, y) to be mapped closely in the output 2D grid.<br />
<span> </span> implements the self-organizing (feature) map by using competitive learning, where now we update weights going to the <em>neighbors</em> of the winning unit as well as those of the winning unit itself.</p>
<ul>
<li><p>Setup: <span class="math inline"><em>N</em></span> continuous-valued inputs <span class="math inline"><em>ξ</em><sub>1</sub></span> to <span class="math inline"><em>ξ</em><sub><em>N</em></sub></span>, defining a point <span class="math inline">$\bm{\xi}$</span> in <span class="math inline"><em>N</em></span>-dimensional space. Outputs <span class="math inline"><em>O</em><sub><em>i</em></sub></span> are arranged in (typically) a 1-D or 2-D array fully connected via <span class="math inline"><em>w</em><sub><em>i</em><em>j</em></sub></span> to the inputs.</p></li>
<li><p>A competitive learning rule is used, choosing output <span class="math inline"><em>O</em><sub><em>i</em></sub><sup>*</sup></span> as winner, determined by <br /><span class="math display">$$\begin{aligned}
        |\bm{w_i^*} - \bm{\xi}| \le |\bm{w}_i - \bm{\xi}| ~~ {\text{{\textcolor{OliveGreen}{\textbf{$\text{(for all i)}$}}}}}
    \end{aligned}$$</span><br /></p></li>
<li><p>The is <span> </span> where <span class="math inline"><em>Λ</em>(<em>i</em>, <em>i</em><sup>*</sup>)</span> is the <strong>neighborhood function</strong>, equal to 1 for <span class="math inline"><em>i</em> = <em>i</em><sup>*</sup></span> and falls off with distance <span class="math inline">$|\bm{r} - \bm{r_i}^*|$</span>.</p></li>
<li><p>A typical choice for <span class="math inline"><em>Λ</em>(<em>i</em>, <em>i</em><sup>*</sup>)</span> is <br /><span class="math display">$$\begin{aligned}
        \Lambda(i, i^*) = \exp\bigg(- \frac{|\bm{r} - \bm{r_i}^*|^2}{2 \sigma^2} \bigg)
    \end{aligned}$$</span><br /> where <span class="math inline"><em>σ</em></span> is width parameter that <em>is gradually decreased</em>. Apparently <span class="math inline"><em>η</em>(<em>t</em>)∝<em>t</em><sup>−<em>α</em></sup></span> where <span class="math inline">0 &lt; <em>α</em> ≤ 1</span> is a good choice.</p></li>
</ul>
<p>LLE is an unsupervised learning algorithm for dimensionality reduction. Similar to PCA and MDS<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a>, LLE is called an <em>eigenvector method</em>. The basic idea is illustrated below in figure [LLE].<br />
</p>
<div class="figure">
<img src="LLE.PNG" alt="(A) Multidimensional sampling distribution with clear underlying manifold representation. (B) Points that were sampled. (C) The neighborhood-preserving mapping discovered by LLE. " />
<p class="caption">(A) Multidimensional sampling distribution with clear underlying manifold representation. (B) Points that were sampled. (C) The neighborhood-preserving mapping discovered by LLE. <span data-label="LLE"></span></p>
</div>
<p><span> </span>The <strong>LLE algorithm</strong>:</p>
<ol>
<li><p>Compute the neighbors of each data point, <span class="math inline"><em>X</em><sub><em>i</em></sub></span>.</p></li>
<li><p>Compute the weights <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span> that best reconstruct each <span class="math inline"><em>X</em><sub><em>i</em></sub></span> from its neighbors, minimizing the cost in <span> </span> by constrained linear fits.</p></li>
<li><p>Compute the <span class="math inline"><em>Y</em><sub><em>i</em></sub></span> reconstructed by the weights <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span>, minimizing the quadratic form in <span> </span> by its bottom nonzero eigenvectors.</p></li>
</ol>
<p><span> </span>Some intuition/overview of the algorithm. We expect each <span class="math inline"><em>X</em><sub><em>i</em></sub></span> and its neighbors to lie on or close to a patch of the manifold. We characterize these patches by linear coefficients <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span> that reconstruct each <span class="math inline"><em>X</em><sub><em>i</em></sub></span> from its neighbors. As seen in eq. [ReconErr], the reconstructed point <span class="math inline"><em>X</em><sub><em>i</em></sub></span> is given by <span class="math inline">∑<sub><em>j</em></sub><em>W</em><sub><em>i</em><em>j</em></sub><em>X</em><sub><em>j</em></sub></span>.<br />
<span> </span><strong>Computing/analyzing the weights <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span></strong>. Minimize eq [ReconErr] subject to <br /><span class="math display">$$\begin{aligned}
        \forall X_j \notin \text{Neighbors}(X_i) ~ : ~ &amp;W_{ij} = 0 \\
        \sum_j ~ &amp;W_{ij} = 1 
    \end{aligned}$$</span><br /> where the optimal weights are found by solving a least squares problem. Note that for a given data point, <em>the weights are invariant to rotations, rescalings, and translations of that data point and its neighbors.</em><a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a> If the data lie on some nonlinear manifold of <span class="math inline"><em>d</em> &lt; &lt;<em>D</em></span>, then there exists a <em>linear mapping</em> (approx) from the high-D coordinates of each neighborhood to global (’internal’) coordinates on the manifold. Lucky for us, <span class="math inline"><em>W</em></span> can also do this!<a href="#fn51" class="footnoteRef" id="fnref51"><sup>51</sup></a><br />
<span> </span><strong>Explanation of eqs. [ReconErr] [map]</strong>. Note that eq. [ReconErr] is minimized over the <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span>, while equation [map] is minimized over the <span class="math inline"><em>Y</em><sub><em>i</em></sub></span>. In English: We first want the weights <span class="math inline"><em>W</em></span> that reconstruct each <span class="math inline"><em>X</em><sub><em>i</em></sub></span> by its neighbors in the high-D space. Then, we want the low-<span class="math inline"><em>d</em></span> coordinates <span class="math inline"><em>Y</em><sub><em>i</em></sub></span>, representing the global coordinates on the manifold, that correspond to each <span class="math inline"><em>X</em><sub><em>i</em></sub></span> from the original space. <strong>How it is minimized:</strong></p>
<blockquote>
<p>it can be minimized by solving a sparse <span class="math inline"><em>N</em> × <em>N</em></span> eigenvector problem, whose bottom <span class="math inline"><em>d</em></span> non-zero eigenvectors provide an ordered set of orthogonal coordinates centered on the origin.</p>
</blockquote>
<p><span> </span><strong>Implementation of algorithm.</strong> Only one free parameter: number of neighbors per data point <span class="math inline"><em>K</em></span>. <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span> and <span class="math inline"><em>Y</em><sub><em>i</em></sub></span> are computed by ’standard linear algebra’.</p>
<p><span> </span>. Briefly goes over how we can corrupt some number of bits and reconstruct a desired image [with hopfield nets]. Unfortunately, can get “spurious basins of attractions.” Pushing down on some region of landscape causes pushing up of some other region. Want to carve energy landscape so that we push down only where we want.<br />
<span> </span>. Want family of solutions (e.g. a line) that solutions drawn to (called line attractors). Head-direction neurons<a href="#fn52" class="footnoteRef" id="fnref52"><sup>52</sup></a> look like an internal compass for animals; encode direction of head in <em>world coordinate system</em>. Different dots represent a single neuron’s firing rate at different relative head directions. <strong>Ring attractors</strong>: population of neurons that with bumps that are stable (?). Convergence/stability because <span class="math inline"><em>T</em><sub><em>i</em><em>j</em></sub></span> matrix is symmetric. Symmetric = fixed stable; Asymmetric =<br />
<span> </span>Bruno shows simulation:</p>
<p>32 neurons where bar is activity of neuron.</p>
<p>Start with random symmetric weight hopfield net.</p>
<p>Eventually weights converge to gaussian-like bump; an equipotential pattern.</p>
<p>If we add small asymmetry (gamma) to weights, then population (bump) would shift. Bump change is shifting position, and when the asymmetry stops (we stop moving our head) the population stays fixed. In English: moving head causes bump to move but when we stop moving, they stay put.</p>
<p>: Read “catcher and zong” paper. I misspelled that.</p>
<p><span> </span>[<em>Enter guest lecturer Alex Anderson</em>] <span><strong><em></em></strong></span>:</p>
<p>[<span class="math inline">→</span>]</p>
<p>Starts with handwriting network.</p>
<p>RNNs good for sequence prediction tasks with “long-term dependencies.”</p>
<p><span> </span>. Blobs do activation computation and transformers do propagations. Note: <span class="math inline"><em>A</em><sup><em>t</em></sup></span> is target output values.<br />
<span> </span>. Feed net a bunch of sentences and have it fill in the blank somewhere, based on the previous info it was fed. Mad libs. Have network understand particular frame of movie by exploiting context; just showing it a bunch of frames isn’t enough/good approach.<br />
<span> </span>. Feed <em>time sequence</em> <span class="math inline"><em>x</em><sub><em>t</em></sub></span> to block <span class="math inline"><em>A</em></span>. Two figures in this slide are different reps of same thing; instructor prefers the right fig. <span class="math inline"><em>H</em><sub><em>k</em></sub></span> is hidden state we want to predict<a href="#fn53" class="footnoteRef" id="fnref53"><sup>53</sup></a>. <span class="math inline"><em>f</em></span> can be some nonlinearity like <span class="math inline"><em>t</em><em>a</em><em>n</em><em>h</em></span>. In RNNs, cost function typically broken up over time; so <span class="math inline"><em>C</em><sub><em>k</em></sub></span> is cost at timestep <span class="math inline"><em>k</em></span>. Usually want hidden state to <em>summarize</em> the past. Hidden state traces out a trajectory over time [wut].<br />
<span> </span>. Can basically turn RNN into a linearized hidden markov chain, where time proceeds to the right. Total cost is given by cost at each time step.<br />
<span> </span>. Shows toy model. Imagine ur an ant walking along graph. Given string of nodes, predict next letter each timestep [solve the question mark in slide]. Don’t necessarily want/need whole past as input. Want to remember past [hidden] states, but they usually get overwritten; want to save it more efficiently. Key: want to make function simple, give the network parameterization.<br />
<span> </span>. Local dependencies easy to learn.</p>
<p>[<span class="math inline">→</span>]</p>
<p>Once we get to B, want network to output a U.</p>
<p>To learn, errors need to propagate back [in time], so we can change the weights that started the error: gradient of cost at timestep <span class="math inline"><em>k</em></span> with respect to initial weights using chain rule. Basically a product of <span class="math inline"><em>k</em></span> matrices.</p>
<p>If <span class="math inline"><em>k</em></span> large and matrices have eigvals less than 1, gradients <em>vanish</em>. If eigvals above 1, gradients <em>explode</em>. So what we want is for eigvals to be very near 1.</p>
<p>: lookup relationship between eigval magnitudes and determinant.</p>
<p><span> </span>. Helps protect hidden state. MultGate can be either 0 or 1, and we multiply the hidden state by that value; if we 0 lose the hidden state; if 1 we keep the hidden state. Since binary functions not smooth/differentiable, continuous gating is better. [slide note: top row is w/o multgate, lower row is with multgate]. Key equation: <br /><span class="math display"><em>c</em><sub><em>t</em></sub> = <em>f</em><sub><em>t</em></sub> ⊙ <em>c</em><sub><em>t</em> − 1</sub> + <em>i</em><sub><em>t</em></sub> ⊙ <em>j</em><sub><em>t</em></sub></span><br /> where <span class="math inline">⊙</span> is elementwise product.<br />
<span> </span>Note: This is in TensorFlow now.</p>
<p><span> </span>. The following governs the dynamic of pairwise recurrently connected networks. <span> </span> For symmetric weights <span class="math inline"><em>T</em><sub><em>i</em><em>j</em></sub> = <em>T</em><sub><em>j</em><em>i</em></sub></span>, consider the change in energy <span class="math inline"><em>Δ</em><em>E</em></span> resulting from making a positive change to <span class="math inline"><em>V</em><sub><em>k</em></sub></span><a href="#fn54" class="footnoteRef" id="fnref54"><sup>54</sup></a> <br /><span class="math display">$$\begin{aligned}
\Delta E = -\Delta V_k \sum_{i \ne k} T_{ki} V_i\end{aligned}$$</span><br /> which will be <em>negative</em> if both <span class="math inline"><em>Δ</em><em>V</em><sub><em>k</em></sub></span> and the sum are positive, thus decreasing the overall energy (good). Conversely, if sum is negative, we should decrease value of <span class="math inline"><em>V</em><sub><em>k</em></sub></span>. <strong>Critical assumption</strong>: Symmetric <span class="math inline"><em>T</em><sub><em>i</em><em>j</em></sub> = <em>T</em><sub><em>j</em><em>i</em></sub></span>. Without this assumption, impossible to show the system will have fixed points.</p>
<blockquote>
<p>For a network with symmetric connections though, the dynamics will converge to so-called .</p>
</blockquote>
<p><span> </span>. Goal: store pattern <span class="math inline"><strong>V</strong><sup><em>α</em></sup></span> as basin of attraction in network. One approach: the <span class="math inline"><em>T</em><sub><em>i</em><em>j</em></sub> = <em>V</em><sub><em>i</em></sub><sup><em>α</em></sup><em>V</em><sub><em>j</em></sub><sup><em>α</em></sup></span>.</p>
<ul>
<li><p><strong>Single memory storage</strong>. Now, the summed input sent to, say, the <span class="math inline"><em>i</em></span>th unit in response to some <span class="math inline"><strong>V</strong><sup><em>β</em></sup></span> will be given by <br /><span class="math display">$$\begin{aligned}
        U_i = V_i^\alpha \sum_{j \ne i} V_j^\alpha V_j^\beta 
    \end{aligned}$$</span><br /> and thus if <span class="math inline"><strong>V</strong><sup><em>α</em></sup> = <strong>V</strong><sup><em>β</em></sup></span>, <span class="math inline"><em>U</em><sub><em>i</em></sub></span> won’t flip sign and the networks stays put.</p></li>
<li><p><strong>Multiple memories</strong>. Now, need to form as many basins of attractions as memories we want stored. Set weights with a superposition over each desired <em>memory</em> <span class="math inline"><strong>V</strong><sup><em>α</em></sup></span>: <span class="math inline"><em>T</em><sub><em>i</em><em>j</em></sub> = ∑<sub><em>α</em></sub><em>V</em><sub><em>i</em></sub><sup><em>α</em></sup><em>V</em><sub><em>j</em></sub><sup><em>α</em></sup></span>, and the corresponding response of the <span class="math inline"><em>i</em></span>th neuron is <br /><span class="math display">$$\begin{aligned}
        U_i = \sum_\alpha V_i^\alpha \sum_{j \ne i} V_j^\alpha V_j^\beta \label{18}
    \end{aligned}$$</span><br /></p></li>
</ul>
<p><span> </span>. If the patterns to store (memories) have <em>few elements in common</em>, then cross terms <span class="math inline">∑<sub><em>j</em> ≠ <em>i</em></sub><em>V</em><sub><em>j</em></sub><sup><em>α</em></sup><em>V</em><sub><em>j</em></sub><sup><em>β</em></sup></span> tend to zero for <span class="math inline"><em>α</em> ≠ <em>β</em></span> (since each <span class="math inline"><em>V</em><sub><em>j</em></sub><sup><em>α</em></sup></span> is <span class="math inline">±1</span> and a random average over <span class="math inline">±1</span> is zero) and <span class="math inline"><em>U</em><sub><em>i</em></sub></span> won’t change. As we store more patterns which are <em>similar</em>, memories degrade and basins gone from desired locations. This <strong>capacity</strong> for Hopfield is <span class="math inline">≈15%</span> of the number of neurons in network<a href="#fn55" class="footnoteRef" id="fnref55"><sup>55</sup></a>.</p>
<p>[Discrete Math and Probability]</p>
<p><span> </span> Alice communicates to Bob. Eve wants to figure it out. The message is <br /><span class="math display"><em>m</em> = <em>D</em>(<em>E</em>(<em>m</em>, <em>s</em>),<em>s</em>)</span><br /></p>
<p><span> </span>. A function <span class="math inline"><em>f</em> : <em>S</em> → <em>T</em></span> is defined as</p>
<p>One-to-one: <span class="math inline"><em>f</em>(<em>x</em>)≠<em>f</em>(<em>x</em>′)∀<em>x</em>, <em>x</em>′≠<em>x</em> ∈ <em>S</em></span>.</p>
<p>Onto: <span class="math inline">∀<em>y</em> ∈ <em>T</em>∃<em>x</em> ∈ <em>S</em></span> where <span class="math inline"><em>f</em>(<em>x</em>)=<em>y</em></span>.</p>
<p><span> <em>Two sets have same size iff there is a bijection between them.</em></span> Relation to modular arithmetic:</p>
<ul>
<li><p>Can reverse mapping from <span class="math inline"><em>S</em></span> to <span class="math inline"><em>T</em></span> with inverse function <span class="math inline"><em>g</em> : <em>T</em> → <em>S</em></span> that maps outputs of <span class="math inline"><em>f</em></span> back to their input.</p></li>
<li><p>Consider <span class="math inline"><em>f</em>(<em>x</em>)=<em>x</em> + 1mod<em>m</em></span>. Is it 1-1?</p></li>
<li><p>Well, consider <span class="math inline"><em>g</em>(<em>x</em>)=<em>x</em> − 1mod<em>m</em></span>. It is the inverse of <span class="math inline"><em>f</em></span>, and so the function <em>is</em> one-to-one. To show a function is one-to-one, trying finding its inverse.</p></li>
<li><p>If <span class="math inline">gcd(<em>a</em>, <em>m</em>)=1,  <em>a</em><em>x</em> ≠ <em>a</em><em>x</em>′(<em>m</em><em>o</em><em>d</em><em>m</em>)</span> for <span class="math inline"><em>x</em> ≠ <em>x</em>′∈{0, …, <em>m</em> − 1}</span></p></li>
<li><p>Consider output space <span class="math inline"><em>T</em> = {0<em>a</em>mod<em>m</em>, …, (<em>m</em> − 1)<em>a</em>mod<em>m</em>}</span> and input <span class="math inline"><em>S</em> = {0, 1, …, (<em>m</em> − 1)}</span>. Want to show that <span class="math inline"><em>S</em> = <em>T</em></span>.</p>
<ul>
<li><p><span class="math inline"><em>T</em> ⊆ <em>S</em></span>, obvi.</p></li>
<li><p>one-to-one mapping from <span class="math inline"><em>S</em></span> to <span class="math inline"><em>T</em></span>, so <span class="math inline">|<em>T</em>|≥|<em>S</em>|</span> and T is superset of S.</p></li>
<li><p><span class="math inline">∴<em>S</em> = <em>T</em></span>.</p></li>
</ul></li>
<li><p>Result: Since <span class="math inline"><em>S</em> = <em>T</em></span>, inverse of <span class="math inline"><em>a</em>mod<em>m</em></span> must exist because <span class="math inline">1mod<em>m</em> ∈ <em>T</em></span>.</p></li>
</ul>
<p><span> </span></p>
<ul>
<li><p>Public key: <span class="math inline">(<em>N</em> = 77, <em>e</em> = 7)</span> and <span class="math inline"><em>d</em> = 43</span> and <span class="math inline"><em>p</em> × <em>q</em> = 11 × 7</span>.</p></li>
<li><p><span class="math inline"><em>E</em>(2)=2<sup><em>e</em></sup>mod77 = 51mod77 → <em>D</em>(51)=51<sup>43</sup>mod77</span></p></li>
<li><p><span class="math inline">51<sup>43</sup></span> is big. to the rescue.</p></li>
<li><p><span class="math inline">51<sup>43</sup> = 51<sup>2<sup>5</sup> + 2<sup>3</sup> + 2<sup>1</sup> + 2<sup>0</sup></sup>mod77</span>. Calculate each factor alone <span class="math inline">mod77</span> and use results from lower powers to calculate higher powers.</p></li>
<li><p>How to actually do it<a href="#fn56" class="footnoteRef" id="fnref56"><sup>56</sup></a>: To compute <span class="math inline"><em>n</em><sup><em>e</em></sup>mod<em>p</em></span>, divide exponent <span class="math inline"><em>e</em></span> repeatedly by 2, flooring each time [Save sequence of numbers this produces]. Starting from smallest number (probably 1), successively take n raised to that power mod 7. Use past results to help future ones. The last number in the sequence is <span class="math inline"><em>e</em></span> and you’ll have <span class="math inline"><em>n</em><sup><em>e</em></sup>mod<em>p</em></span>.</p></li>
</ul>
<p><span> </span>.</p>
<ul>
<li><p><br /><span class="math display">$$\begin{aligned}
        m^{ed} = m \mod{pq} \text{ if } ed = 1 \mod{(p-1)(q-1)} \label{med}
    \end{aligned}$$</span><br /></p></li>
<li><p><br /><span class="math display">$$\begin{aligned}
a^{k(p-1) + 1} = a \mod{p}\end{aligned}$$</span><br /></p></li>
<li><p><strong></strong>: For any prime <span class="math inline"><em>p</em></span> and any <span class="math inline"><em>a</em></span>, <span class="math inline"><em>b</em></span>:<a href="#fn57" class="footnoteRef" id="fnref57"><sup>57</sup></a> <span class="math inline"><em>a</em><sup>1 + <em>b</em>(<em>p</em> − 1)</sup> ≡ <em>a</em>mod<em>p</em></span></p></li>
<li><p><strong></strong>: <span class="math inline">∀ primes <em>p</em>, <em>q</em> ≠ <em>p</em></span> and <span class="math inline">∀<em>x</em>, <em>k</em></span>: <span class="math inline"><em>x</em><sup>1 + <em>k</em>(<em>p</em> − 1)(<em>q</em> − 1)</sup> ≡ <em>x</em>mod<em>p</em><em>q</em></span></p></li>
<li><p>Let <span class="math inline"><em>π</em>(<em>N</em>)</span> denote the number of primes less than or equal to <span class="math inline"><em>N</em></span>. For all <span class="math inline"><em>N</em> ≥ 17</span> <br /><span class="math display">$$\begin{aligned}
    \pi(N) \ge N/\ln N\end{aligned}$$</span><br /></p></li>
</ul>
<p><span> </span><a href="#fn58" class="footnoteRef" id="fnref58"><sup>58</sup></a></p>
<ul>
<li><p><span class="math inline"><em>g</em><em>c</em><em>d</em>(<em>a</em>, <em>p</em><em>q</em>)=1 ⇐ <em>g</em><em>c</em><em>d</em>(<em>a</em>, <em>p</em>)=<em>g</em><em>c</em><em>d</em>(<em>a</em>, <em>q</em>)=1</span></p></li>
<li><p>Before expanding the exponent in <span class="math inline"><em>a</em><sup>(<em>p</em> − 1)(<em>q</em> − 1)</sup></span>, realize that it’s the same as <span class="math inline">(<em>a</em><sup>(<em>p</em> − 1)</sup>)<sup><em>q</em> − 1</sup></span></p></li>
</ul>
<p>Polynomials in modular arithmetic <span class="math inline"><em>P</em>(<em>x</em>)mod<em>p</em></span> consist only of points in the domain <span class="math inline">{0, 1, …, <em>p</em> − 1}</span>.</p>
<p>Solve intersection of polynomials by equating and solving for <span class="math inline"><em>x</em></span>, use multiplicative inverses rather than dividing. &quot;Whole world is <span class="math inline">mod<em>p</em></span>.</p>
<p><span> <em></em></span>There is exactly one polynomial of degree <span class="math inline">≤<em>d</em></span> ([optionally] with arithmetic modulo prime p) that <span class="math inline"><em>d</em> + 1</span> (particular/given) points.</p>
<p><strong>Secret</strong>: I’m going to give you <span class="math inline">2 + 1</span> points of a parabola, and the <em>secret</em> is that parabola’s y-intercept.</p>
<p>Shamir’s</p>
<ul>
<li><p>Choose secret <span class="math inline"><em>s</em> = <em>a</em><sub>0</sub> ∈ {0, …, <em>p</em> − 1}</span> and randomly <span class="math inline"><em>a</em><sub>1</sub>, …, <em>a</em><sub><em>k</em> − 1</sub></span>.</p></li>
<li><p>Let <span class="math inline"><em>P</em>(<em>x</em>)=<em>a</em><sub><em>k</em> − 1</sub><em>x</em><sup><em>k</em> − 1</sup> + ⋯ + <em>a</em><sub>0</sub></span>.</p></li>
<li><p>. The <span class="math inline"><em>i</em></span>th shared point is <span class="math inline">(<em>i</em>, <em>P</em>(<em>i</em>)mod<em>p</em></span>.</p></li>
<li><p>: Any <span class="math inline"><em>k</em></span> shares gives secret.</p></li>
<li><p>Knowing <span class="math inline">≤<em>k</em> − 1</span> points <span class="math inline">⇒</span> any <span class="math inline"><em>P</em>(0)</span> is possible.</p></li>
</ul>
<p>Solving polynomial given enough points <span class="math inline">≡</span></p>
<ul>
<li><p>Given points: <span class="math inline">(<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>),…,(<em>x</em><sub><em>k</em></sub>, <em>y</em><sub><em>k</em></sub>)</span>, Solve <br /><span class="math display">$$\begin{aligned}
            a_{k-1}x_1^{k-1} + \cdots + a_0 &amp;\equiv y_1 \mod{p} \\
            &amp;\vdots\\
            a_{k-1}x_k^{k-1} + \cdots + a_0 &amp;\equiv y_k \mod{p}
        \end{aligned}$$</span><br /></p></li>
</ul>
<p><span><strong><em></em></strong></span></p>
<ul>
<li><p>: Want to find <span class="math inline"><em>P</em>(<em>x</em>)=<em>a</em><sub>2</sub><em>x</em><sup>2</sup> + <em>a</em><sub>1</sub><em>x</em> + <em>a</em><sub>0</sub>mod5</span> that contains <span class="math inline">(1, 3),(2, 4),(3, 0)</span>.</p></li>
<li><p>Find <span class="math inline"><em>Δ</em><sub>1</sub>(<em>x</em>)</span> defined such that, for all <span class="math inline"><em>x</em></span> above except <span class="math inline"><em>x</em> = 1</span>, <span class="math inline"><em>Δ</em><sub>1</sub>(<em>x</em>)=0mod5</span> and evaluates to 1 at <span class="math inline"><em>x</em> = 1</span>. Solution, as shown below, is to factor all <span class="math inline"><em>x</em> − <em>x</em><sub><em>i</em></sub></span> together, evaluate at <span class="math inline"><em>x</em> = 1</span>, and multiply the inverse of that to force/normalize <span class="math inline"><em>Δ</em><sub>1</sub>(<em>x</em> = 1)=1mod5</span>. <br /><span class="math display">$$\begin{aligned}
            \Delta_1(x) = 3 (x - 2)(x - 3) \mod{5}
        \end{aligned}$$</span><br /> where <span class="math inline">3</span> is inverse of <span class="math inline">(1 − 3)(1 − 2)mod5</span>.</p></li>
<li><p>Repeat, constructing <span class="math inline"><em>Δ</em><sub><em>i</em></sub>(<em>x</em>)∀<em>x</em>∈</span> given points.</p></li>
<li><p>Now we have <span class="math inline">3</span> polynomials that each evaluate to 1 only and 0 else for each given point. To make the <span class="math inline"><em>y</em> − <em>v</em><em>a</em><em>l</em><em>u</em><em>e</em><em>s</em></span> align and get desired polynomial, compute result: <br /><span class="math display">$$\begin{aligned}
            P(x) = y_1 \Delta_1(x) + 4\Delta_2(x) + 0 \Delta_3(x) \mod{5}
        \end{aligned}$$</span><br /></p></li>
<li><p><br /><span class="math display">$$\begin{aligned}
            \Delta_i(x) = \dfrac{\prod_{j \ne i} (x - x_j)}{\prod_{j \ne i} (x_i - x_j)}
        \end{aligned}$$</span><br /></p>
<p>where, if in modular field, you don’t technically “divide” the lower product; rather, you should read that as a multiplication by <span class="math inline">denom<sup>−1</sup>mod<em>p</em></span> (the multiplicative inverse).</p></li>
<li><p>Construction via interpolation proves existence of unique solution.</p></li>
</ul>
<p>Any degree <span class="math inline"><em>d</em></span> polynomial has at most <span class="math inline"><em>d</em></span> roots.</p>
<p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Problem: Divide <span class="math inline">4<em>x</em><sup>2</sup> − 3<em>x</em> + 2</span> by <span class="math inline">(<em>x</em> − 3)mod5</span>.</p></li>
<li><p>One approach is calculating while ignoring mod, then modding at end</p>
<p>and answer is then <span class="math inline">29mod5 = 4</span>. You can also just mod 5 everything as you go, too.</p></li>
<li><p>In general, dividing <span class="math inline"><em>P</em>(<em>x</em>)</span> by <span class="math inline">(<em>x</em> − <em>a</em>)</span> gives <span class="math inline"><em>Q</em>(<em>x</em>)</span> and remainder <span class="math inline"><em>r</em></span>. i.e. <br /><span class="math display">$$\begin{aligned}
            P(x) = (x-a)~Q(x) + r
            \label{Poly}
        \end{aligned}$$</span><br /></p></li>
</ul>
<p>: <span class="math inline"><em>P</em>(<em>x</em>)</span> has root <span class="math inline"><em>a</em></span> iff <span class="math inline"><em>P</em>(<em>x</em>)/(<em>x</em> − <em>a</em>)</span> has remainder 0.<a href="#fn59" class="footnoteRef" id="fnref59"><sup>59</sup></a></p>
<p>: <span class="math inline"><em>P</em>(<em>x</em>)</span> has <span class="math inline"><em>d</em></span> roots; <span class="math inline"><em>r</em><sub>1</sub>, …, <em>r</em><sub><em>d</em></sub></span> then<a href="#fn60" class="footnoteRef" id="fnref60"><sup>60</sup></a> <br /><span class="math display">$$\begin{aligned}
        P(x) = c(x-r_1)(x-r_2)\cdots(x-r_d)
    \end{aligned}$$</span><br /></p>
<h3 id="polynomials-discussion">Polynomials Discussion</h3>
<ol>
<li><p><strong>How many polynomials?</strong> (I’ll express my degree of certainty for each of my answers as a footnote)</p>
<ol>
<li><p>Strictly speaking, <span class="math inline"><em>P</em>(2)</span> can only have 5 values since <span class="math inline"><em>G</em><em>F</em>(5)</span>. The number of distinct polynomials is <span class="math inline">5 × 5 × 5 = 125</span>.<a href="#fn61" class="footnoteRef" id="fnref61"><sup>61</sup></a></p></li>
<li><p>The number of different pairs are <span class="math inline">5<sup>2</sup> = 25</span>. The number of polynomials here is the number of distinct pairs of <span class="math inline"><em>P</em>(<em>i</em> ≠ 0),<em>P</em>(<em>j</em> ≠ 0, <em>i</em>)</span>. This is <span class="math inline">(5 × 4)×(5 × 3)=300</span>.<a href="#fn62" class="footnoteRef" id="fnref62"><sup>62</sup></a></p></li>
<li><p><del>If we know <span class="math inline"><em>k</em></span> values, then we need <span class="math inline">(<em>d</em> + 1)−<em>k</em> = (<em>d</em> − <em>k</em>)+1</span> more points to uniquely determine any polynomial. The next point can have <span class="math inline"><em>p</em> − <em>k</em></span> possible values for <span class="math inline"><em>x</em></span>, and each of those can have <span class="math inline"><em>p</em></span> possible <span class="math inline"><em>y</em></span> values, for a total of <span class="math inline">(<em>p</em> − <em>k</em>)×<em>p</em></span> unique choices for the next point alone. For subsequent choices, the number of possibles decreases by a factor of <span class="math inline"><em>p</em></span>. Therefore, the number of different polynomials we could obtain, given that we are in <span class="math inline"><em>G</em><em>F</em>(<em>p</em>)</span>, is</del><a href="#fn63" class="footnoteRef" id="fnref63"><sup>63</sup></a></p>
<p>The main error in your line of thought is that many of those polynomials <em>would be the same one</em>. Although polynomials are indeed definable by a set of points, many such sets can define a single polynomial. If you’re going to take this approach, you need to say more like: We have (d-k)+1 points, each of which could take on <span class="math inline"><em>p</em></span> different values, so the number of <em>distinct</em> polynomials is <span class="math inline"><em>p</em><sup>(<em>d</em> − <em>k</em>)+1</sup></span>. Ta-da.</p></li>
</ol></li>
<li><p><strong>Lagrange Interpolation</strong>. I have an issue with their wording: Should just say “of degree 3” since it says <em>unique</em>. Whatever<a href="#fn64" class="footnoteRef" id="fnref64"><sup>64</sup></a></p>
<ol>
<li><p><span class="math inline">$ \Delta_{-1}(x) = \tfrac{(x-0)(x-1)(x-2)}{(-1-0)(-1-1)(-1-2)}$</span></p></li>
<li><p><span class="math inline">$ \Delta_{0}(x) = \frac{(x+1)(x-1)(x-2)}{(1)(-1)(-2)}$</span></p></li>
<li><p><span class="math inline">$ \Delta_{1}(x) = \frac{(x+1)(x-0)(x-2)}{(2)(1)(-1)}$</span></p></li>
<li><p><span class="math inline">$ \Delta_{2}(x) = \frac{(x+1)(x-0)(x-1)}{(3)(2)(1)}$</span></p></li>
<li><p><span class="math inline"><em>p</em>(<em>x</em>)=3<em>Δ</em><sub>−1</sub>(<em>x</em>)+1<em>Δ</em><sub>0</sub>(<em>x</em>)+2<em>Δ</em><sub>1</sub>(<em>x</em>)+0<em>Δ</em><sub>2</sub>(<em>x</em>)</span></p></li>
</ol></li>
<li><p><strong>Secret sharing</strong> Generate a degree 2 polynomial. Give each TA two points of it. Give each reader 1 point of it.<a href="#fn65" class="footnoteRef" id="fnref65"><sup>65</sup></a></p></li>
</ol>
<h3 id="polynomials-note">Polynomials Note</h3>
<ul>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>: If we have a polynomial p(x) of degree d, we can divide by a polynomial q(x) of degree <span class="math inline"><em>l</em><em>e</em></span> by using long division. The result will be: <span class="math inline"><em>p</em>(<em>x</em>)=<em>q</em>(<em>x</em>)<em>q</em>′(<em>x</em>)+<em>r</em>(<em>x</em>)</span> where<a href="#fn66" class="footnoteRef" id="fnref66"><sup>66</sup></a> <span class="math inline">deg(<em>r</em>)&lt;deg(<em>p</em>)</span>. Subtlety: When you rewrite p in quotient/remainder form like this, where you’ve explictly said what you’re dividing by (q), then <span class="math inline">deg(<em>r</em>)&lt;deg(<em>q</em>)</span> by definition.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span>: A non-zero polynomial of degree <span class="math inline"><em>d</em></span> has at most <span class="math inline"><em>d</em></span> roots.</p>
<ul>
<li><p><strong>Claim 1</strong> <span class="math inline">[<em>p</em>(<em>a</em>)=0] ⇒ [<em>p</em>(<em>x</em>)=(<em>x</em> − <em>a</em>)<em>q</em>(<em>x</em>)]</span> where <span class="math inline">deg(<em>p</em>)=<em>d</em></span> and <span class="math inline">deg(<em>q</em>)=<em>d</em> − 1</span>.</p></li>
<li><p><strong>Claim 2</strong>:<a href="#fn67" class="footnoteRef" id="fnref67"><sup>67</sup></a> If <span class="math inline"><em>p</em>(<em>x</em>)</span> has <span class="math inline"><em>d</em></span> distinct roots <span class="math inline"><em>a</em><sub><em>i</em></sub></span>, then <span class="math inline"><em>p</em>(<em>x</em>)</span> can be written as <span class="math inline"><em>p</em>(<em>x</em>)=<em>c</em>(<em>x</em> − <em>a</em><sub>1</sub>)(<em>x</em> − <em>a</em><sub>2</sub>)⋯(<em>x</em> − <em>a</em><sub><em>d</em></sub>)</span>.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span>: Given <span class="math inline"><em>d</em> + 1</span> pairs with all <span class="math inline"><em>x</em><sub><em>i</em></sub></span> distinct <span class="math inline">∃</span> unique <span class="math inline"><em>p</em>(<em>x</em>)</span> of degree (at most) d such that <span class="math inline"><em>p</em>(<em>x</em><sub><em>i</em></sub>)=<em>y</em><sub><em>i</em></sub>∀<em>i</em> ∈ {1, …, <em>d</em> + 1}</span>.</p></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Can specify any <span class="math inline"><em>d</em> + 1</span> polynomial with either (a) it’s coefficients (coefficient representation) <span class="math inline"><em>a</em><sub><em>i</em></sub></span>, or (2) a set of <span class="math inline"><em>d</em> + 1</span> points (value representation) contained by the polynomial. Can convert rep (a) to rep (b) by evaluating at the points. Can convert (b) to (a) with lagrange interpolation.</p></li>
<li><p>IMPORTANT: When they say “how many distinct polynomials go through these..” and whatever, they apparently always assume that the x points are ordered, and you’re only interested in the value of <span class="math inline"><em>p</em>(<em>x</em>)</span> at the next, as of yet unspecified, x point. Wtf?</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Rewriting <span class="math inline"><em>p</em>(<em>x</em>)</span> in quotient + remainder form and exploiting properties of roots,degree of the quotient, etc.</p></li>
<li><p>Induction on the degree <span class="math inline"><em>d</em></span> of a polynomial.</p></li>
<li><p>When thinking about number of polynomials in [], remember that a polynomial can be uniquely defined by its <em>coefficients</em>. Equivalently, can think of as defined by <span class="math inline"><em>d</em> + 1</span> points; Note that there can be <em>many</em> such sets of <span class="math inline"><em>d</em> + 1</span> points that define the same polynomial.</p></li>
</ul></li>
</ul>
<ul>
<li><p>Lecture outline:</p>
<ul>
<li><p>Finish polynomials and secret sharing</p></li>
<li><p>Finite fields: Abstract Algebra</p></li>
<li><p>Erasure Coding</p></li>
</ul></li>
<li><p>Note: the <span class="math inline"><em>d</em> + 1</span> points needed to specify any polynomial must have different x values (obvi).</p></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Proofs of uniqueness haven’t depended on whether <span class="math inline"><em>x</em></span> is reals, rationals, complex numbersbut not integers since no multiplicative inverses. Only works if modulo a prime <span class="math inline"><em>p</em></span> and finite element sets.</p></li>
<li><p>Can still generalize all to . Denote arithmetic mod <span class="math inline"><em>p</em></span> as field <span class="math inline"><em>F</em><sub><em>p</em></sub></span> or <span class="math inline"><em>G</em><em>F</em>(<em>p</em>)</span>.</p></li>
<li><p>Field def (informal): set with operations corresponding to addition/mult/div.</p></li>
<li><p>The number of degree <span class="math inline"><em>d</em></span> polynomials over <span class="math inline"><em>G</em><em>F</em>(<em>m</em>)</span> is <span class="math inline"><em>m</em><sup><em>d</em> + 1</sup></span>.</p></li>
</ul></li>
<li><p>Revisit of polynomial secret sharing (k of n).</p>
<ul>
<li><p>Need <span class="math inline"><em>p</em> &gt; <em>n</em></span> to hand out <span class="math inline"><em>n</em></span> shares.</p></li>
<li><p>For <span class="math inline"><em>b</em></span>-bit secret, need<a href="#fn68" class="footnoteRef" id="fnref68"><sup>68</sup></a> <span class="math inline"><em>p</em> &gt; 2<sup><em>b</em></sup></span>.</p></li>
<li><p><span> <em></em></span>There is always a prime between <span class="math inline"><em>n</em></span> and <span class="math inline">2<em>n</em></span>.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span> (error correcting codes)</p>
<ul>
<li><p><strong>Problem:</strong> Want to send message with <span class="math inline"><em>n</em></span> packets. Lossy channel: loses <span class="math inline"><em>k</em></span> packets.</p></li>
<li><p><strong>Question:</strong> Can you send <span class="math inline"><em>n</em> + <em>k</em></span> packets and recover message?<a href="#fn69" class="footnoteRef" id="fnref69"><sup>69</sup></a></p></li>
<li><p>Solution Idea: Use polynomials. “<em>Any</em> <span class="math inline"><em>n</em></span> packets (out of the <span class="math inline"><em>n</em> + <em>k</em></span>) should allow reconstruction of original <span class="math inline"><em>n</em></span> packet message.”<a href="#fn70" class="footnoteRef" id="fnref70"><sup>70</sup></a></p></li>
<li><p>Restated: Any <span class="math inline"><em>n</em></span> allow reconstruction of degree <span class="math inline"><em>n</em> − 1</span> polynomial.</p></li>
<li><p><strong>Erasure coding scheme:</strong> Message consists of <span class="math inline"><em>n</em></span> packets denoted <span class="math inline"><em>m</em><sub>0</sub>, <em>m</em><sub>1</sub>, …, <em>m</em><sub><em>n</em> − 1</sub></span>. Each <span class="math inline"><em>m</em><sub><em>i</em></sub></span> is packet.</p>
<ol>
<li><p>Choose prime <span class="math inline"><em>p</em> &gt; 2<sup><em>b</em></sup></span> for packet size <span class="math inline"><em>b</em></span> (num bits).</p></li>
<li><p><span class="math inline"><em>P</em>(<em>x</em>)=<em>m</em><sub><em>n</em> − 1</sub><em>x</em><sup><em>n</em> − 1</sup> + ⋯ + <em>m</em><sub>0</sub>mod<em>p</em></span>.</p></li>
<li><p>Send <span class="math inline"><em>P</em>(1),<em>P</em>(2),…,<em>P</em>(<em>n</em> + <em>k</em>)</span>.</p></li>
</ol></li>
<li><p>Any <span class="math inline"><em>n</em></span> of the <span class="math inline"><em>n</em> + <em>k</em></span> gives polynomial, and thus the message.</p></li>
</ul></li>
<li><p>Comparison: Erasure codes vs. secret sharing.</p>
<ul>
<li><p>Secret sharing: each share is size of whole secret.</p></li>
<li><p>Erasure: each share (a packet) is size <span class="math inline">1/<em>n</em></span> of whole secret.</p></li>
</ul></li>
<li><p>: Erasure codes</p>
<ul>
<li><p>Send message <span class="math inline">1, 4, 4</span> containing <span class="math inline"><em>n</em> = 3</span> numbers, up to <span class="math inline"><em>k</em> = 3</span> of which can be lost.</p></li>
<li><p>Make <span class="math inline"><em>P</em>(1)=1</span>, <span class="math inline"><em>P</em>(2)=4</span>, and <span class="math inline"><em>P</em>(3)=4</span>.</p></li>
<li><p>Work modulo 7 to accommodate at least <span class="math inline"><em>n</em> + <em>k</em> = 6</span> packets.</p></li>
<li><p>Can construct via linear system:<a href="#fn71" class="footnoteRef" id="fnref71"><sup>71</sup></a> <br /><span class="math display">$$\begin{aligned}
            P(1) &amp;= a_2 + a_1 + a_0 \equiv 1 \mod{7} \\
            P(2) &amp;= 4a_2 + 2a_1 + a_0 \equiv 4 \mod{7} \\
            P(3) &amp;= 2a_2 + 3a_1 + a_0 \equiv 4 \mod{7} \\
        \end{aligned}$$</span><br /> so <span class="math inline"><em>P</em>(<em>x</em>)=2<em>x</em><sup>2</sup> + 4<em>x</em> + 2</span>. Send packets <span class="math inline">(1, 1),(2, 4),(3, 4),(4, <em>P</em>(4)), (5, <em>P</em>(5)), (6, <em>P</em>(6))</span>.</p>
<p>Don’t forget to take mods</p></li>
</ul></li>
</ul>
<h3 id="error-correcting-codes">Error Correcting Codes</h3>
<ul>
<li><p><span><strong><em></em></strong></span>: (missing packets)</p>
<ul>
<li><p>Note: I’m only writing info here that I didn’t write in the previous section.</p></li>
<li><p>If each packet is a <span class="math inline"><em>b</em></span>-bit string, choose prime <span class="math inline"><em>p</em></span> to be any prime larger than <span class="math inline">2<sup><em>b</em></sup></span>.</p></li>
<li><p>Be careful to ensure that <span class="math inline"><em>n</em> + <em>k</em> ≤ <em>p</em></span>, which is usually pretty easy.</p></li>
<li><p>If receiver only gets <span class="math inline"><em>n</em> − 1</span> of the packets, there are exactly <span class="math inline"><em>p</em></span> polynomials of degree at most <span class="math inline"><em>n</em> − 1</span> that agree with the received packets.</p></li>
<li><p>“This error-correcting scheme is therefore : it can recover the n characters of the transmitted message from any n received characters, but recovery from any fewer characters is impossible.”</p></li>
<li><p>To prove that the linear system always has a solution and that it is unique (which is true), hint is to show that a certain determinant is non-zero.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span> (individual packets may be corrupted, but all are transmitted)</p>
<ul>
<li><p><strong></strong>: Rather than the message being the coefficients of the polynomial, now want to encode as what polynomial evaluates to. fml.</p></li>
<li><p>One can still guard against k general errors by transmitting only 2k additional packets or characters<a href="#fn72" class="footnoteRef" id="fnref72"><sup>72</sup></a>.</p></li>
<li><p>Encoded message: <span class="math inline"><em>c</em><sub>1</sub>, <em>c</em><sub>2</sub>, …, <em>c</em><sub><em>n</em> + 2<em>k</em></sub></span> where <span class="math inline"><em>c</em><sub><em>j</em></sub> = <em>P</em>(<em>j</em>)</span> for <span class="math inline">1 ≤ <em>j</em> ≤ <em>n</em> + 2<em>k</em></span>. At least <span class="math inline"><em>n</em> + <em>k</em></span> of these are received uncorrupted<a href="#fn73" class="footnoteRef" id="fnref73"><sup>73</sup></a></p></li>
<li><p>Receiver has to find <span class="math inline"><em>P</em>(<em>x</em>)</span>. Know that <span class="math inline"><em>P</em>(<em>i</em>)=<em>r</em><sub><em>i</em></sub></span> on at least <span class="math inline"><em>n</em> + <em>k</em></span> points, where <span class="math inline"><em>r</em><sub><em>i</em></sub></span> denotes the <span class="math inline"><em>i</em></span>th <em>received</em> value. There are <span class="math inline"><em>k</em></span> points where <span class="math inline"><em>P</em>(<em>i</em>)≠<em>r</em><sub><em>i</em></sub></span> because they have been corrupted (changed) during the transmission process.</p></li>
<li><p>If <span class="math inline"><em>e</em><sub>1</sub>, …, <em>e</em><sub><em>k</em></sub></span> packets corrupted, define degree <span class="math inline"><em>k</em></span> polynomial <span class="math inline"><em>E</em>(<em>x</em>)</span> as follows, and with relationship to <span class="math inline"><em>P</em>(<em>x</em>)</span>: <br /><span class="math display">$$\begin{aligned}
            E(x) &amp;= (x - e_1)(x-e_2)\cdots(x-e_k) \\
            P(i)~E(i) &amp;= r_i ~ E(i) \label{balls}
        \end{aligned}$$</span><br /> for <span class="math inline">1 ≤ <em>i</em> ≤ <em>n</em> + <em>k</em></span> where received points are of form <span class="math inline">(<em>i</em>, <em>r</em><sub><em>i</em></sub>)</span>. For any <span class="math inline"><em>i</em> = <em>e</em><sub><em>i</em></sub></span>, <span class="math inline"><em>E</em>(<em>i</em>)=0</span>. This is true because: (1) out of the <span class="math inline"><em>n</em> + 2<em>k</em></span> received, <span class="math inline"><em>n</em> + <em>k</em></span> match the desired <span class="math inline"><em>P</em>(<em>x</em>)</span> correctly, i.e. <span class="math inline"><em>P</em>(<em>i</em>)=<em>r</em><sub><em>i</em></sub></span> for <span class="math inline"><em>n</em> + <em>k</em></span> points and eq [balls] is obviously true. For the other points (the ones that got corrupted), <span class="math inline"><em>P</em>(<em>i</em>)</span> will be some (as of yet unknown) value that is not <span class="math inline"><em>r</em><sub><em>i</em></sub></span>. However, eq [balls] is still true because <span class="math inline"><em>E</em>(<em>x</em>)=0</span> for any <span class="math inline"><em>x</em></span> that was corrupted.</p></li>
<li><p>Eq [balls] is really <span class="math inline"><em>n</em> + 2<em>k</em></span> linear equations with <span class="math inline"><em>n</em> + 2<em>k</em></span> unknowns.</p>
<ul>
<li><p><strong>Unknowns are the coefficients</strong> of <span class="math inline"><em>E</em>(<em>x</em>)</span> and <span class="math inline"><em>Q</em>(<em>x</em>):=<em>P</em>(<em>x</em>)<em>E</em>(<em>x</em>)</span>. <br /><span class="math display">$$\begin{aligned}
                Q(x) &amp;= a_{n+k-1} x^{n+k-1} + \cdots + a_1 x + a_0 \\
                E(x) &amp;= (1) x^k + b_{k-1} x^{k-1} + \cdots + b_1 x + b_0
            \end{aligned}$$</span><br /></p></li>
</ul></li>
<li><p>Convention seems to be that, if we want to send a message of size <span class="math inline"><em>n</em></span>, we encode that message directly <strong><em>in order</em></strong> as <span class="math inline"><em>P</em>(1),⋯,<em>P</em>(<em>n</em>)</span>, starting for some reason at <span class="math inline">1</span>. We then encode the extra <span class="math inline"><em>k</em></span> parts as ordered eval of <span class="math inline"><em>P</em>(<em>n</em> + 1),⋯,<em>P</em>(<em>n</em> + <em>k</em>)</span>.</p></li>
<li><p>The <strong>degree of P(x) is</strong> <span class="math inline"><em>d</em><em>e</em><em>g</em>(<em>P</em>)=<em>n</em> − 1</span>. In other words, we map the desired <span class="math inline"><em>n</em></span>-point message to <span class="math inline">(<em>n</em> − 1)+1</span> points defining the degree <span class="math inline"><em>n</em> − 1</span> polynomial.</p></li>
<li><p>:</p>
<ul>
<li><p>Setup: Working over <span class="math inline"><em>G</em><em>F</em>(7)</span>. Message has <span class="math inline"><em>n</em> = 3</span> characters.</p></li>
<li><p><strong>UNKNOWN TO RECEIVER:</strong> Desired message: <span class="math inline">3, 0, 6</span>. Then we need <span class="math inline"><em>P</em>(<em>x</em>)</span> uniquely defined by the points <span class="math inline">(1, 3),(2, 0),(3, 6)</span>. Therefore, <span class="math inline"><em>P</em>(<em>x</em>)</span> is degree <span class="math inline"><em>n</em> − 1 = 2</span> with <span class="math inline">$P(x) = x^2 + x + 1 \pmod 7$</span>.</p></li>
<li><p><strong>KNOWN TO RECEIVER</strong>: Know that <span class="math inline"><em>n</em> = 3</span>, <span class="math inline"><em>k</em> = 1</span>, and therefore they know that the received message of size <span class="math inline"><em>n</em> + 2<em>k</em> = 5</span> has 1 corrupted letter. They know that the following polynomials take the respective forms<a href="#fn74" class="footnoteRef" id="fnref74"><sup>74</sup></a> <br /><span class="math display">$$\begin{aligned}
                    E(x) &amp;= x + e_0  \\
                    Q(x) &amp;= q_3 x^3 + q_2 x^2 + q_1 x + q_0 \\
                     &amp;= r_x E(x) 
                \end{aligned}$$</span><br /></p></li>
<li><p>Don’t forget to take mods of coefficients along the way.</p></li>
<li><p>: Given that we know <span class="math inline"><em>k</em> = 1</span> points will be corrupted, why is it <em>exactly</em> that we need to send <span class="math inline"><em>n</em> + 2<em>k</em> = 5</span> points? : See below. Basically, it is so we can guarantee that the recovered polynomial <span class="math inline"><em>P</em></span> is unique (and the one we sent).</p></li>
</ul></li>
</ul></li>
</ul>
<ul>
<li><p>Only going to write new information here.</p></li>
<li><p><strong>Problem</strong>:Communicate <span class="math inline"><em>n</em></span> packets <span class="math inline"><em>m</em><sub>1</sub>…<em>m</em><sub><em>n</em></sub></span> on noisy channel that corrupts <span class="math inline">≤<em>k</em></span> packets. Notice that it is <span class="math inline">≤<em>k</em></span> now.</p></li>
<li><p><strong>Reed Solomon Code</strong>: Make <span class="math inline"><em>P</em>(<em>x</em>)</span> of degree <span class="math inline"><em>n</em> − 1</span>. <br /><span class="math display">$$\begin{aligned}
        P(1) = m_1; \ldots ;  P(n) = m_n 
    \end{aligned}$$</span><br /></p></li>
<li><p>Send <span class="math inline"><em>P</em>(1),…,<em>P</em>(<em>n</em> + 2<em>k</em>)</span>.</p></li>
<li></li>
<li><p><a href="#fn75" class="footnoteRef" id="fnref75"><sup>75</sup></a>. Okay I think I know why we need <span class="math inline"><em>n</em> + 2<em>k</em></span> points. It is related to the fact that we need to guarantee the receiver will reconstruct the <em>unique</em> polynomial <span class="math inline"><em>P</em>(<em>x</em>)</span> as opposed to some other polynomial.</p></li>
<li><p>Claim: If two polynomials <span class="math inline"><em>P</em>(<em>x</em>)</span> and <span class="math inline"><em>P</em>′(<em>x</em>)</span> satisfy <span class="math inline"><em>P</em>(<em>i</em>)=<em>r</em><sub><em>i</em></sub></span> and <span class="math inline"><em>P</em>′(<em>i</em>′) = <em>r</em><sub><em>i</em></sub>′</span> for their own (separate) sets of <span class="math inline">≥<em>n</em> + <em>k</em></span> points in the received message of size <span class="math inline"><em>n</em> + 2<em>k</em></span>, then <span class="math inline"><em>P</em>(<em>x</em>)=<em>P</em>′(<em>x</em>)</span>.</p></li>
<li><p>Proof: We know that <span class="math inline">≤<em>k</em></span> (so at most k) packets are corrupted. This means that <span class="math inline"><em>P</em>(<em>x</em>)</span> and <span class="math inline"><em>P</em>′(<em>x</em>)</span> share <em>at least</em> <span class="math inline"><em>n</em></span> points in common (out of their respective <span class="math inline"><em>n</em> + <em>k</em></span> point sets), i.e. where for any of these points <span class="math inline"><em>r</em><sub><em>j</em></sub></span>, it is true that <span class="math inline"><em>P</em>(<em>j</em>)=<em>r</em><sub><em>j</em></sub> = <em>P</em>′(<em>r</em><sub><em>j</em></sub>)</span>. Since they are degree <span class="math inline"><em>n</em> − 1</span> polynomials that are uniquely defined by <span class="math inline"><em>n</em></span> points, it must be that <span class="math inline"><em>P</em>(<em>x</em>)=<em>P</em>′(<em>x</em>)</span>.</p></li>
<li><p>Lec then goes over example of <span class="math inline">3, 0, 6</span> from the note and works through it.</p></li>
<li><p>jargon: calls <span class="math inline"><em>E</em>(<em>x</em>)</span> the .</p></li>
<li><p>kind of annoyed that he keeps saying things like <span class="math inline"><em>P</em>(<em>x</em>)</span> is degree <span class="math inline">≤<em>n</em> − 1</span>, when the note seems to just say “equals”. Come back later and explain whether or not I should care.</p></li>
<li><p>However, says deg(E) = k.</p></li>
</ul>
<ul>
<li><p>Continues on general-error encoding example from note.</p></li>
<li><p>Technique is called .<a href="#fn76" class="footnoteRef" id="fnref76"><sup>76</sup></a></p></li>
<li><p>Wants to answer existence and uniqueness of <span class="math inline"><em>P</em>(<em>x</em>)</span> and <span class="math inline"><em>Q</em>(<em>x</em>)</span>. Existence is easy. n+2k in n+2k unknowns can be solved so yes it exists.</p></li>
<li><p>uniqueness requires proof by contradiction assuming two different solutions exist. I don’t see how this is any different from my claim/proof in the previous lecture. Time: 17:00. Identical proof as in note though regarding EQ = Q’E’.</p></li>
<li><p>. Proof techniques are enumeration and constructing bijections.</p></li>
<li><p>: A set is countably infinite if its elements can be put in one-to-one correspondence with the set of natural numbers.</p></li>
<li><p>Determining if two sets are <strong>same size</strong>.</p>
<ul>
<li><p>Make function <span class="math inline"><em>f</em> : <em>A</em> → <em>B</em></span>.</p></li>
<li><p>Show <span class="math inline"><em>f</em></span> is one-to-one, defined as <span class="math inline">∀<em>x</em>, <em>y</em> ∈ <em>A</em>, <em>x</em> ≠ <em>y</em> ⟹ <em>f</em>(<em>x</em>)≠<em>f</em>(<em>y</em>)</span>. Show <span class="math inline"><em>f</em></span> is onto, i.e. <span class="math inline">∀<em>s</em> ∈ <em>B</em>, ∃<em>c</em> ∈ <em>A</em>,  <em>s</em> = <em>f</em>(<em>c</em>)</span>.</p></li>
<li><p>If there exists bijection <span class="math inline"><em>f</em> : <em>A</em> → <em>B</em></span>, then <span class="math inline">|<em>A</em>|=|<em>B</em>|</span> (the cardinality of A is the same as cardinality of B).</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Equal to number of binary <span class="math inline"><em>n</em></span>-bit strings. In other words, there exists a bijection <span class="math inline"><em>f</em> : subsets →  n-bit strings</span>.</p></li>
<li><p>: For some subset <span class="math inline"><em>x</em></span> of <span class="math inline">{<em>a</em><sub>1</sub>, …, <em>a</em><sub><em>n</em></sub>}</span>, define <br /><span class="math display">$$\begin{aligned}
            f(x) &amp;= \bigg(g(x, a_1), \ldots, g(x, a_n) \bigg) \\
            g(x, a) &amp;= \begin{cases} 1 &amp; a \in x \\ 0 &amp; \text{otherwise} \end{cases}
        \end{aligned}$$</span><br /></p></li>
<li><p>Example: <span class="math inline"><em>S</em> = {1, 2, 3, 4, 5},<em>x</em> = {1, 3, 4}</span>. Then <span class="math inline"><em>f</em>(<em>x</em>)=(1, 0, 1, 1, 0)</span>.</p></li>
<li><p>The cardinality of the of <span class="math inline"><em>S</em></span> is <br /><span class="math display">$$\begin{aligned}
            |\mathcal{P}(S)| &amp;= |\{0, 1\}^n| = 2^n 
        \end{aligned}$$</span><br /> which is the number of n-bit binary strings, and <em>therefore</em> the number of subsets is also <span class="math inline">2<sup><em>n</em></sup></span> since <span class="math inline"><em>f</em></span> is a bijection.</p></li>
</ul></li>
<li><p><span><strong><em></em></strong></span> [38:00]</p>
<ul>
<li><p>Natural numbers = “the counting numbers”.</p></li>
<li><p>Any set S is if there exists a bijection between S and <em>some subset of</em> <span class="math inline">ℕ</span>.</p></li>
<li><p>If the subset of <span class="math inline">ℕ</span> is finite, then <span class="math inline"><em>S</em></span> has . If infinite subset then countably infinite and say it has “the same cardinality as <span class="math inline">ℕ</span>”.</p></li>
<li><p>Note, if a bijection exists from <span class="math inline"><em>A</em></span> to <span class="math inline"><em>B</em></span>, then we automatically know one exists from <span class="math inline"><em>B</em></span> to <span class="math inline"><em>A</em></span> because function inverse guaranteed.</p></li>
<li><p>Comparing cardinality of <span class="math inline">ℤ</span> to that of <span class="math inline">ℕ</span>: Define <span class="math inline"><em>f</em> : ℕ → ℤ</span> where <br /><span class="math display">$$\begin{aligned}
            f(n) = \begin{cases}
                n/2 &amp; \text{if n even} \\
                -(n+1)/2 &amp; \text{odd} 
            \end{cases}
        \end{aligned}$$</span><br /> and check (1) one-to-one by proof by cases on <span class="math inline"><em>x</em>, <em>y</em> ∈ ℕ</span> and combinations of one/both being even/odd, and (2) onto by for <span class="math inline"><em>z</em> ∈ ℤ</span>, cases where its negative/nonnegative and showing that it’s pre-image would be <span class="math inline">∈ℕ</span>.</p></li>
</ul></li>
</ul>
<ul>
<li><p>have natural ordering property where position of item in list is a natural number. One way of showing if list is countable is by of elements in that set. Enumerability <span class="math inline">≡</span> countability.</p></li>
<li><p>When enumerating, need to be careful that each element has a <em>finite</em> specified position in the list.</p></li>
<li><p>Any subset <span class="math inline"><em>T</em></span> of a countable set <span class="math inline"><em>S</em></span> is countable.</p></li>
<li><p>All countably infinite sets have the same cardinality.</p></li>
<li><p>For finite sets <span class="math inline"><em>S</em><sub>1</sub></span> and <span class="math inline"><em>S</em><sub>2</sub></span>, cardinality of <span class="math inline"><em>S</em><sub>1</sub> × <em>S</em><sub>2</sub></span> is <span class="math inline">|<em>S</em><sub>1</sub>|×|<em>S</em><sub>2</sub>|</span>.<a href="#fn77" class="footnoteRef" id="fnref77"><sup>77</sup></a></p></li>
<li><p>for analyzing the cardinality of <span class="math inline">ℝ</span>.</p>
<ul>
<li><p>Try enumerating. View as a table. Construct a number along the diagonal: digit <span class="math inline"><em>i</em></span> is 7 if row <span class="math inline"><em>i</em></span>’s <span class="math inline"><em>i</em></span>th digit is not 7, 6 otherwise. Implies that the diagonal number is not in the list<a href="#fn78" class="footnoteRef" id="fnref78"><sup>78</sup></a>, but it is somehow in <span class="math inline">ℝ</span>, which is a .</p></li>
<li><p>Note: We can say that, <em>since</em> the numbers in the range <span class="math inline">[0, 1]</span> are uncountable, and since they are a subset of <span class="math inline">ℝ</span>, that <span class="math inline">ℝ</span> is uncountable.</p></li>
</ul></li>
<li><p>Can show a bijection between two uncountable sets, e.g. <span class="math inline"><em>f</em> : ℝ<sup>+</sup> → [0, 1]</span>.</p>
<p><span><strong><em></em></strong></span>:</p>
<ul>
<li><p>. Why is this supposed to be interesting? Proof by cases leads to contradiction.</p></li>
<li><p>Any definable collection is a set. Example: <br /><span class="math display">$$\begin{aligned}
        \exists Y \forall x (x \in Y \iff P(x))
        \end{aligned}$$</span><br /> and “y is the set of elements that satisfies P(x).” Can apply to barber paradox.</p></li>
<li><p>Key notion here is .</p></li>
</ul></li>
<li><p>The : write program that checks if other program halts: <span class="math inline"><em>H</em><em>A</em><em>L</em><em>T</em>(<em>P</em>, <em>I</em>)</span> where <span class="math inline"><em>P</em></span> is a program, <span class="math inline"><em>I</em></span> is input. Determines if <span class="math inline"><em>P</em>(<em>I</em>)</span> [P run on I] halts or loops forever. Program itself is some text string, which is why it (a program) can be fed as input to a program. <em>This enables self-reference in computation. One program executing on itself is possible</em>.</p></li>
<li><p>HALT does <strong>not</strong> exist. Proof: Assume there is a program called HALT and a program TURING(P).</p>
<ol>
<li><p>If HALT(P, P) = “”. then define Turing such that it goes into an infinite loop.</p></li>
<li><p>Otherwise, Turing halts immediately. It basically does the opposite.</p></li>
<li><p>Assumptions: there is a program HALT and text that are both the programs TURING and HALT.</p></li>
<li><p>Question: Does Turing(Turing) halt? Proof by cases.</p>
<ul>
<li><p>Assume it does halt. Then HALT(Turing, Turing) = halts. Then we TURING(turing) loops forever. Contradiction.</p></li>
<li><p>Assume it loops forever. Then HALT(turing, turing) <span class="math inline">≠</span> halts. Then Turing(turing) halts. Contradiction.</p></li>
</ul>
<p>and so program HALT does not exist.</p></li>
</ol></li>
</ul>
<p><span><strong><em></em></strong></span></p>
<ul>
<li><p>Goes over Turing machine. Infinite tape with characters. Can be in a state, read a character. More left/right and read/write charcter.</p></li>
<li><p>Universal turing machine: tape could be a description of a turing machine.</p></li>
<li><p>Church proved equivalent theorem about .</p></li>
<li><p>Godel proved his : any formal system is either inconsistent [false statement can be proven] or incomplete [the is no proof for some sentence in the system]. Godel also showed every statement corresponds to a natural number. wtf.</p></li>
</ul>
<p><span><strong><em></em></strong></span>:</p>
<ul>
<li><p>Related to questions of the form “How many given [condition]?”</p></li>
<li><p>: Objects made by choosing from <span class="math inline"><em>n</em><sub>1</sub></span> then <span class="math inline"><em>n</em><sub>2</sub></span>, , then <span class="math inline"><em>n</em><sub><em>k</em></sub></span>, then the number of objects is <br /><span class="math display">$$\begin{aligned}
        n_1 \times n_2 \times \cdots \times n_k
    \end{aligned}$$</span><br /></p></li>
<li><p>General case is “how many different samples of size <span class="math inline"><em>k</em></span> from <span class="math inline"><em>n</em></span> numbers <strong>without replacement</strong>.” Answer: <br /><span class="math display">$$\begin{aligned}
        n \times (n-1) \times \cdots \times (n - k + 1) &amp;= \dfrac{n!}{(n-k)!} \quad \text{[{\textcolor{Maroon}{\textbf{$^nP_k$}}}]} 
    \end{aligned}$$</span><br /></p></li>
<li><p>If order doesn’t matter, count ordered objects and then divide by number of orderings<a href="#fn79" class="footnoteRef" id="fnref79"><sup>79</sup></a>. Have <span class="math inline"><em>n</em></span> objects and want to choose <span class="math inline"><em>k</em></span>? <br /><span class="math display">$$\begin{aligned}
        \dfrac{n!}{(n-k)!\times k!}     &amp;= {n \choose k}
    \end{aligned}$$</span><br /></p></li>
<li><p>Suppose sampling with replacement but order doesn’t matter. Famous example is : <em>How many ways can Bob and Alice split 5 dollar bills?</em> For each of 5 dollars pick Bob or Alice (<span class="math inline">2<sup>5</sup></span>), “then divide out order??” Let <span class="math inline"><em>a</em></span> denote number of dollars for Alice, similarly for bob such that <span class="math inline"><em>a</em> + <em>b</em> = 5</span>, or in more general case <span class="math inline"><em>a</em> + <em>b</em> = <em>k</em></span>. There are apparently <span class="math inline"><em>k</em> + 1</span> ways.</p></li>
<li><p>General case[48:00]: If want to split up between, say, <span class="math inline"><em>k</em> = 3</span>, can split with : <span class="math inline">* * | * | * *</span>. Each sequence of stars and bars <span class="math inline">⟹</span> split.</p></li>
<li><p>If there is a 1-to-1 mapping between two sets, they have the same size.</p></li>
<li><p>: For disjoint <span class="math inline"><em>S</em></span> and <span class="math inline"><em>T</em></span>, <span class="math inline">|<em>S</em> ∪ <em>T</em>|=|<em>S</em>|+|<em>T</em>|</span>.</p></li>
<li><p>: <span class="math inline">∀<em>S</em>,  <em>T</em>,   |<em>S</em> ∪ <em>T</em>|=|<em>S</em>|+|<em>T</em>|−|<em>S</em> ∩ <em>T</em>|</span>.</p></li>
</ul>
<p><span> </span><span><strong><em></em></strong></span> <span class="math inline"><em>k</em></span> stars <span class="math inline"><em>n</em> − 1</span> bars. There are <br /><span class="math display">$$\begin{aligned}
{n+k-1 \choose n-1} = {(n - 1) + k \choose n-1}  = {n+k-1 \choose k} \end{aligned}$$</span><br /> in other words, <span class="math inline"><em>n</em> + <em>k</em> − 1</span> positions from which to choose <span class="math inline"><em>n</em> − 1</span> bar positions. <span style="font-variant: small-caps;">Wikipedia version:</span><br />
</p>
<p>[Theorem one] <span class="math inline">∀<em>n</em>, <em>k</em> ∈ ℤ<sup>+</sup></span> : the number of k-tuples of <strong>positive</strong> integers, whose sum = n, is <span class="math inline">$\binom{n-1}{k -1}$</span> Translation: If each person must get something, there are <span class="math inline">$\binom{n-1}{k -1}$</span> ways to split <span class="math inline"><em>n</em></span> stars up among <span class="math inline"><em>k</em> + 1</span> people.</p>
<p>[Theorem two] <span class="math inline">∀<em>n</em>, <em>k</em> ∈ ℤ<sup>+</sup></span> : the number of k-tuples of <strong>non-negative</strong> integers, whose sum = n, is <span class="math inline">$\binom{n+k-1}{k -1} = \binom{n+k-1}{n} $</span>. Translation: In general case, there are <span class="math inline">$\binom{n+k-1}{k -1} = \binom{n+k-1}{n} $</span> ways to split <span class="math inline"><em>n</em></span> stars up among <span class="math inline"><em>k</em> + 1</span> people.</p>
<p>Since the above is confusing, here is the clearest possible way I can state it: If asked, how many ways to split up <span class="math inline"><em>n</em></span> [things] among <span class="math inline"><em>k</em></span> [people]? The answer is always <br /><span class="math display">$$\begin{aligned}
    \binom{n + k - 1}{k - 1}\end{aligned}$$</span><br /></p>
<p><span><strong><em></em></strong></span></p>
<ul>
<li><p>How many 3-bit strings?</p>
<p><img src="StringTree.PNG" alt="image" style="width:30.0%" /></p></li>
<li><p>How many outcomes for <span class="math inline"><em>k</em></span> coin tosses? <span class="math inline">2<sup><em>k</em></sup></span>.</p></li>
<li><p>How many 10 digit numbers? <span class="math inline">10<sup><em>k</em></sup></span>.</p></li>
<li><p>How many <span class="math inline"><em>n</em></span> digit base <span class="math inline"><em>m</em></span> numbers? <span class="math inline"><em>m</em><sup><em>n</em></sup></span>.</p></li>
<li><p>How many <span class="math inline"><em>f</em></span> mapping <span class="math inline"><em>S</em></span> to <span class="math inline"><em>T</em></span>? <span class="math inline">|<em>T</em>|<sup>|<em>S</em>|</sup></span>, because <span class="math inline">∀<em>s</em><sub><em>i</em></sub> ∈ <em>S</em></span> have <span class="math inline">|<em>T</em>|</span> choices for <span class="math inline"><em>f</em>(<em>s</em><sub><em>i</em></sub>)</span>.</p></li>
<li><p>How many of degree <span class="math inline"><em>d</em></span> modulo <span class="math inline"><em>p</em></span>? <span class="math inline"><em>p</em><sup><em>d</em> + 1</sup></span> coefficient choices and/or choices of the unique <span class="math inline"><em>d</em> + 1</span> points (both lead to same answer).</p></li>
<li><p>How many 10 digit numbers <em>without repeating a digit?</em>. <span class="math inline">10 × 9 × ⋯ × 1 = 10!</span>.</p></li>
<li><p>How many 1-to-1 functions from <span class="math inline">|<em>S</em>|</span> to <span class="math inline">|<em>S</em>|</span>? <span class="math inline">|<em>S</em>|!</span>.</p></li>
<li><p>How many poker hands? Number of orderings for a given poker hand is <span class="math inline">5!</span>, so answer is <span class="math inline">52!/(5!47!)</span>.</p></li>
<li><p>How many different 5 star and 2 bar diagrams? 7 positions in which to place the <span class="math inline">2</span> bars. <span class="math inline">${7 \choose 2}$</span> ways splitting <span class="math inline">5</span> dollars among 3 people.</p></li>
</ul>
<h3 id="combinatorial-proofs">Combinatorial Proofs</h3>
<p><span> </span></p>
<ul>
<li><p>LHS. Number of subsets of size <span class="math inline"><em>k</em> + 1</span> from set of size <span class="math inline"><em>n</em></span>.</p></li>
<li><p>RHS. Ask yourself: What’s another way I could find all subsets of size <span class="math inline"><em>k</em> + 1</span>?</p>
<ul>
<li><p>Well, I could count the number of subsets that include the element <span class="math inline">min(<em>A</em>)</span>. This means I have <span class="math inline"><em>k</em></span> elements out of the remaining <span class="math inline"><em>n</em> − 1</span> to choose from, i.e. <span class="math inline">$\binom{n-1}{k}$</span>. That takes care of all subsets including <span class="math inline">min(<em>A</em>)</span>.</p></li>
<li><p>What about subsets where the smallest element is the <em>second-smallest</em> element in <span class="math inline"><em>A</em></span>?<a href="#fn80" class="footnoteRef" id="fnref80"><sup>80</sup></a> Now we have <span class="math inline"><em>k</em></span> elements out of the remaining <span class="math inline"><em>n</em> − 2</span> to choose from, i.e. <span class="math inline">$\binom{n-2}{k}$</span>, and the pattern emerges.</p></li>
</ul></li>
<li><p>Therefore, the <span class="math inline"><em>j</em></span>th term on the RHS represents the number of subsets of size <span class="math inline"><em>k</em></span> where the smallest item in the (<span class="math inline"><em>j</em></span>th) subset is the <span class="math inline"><em>j</em></span>th smallest element in <span class="math inline"><em>A</em></span>.</p></li>
</ul>
<h3 id="textbook-rosen-notes">Textbook (Rosen) Notes</h3>
<ul>
<li><p>If <span class="math inline"><em>A</em><sub>1</sub>, …, <em>A</em><sub><em>m</em></sub></span> are finite sets, then number of elements in the Cartesian product of these sets is</p>
<p>[enhanced, colback=green!40!gray, colframe=green!75!black, colbacktitle=gray!20!black,fonttitle=<strong>, frame hidden, title=<span style="font-variant: small-caps;">Equation</span>, boxrule=0pt,titlerule=1mm, titlerule style=gray!50!black, width=0.4, top=-13pt, enlarge left by=0mm, boxsep=1pt ] <br /><span class="math display">$$\begin{aligned}
		|A_1 \times \cdots \times A_m| = |A_1|  \cdots |A_m|
		\end{aligned}$$</span><br /></strong></p></li>
<li><p>An of elements of a set is an unordered selection of <span class="math inline"><em>r</em></span> elements from the set. Thus, an r-combination is simply a subset of the set with <span class="math inline"><em>r</em></span> elements. The number of <span class="math inline"><em>r</em></span>-combinations from a set of <span class="math inline"><em>n</em></span> elements is often denoted as <span class="math inline">$\binom{n}{r}$</span>.</p></li>
</ul>
<p><span> </span><span><strong><em></em></strong></span> and related stuff.</p>
<p>[enhanced, colback=green!40!gray, colframe=green!75!black, colbacktitle=gray!20!black,fonttitle=<strong>, frame hidden, title=<span style="font-variant: small-caps;">Binomial Theorem</span>, boxrule=0pt,titlerule=1mm, titlerule style=gray!50!black, width=0.4, top=-13pt, enlarge left by=0mm, boxsep=1pt ] <br /><span class="math display">$$\begin{aligned}
		
    (x+y)^n = \sum_{j=0}^{n} \binom{n}{j} x^{n-j} y^j

		\end{aligned}$$</span><br /></strong></p>
<p>which can be proved by counting the number of <span class="math inline"><em>x</em><sup><em>n</em> − <em>j</em></sup><em>y</em><sup><em>j</em></sup></span> terms. Since we have <span class="math inline"><em>n</em></span> products of sums <span class="math inline"><em>x</em> + <em>y</em></span>, we would need to <em>choose</em> <span class="math inline"><em>n</em> − <em>j</em></span> x’s from the <span class="math inline"><em>n</em></span> sums. But this is just <span class="math inline">$\binom{n}{n - j} = \binom{n}{j}$</span>. Damn.</p>
<p>[enhanced, colback=green!40!gray, colframe=green!75!black, colbacktitle=gray!20!black,fonttitle=<strong>, frame hidden, title=<span style="font-variant: small-caps;">Corollaries to the Binomial Theorem</span>, boxrule=0pt,titlerule=1mm, titlerule style=gray!50!black, width=0.4, top=-13pt, enlarge left by=0mm, boxsep=1pt ] <br /><span class="math display">$$\begin{aligned}
		
    \sum_{k=0}^{n} \binom{n}{k}         &amp;= 2^n  \\
    \sum_{k=0}^{n} (-1)^k \binom{n}{k}  &amp;= 0    \\
    \sum_{k=0}^{n} (2)^k \binom{n}{k}   &amp;= 3^n  

		\end{aligned}$$</span><br /></strong></p>
<p>where <em>all</em> of these can be proven very easily using the Binomial Theorem (Hint: Think about what each implies about the values of <span class="math inline"><em>x</em></span> and <span class="math inline"><em>y</em></span>).<br />
<span> </span><span><strong><em></em></strong></span>.</p>
<p>[enhanced, colback=green!40!gray, colframe=green!75!black, colbacktitle=gray!20!black,fonttitle=<strong>, frame hidden, title=<span style="font-variant: small-caps;">Pascal’s Identity and Vandermonde’s Identity</span>, boxrule=0pt,titlerule=1mm, titlerule style=gray!50!black, width=0.4, top=-13pt, enlarge left by=0mm, boxsep=1pt ] <br /><span class="math display">$$\begin{aligned}
		
    \binom{n+1}{k} &amp;= \binom{n}{k-1}  + \binom{n}{k} ~~ {\footnotesize{\text{{\textcolor{Maroon}{\textbf{$PASCAL$}}}}}} \\
    \binom{m + n}{r} &amp;= \sum_{k=0}^{r} \binom{m}{r - k}\binom{n}{k} ~~ {\footnotesize{\text{{\textcolor{Maroon}{\textbf{$VAND.$}}}}}}

		\end{aligned}$$</span><br /></strong></p>
<p><span> </span>Note: It seems pretty popular to think about <span class="math inline">$\binom{n}{k}$</span> as “the number of bit strings of length <span class="math inline"><em>n</em></span> containing <span class="math inline"><em>k</em></span> ones.”</p>
<p><span> </span></p>
<ul>
<li><p>If need bijection <span class="math inline"><em>f</em> : (1, ∞)→(0, 1)</span>, don’t get too caught up with how any particular number should be mapped. Instead, think about what functions <em>over the given domain</em> map a positive real number above 1 to the interval 0, 1. The function they use is <span class="math inline">1/<em>x</em></span>. Then show it’s one-to-one and onto in order to prove bijection.</p></li>
<li><p>To check if two sets <span class="math inline"><em>A</em>, <em>B</em></span> are <em>equal</em> (not just same size), check both that <span class="math inline"><em>A</em> ⊆ <em>B</em></span> and <span class="math inline"><em>B</em> ⊆ <em>A</em></span>.</p></li>
</ul>
<p><span> </span></p>
<p>[<span class="math inline">→</span>]</p>
<p>: Given just <span class="math inline"><em>N</em></span> and <span class="math inline"><em>e</em></span>, how to quickly find <span class="math inline"><em>d</em></span>? You can’t unless you know the factors of <span class="math inline"><em>N</em></span>.</p>
<p>: What is the general meaning of ’signature of x’?</p>
<p>Write everything here about meaning of <em>relatively prime to [a number]</em> and what it implies/how to think about it.</p>
<p>[<span class="math inline">⋆</span>]</p>
<p>Definition: <span class="math inline"><em>a</em></span> rel prime to <span class="math inline"><em>b</em></span> iff <span class="math inline">gcd(<em>a</em>, <em>b</em>)=1</span></p>
<p>Means that the two numbers share no common factor.</p>
<p>Multiplicative inverse of <span class="math inline"><em>a</em></span> exists mod <span class="math inline"><em>b</em></span> and vice versa.<a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a></p>
<p>If inverse exists, then it is <em>also</em> relatively prime with the other number. This should be obvious because the inverse of the inverse exists (it is the original number) which means it must be rel prime.</p>
<p>: For any modulus <span class="math inline"><em>n</em></span> and any integer <span class="math inline"><em>a</em></span> coprime to <span class="math inline"><em>n</em></span>, <br /><span class="math display">$$\begin{aligned}
            a^{\varphi(n)} \equiv 1 \pmod n
        \end{aligned}$$</span><br /> where <span class="math inline"><em>φ</em>(<em>n</em>)</span> denotes <strong>Euler’s totient function</strong> which counts the number of integers between 1 and <span class="math inline"><em>n</em></span> <em>that are coprime with <span class="math inline"><em>n</em></span></em>. <br /><span class="math display">$$\begin{aligned}
            \varphi(n) &amp;= n \prod_{p|n} \big(1 - \frac{1}{p} \big) \\
             \gcd(m, n) = 1 &amp;\implies \varphi(mn) = \varphi(m)\varphi(n) \\
             \varphi(p^k) &amp;= p^k \big(1 - \frac{1}{p} \big)
        \end{aligned}$$</span><br /></p>
<p>: a theorem of number theory, which states that, if one knows the remainders of the division of an integer n by several integers, then one can determine uniquely the remainder of the division of n by the product of these integers, under the condition that the divisors are pairwise coprime.</p>
<p>Any RSA scheme is considered broken/breakable if knowing <span class="math inline"><em>N</em></span> allows one to deduce the value of <span class="math inline">(<em>p</em> − 1)(<em>q</em> − 1)</span>, where you’re only given <span class="math inline"><em>N</em></span>, not its factors. This is because, equivalently, breaking RSA means figuring out the value of <span class="math inline">$d = e^{-1} \pmod{(p-1)(q -1)}$</span>.</p>
<p>Also, unbreakable means at least as difficult as ordinary RSA. So, if you can make a bridge between the problem you’re doing and the problem of ordinary RSA (given just <span class="math inline"><em>N</em>, <em>e</em></span>, find <span class="math inline"><em>d</em></span>), that suffices.</p>
<p>: How to prove correctness of RSA?</p>
<p><span> </span></p>
<ul>
<li><p>Walkthrough of how smart person would approach “What is <span class="math inline">$3^{240} \pmod{77} $</span>”</p>
<ol style="list-style-type: decimal">
<li><p><em>Oh, 77 is 11 <span class="math inline">×</span> 7, so I could think of as <span class="math inline">$\pmod{77} = \pmod{pq}$</span>.</em></p></li>
<li><p><em>From things theorems like  [med], I know that <br /><span class="math display">$$x^y \pmod{pq} \equiv_{pq} (x^{y})^{1 \pmod{(p-1)(q - 1)}} \equiv_{pq} x^{y\pmod{(p-1)(q - 1)}}$$</span><br /></em></p></li>
<li><p><em>So I can rewrite and solve as <br /><span class="math display">$$3^{240} \equiv_{pq}  3^{240\pmod{(10-1)(7-1)}} \equiv_{pq} 3^{240\pmod 60} \equiv_{pq} 3^{0} \equiv_{pq} 1$$</span><br /></em></p></li>
</ol></li>
<li><p>Write about polynomial intersections here. <span class="math inline"><em>P</em>(<em>x</em>)−<em>Q</em>(<em>x</em>)=0</span> is max deg 4, so it has 4 roots, answer is 4.</p></li>
<li><p>Note: <span class="math inline">$n + x \equiv_n x \pmod n$</span>.</p></li>
<li><p>Note: Modulo over polynomials should be <em>prime</em>.</p></li>
<li><p>General errors. Remember that for <span class="math inline"><em>E</em>(<em>x</em>)=∏<sub><em>i</em></sub>(<em>x</em> − <em>e</em><em>r</em><em>r</em><sub><em>i</em></sub>)</span>, the <span class="math inline"><em>e</em><em>r</em><em>r</em><sub><em>i</em></sub></span> is an <span class="math inline"><em>x</em></span> value (!!!) and NOT a <span class="math inline"><em>y</em></span> value. It is an index.</p></li>
</ul>
<p><span> </span></p>
<ul>
<li><p>. If <span class="math inline"><em>k</em></span> bars and <span class="math inline"><em>n</em></span> stars, <span class="math inline">$\binom{n + k}{k} =  \binom{n + k}{n}$</span> ways. I promise.</p></li>
<li><p>. Convert to stars and bars problem with (numBins - 1) bars.</p></li>
<li><p>Don’t forget the general sum rule: <span class="math inline">∀<em>S</em>,  <em>T</em>,   |<em>S</em> ∪ <em>T</em>|=|<em>S</em>|+|<em>T</em>|−|<em>S</em> ∩ <em>T</em>|</span>.</p></li>
</ul>
<p><span> </span></p>
<p>[<span class="math inline">→</span>]</p>
<p>Meaning of “undecidable”? an undecidable problem is a decision problem for which it is known to be impossible to construct a single algorithm that always leads to a correct yes-or-no answer.</p>
<p>Master: halting problem, programs that return themselves.</p>
<p>: A program that prints itself.</p>
<blockquote>
<p><code>Print out the following sentence twice, the second time in quotes: Print out the following sentence twice, the second time in quotes:</code></p>
</blockquote>
<p>[<span class="math inline">⇝</span>]</p>
<p>We can always write quines in any programming language.</p>
<p>Another example:</p>
<blockquote>
<p>(Quine “s”) (s “s”)</p>
</blockquote>
<p>which, if passed in <span class="math inline"><em>s</em> = <em>Q</em><em>u</em><em>i</em><em>n</em><em>e</em></span>, will output (Quine “s”), which means we run the string <span class="math inline"><em>s</em></span> (now interpreted as a program) on itself.</p>
<p><span> <em>Given any program <span class="math inline"><em>P</em>(<em>x</em>, <em>y</em>)</span>, we can always “convert it” to another program <span class="math inline"><em>Q</em>(<em>x</em>)</span> such that <span class="math inline"><em>Q</em>(<em>x</em>)=<em>P</em>(<em>x</em>, <em>Q</em>)</span>, i.e. Q behaves exactly as P would if its second input is the description of the program Q.</em></span></p>
<p>.</p>
<p>[]</p>
<p>Proof relies on (1) self-reference, and (2) fact that we can’t separate programs from data.</p>
<p>Problem: Given the <strong>description P of a program</strong> and its input, write a program <code>TestHalt</code> that behaves as: <br /><span class="math display">$$\begin{aligned}
            TestHalt(P, x) = \begin{cases}
                \text{``yes''} &amp; \text{if P halts on input x} \\
                \text{``no''} &amp; \text{if P loops on input x} 
            \end{cases}
        \end{aligned}$$</span><br /></p>
<p>Proof: Try feeding program P the input P (itself as bitstring). Define</p>
<pre><code>            def Turing(P):
                if TestHalt(P, P) == &quot;yes&quot;:
                    loop forever
                else:
                    halt
        </code></pre>
<p>and consider behavior of Turing(Turing). It leads to proof by contradiction that TestHalt(P, P) cannot exist, since that was our main assumption this whole time.</p>
<p>[<strong>HARD</strong>]</p>
<p>[]</p>
<p>General pattern to recognize for problem-solving: Try <strong>reducing</strong> (changing) the problem into the general form of the halting problem.</p>
<p><span> </span></p>
<p>[<span class="math inline">⋆</span>]</p>
<p>Repeated squaring: It’s easier if you write within the equation as you go. Example: <br /><span class="math display">$$x^{16} \pmod y  = (x^2)^8 \pmod y = ((x^2)^2)^4 \pmod y = \cdots$$</span><br /></p>
<p>Write down cardinality of as many sets as possible and whether or not they are countable.</p>
<p>Rational numbers have decimal expansions that are either finite or periodic.</p>
<p><span> </span><em>Note: This lecture (23) corresponds to <strong>Note 14</strong> (Combinations of Events).</em><br />
<span> </span>.</p>
<ul>
<li><p>A and B positively correlated: <span class="math inline"><em>P</em><em>r</em>(<em>A</em>|<em>B</em>)&gt;<em>P</em><em>r</em>(<em>A</em>)</span>; Negatively correlated if <span class="math inline"><em>P</em><em>r</em>(<em>A</em>|<em>B</em>)&lt;<em>P</em><em>r</em>(<em>A</em>)</span></p></li>
<li><p><span class="math inline"><em>B</em> ⊂ <em>A</em>⟹</span> A and B positively correlated.</p></li>
<li><p><span class="math inline"><em>A</em> ∩ <em>B</em> = ∅⟹</span> A and B negatively correlated.</p></li>
<li><p>Total probability rule: <span class="math inline">$Pr(B) = Pr(A \cap B) + Pr(\bar{A} \cap B)$</span>.</p></li>
<li><p>: If <span class="math inline"><em>P</em><em>r</em>(<em>A</em>|<em>B</em>)&gt;<em>P</em><em>r</em>(<em>A</em>)</span>, then <span class="math inline"><em>P</em><em>r</em>(<em>B</em>|<em>A</em>)&gt;<em>P</em><em>r</em>(<em>B</em>)</span>.</p></li>
<li><p>: If <span class="math inline"><em>P</em><em>r</em>(<em>C</em>|<em>A</em>)&gt;<em>P</em><em>r</em>(<em>C</em>|<em>B</em>)</span>, then <span class="math inline"><em>P</em><em>r</em>(<em>A</em>|<em>C</em>)&gt;<em>P</em><em>r</em>(<em>B</em>|<em>C</em>)</span>.</p></li>
<li><p>See lec at for square-space probability illustration.</p></li>
</ul>
<p><span> </span>. Two events <span class="math inline"><em>A</em></span> and <span class="math inline"><em>B</em></span> are independent if any of the (equivalent) statements hold:<span> </span> Examples:</p>
<p>[<span class="math inline">→</span>]</p>
<p>When rolling two dice, one blue and one red, define events <span class="math inline"><em>A</em> = sum is 7</span> and <span class="math inline"><em>B</em> = red die is 1</span>. : Are these independent events?<a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a> : Yes.</p>
<p>Now define events <span class="math inline"><em>A</em> = sum is 3</span> and <span class="math inline"><em>B</em> = red die is 1</span>. : Are these independent events? : no.</p>
<p><span> </span>. Events <span class="math inline">{<em>A</em><sub><em>j</em></sub>,  <em>j</em> ∈ <em>J</em>}</span> are mutually independent if <span> </span> for all finite <span class="math inline"><em>K</em> ⊆ <em>J</em></span>.<br />
</p>
<ul>
<li><p><span> <em>If all <span class="math inline"><em>K</em><sub><em>n</em></sub></span> are pairwise disjoint finite subsets of <span class="math inline"><em>J</em></span>, then events <span class="math inline"><em>V</em><sub><em>n</em></sub></span> defined by <span class="math inline">{<em>A</em><sub><em>j</em></sub>, <em>j</em> ∈ <em>K</em><sub><em>n</em></sub>}</span> are mutually independent.</em></span> Proof is in Note 25 example 2.7.</p></li>
<li><p><span class="math inline">(<em>A</em>, <em>B</em>, <em>C</em>, …, <em>G</em>, <em>H</em> mutually indep. )⟹(<em>A</em>, <em>B</em><sup><em>C</em></sup>, <em>C</em>, …, <em>G</em><sup><em>C</em></sup>, <em>H</em> mutually indep. )</span>. <strong>Inductive Proof</strong>. Need to show eq [mutualIndep] holds regardless of which events we take complement of or not. Proceed by induction on <span class="math inline"><em>n</em></span>, <em>the number of complements</em>. For <span class="math inline"><em>n</em> = 0</span>, this is the normal definition of mutual independence. Assume true for <span class="math inline"><em>n</em></span>. . For <span class="math inline"><em>n</em> + 1</span>, need<a href="#fn83" class="footnoteRef" id="fnref83"><sup>83</sup></a> <br /><span class="math display">$$\begin{aligned}
        A \cap B^c \cap C \cap \cdots \cap G^c \cap H = X \cap H ~ \setminus ~ X \cap G \cap H
    \end{aligned}$$</span><br /> where <span class="math inline"><em>X</em> := <em>A</em> ∩ <em>B</em><sup><em>c</em></sup> ∩ <em>C</em> ∩ ⋯ ∩ <em>F</em></span>. Recognize that <span class="math inline"><em>X</em> ∩ <em>G</em> ∩ <em>H</em>  ⊂  <em>X</em> ∩ <em>H</em></span>.</p></li>
</ul>
<p><span> </span><em>Note: This lecture (25) corresponds to <strong>Note 16</strong> (Random Variables, Distribution, Expectation).</em><br />
<span> </span>. Have <span class="math inline"><em>n</em></span> bins and <span class="math inline"><em>m</em> &lt; <em>n</em></span> balls. Randomly (uniformly) throw balls, one by one, into bins. : What is the probability that after some <span class="math inline"><em>m</em></span> balls, that we don’t have any collisions? (no two balls in same bin)<a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a>. Result: <br /><span class="math display">$$\begin{aligned}
    Pr(\text{no collision}) \approx e^{- \frac{m^2}{2n} }\end{aligned}$$</span><br /></p>
<p><span> </span>. Say there are large <span class="math inline"><em>n</em> &gt; &gt;1</span> number of unique possible baseball cards. Each cereal box has a random card. You buy <span class="math inline"><em>m</em></span> boxes. The probability that you don’t get a particular card (approx), and also a bound on the probability that you miss at least one card is shown below. <br /><span class="math display">$$\begin{aligned}
    Pr(\text{miss a specific card}) &amp;\approx e^{- \frac{m}{n} }  \\
    Pr(\text{miss at least one card}) &amp;\le n e^{- \frac{m}{n} }  \end{aligned}$$</span><br /></p>
<p><span> </span>. Define random variable <span class="math inline"><em>X</em></span> to be the function <span class="math inline"><em>X</em> : <em>Ω</em> → ℝ</span> that assigns the value <span class="math inline"><em>X</em>(<em>ω</em>)</span> to outcome <span class="math inline"><em>ω</em></span>. For more, see portion of section  [sec:Probability Review] on random variables. The <strong>expected value</strong> of a (discrete) random variable <span class="math inline"><em>X</em></span> is <span> </span> where subscript <span class="math inline"><em>a</em></span> denotes all possible values of <span class="math inline"><em>X</em></span>, and <span class="math inline"><em>ω</em></span> denotes all possible outcomes in the sample space.<br />
This suggests that if we repeat an experiement a large number <span class="math inline"><em>N</em></span> of times and denote <span class="math inline"><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>n</em></sub></span> as the successive values we get, then <br /><span class="math display">$$\begin{aligned}
    {\mathbb{E}[X]} \approx \frac{\sum_i X_i}{N}\end{aligned}$$</span><br /></p>
<p><span> </span>. If asked on final the definition of random variable X, write the following:</p>
<blockquote>
<p>X is a real-valued function of the outcome of a random experiment.</p>
</blockquote>
<p>and some useful properties:</p>
<ul>
<li><p><span class="math inline"><em>P</em><em>r</em>(<em>X</em> = <em>a</em>):=<em>P</em><em>r</em>(<em>X</em><sup>−1</sup>(<em>a</em>)) = <em>P</em><em>r</em>({<em>ω</em>|<em>X</em>(<em>ω</em>)=<em>a</em>})</span> “The probability that X takes on the value a = The probability that random outcome of experiment happens to map into a”</p></li>
<li><p><span class="math inline"><em>P</em><em>r</em>(<em>X</em> ∈ <em>A</em>):=<em>P</em><em>r</em>(<em>X</em><sup>−1</sup>(<em>A</em>))</span>.</p></li>
<li><p>The of <span class="math inline"><em>X</em></span> is the list of possible values and their probability: <br /><span class="math display">{(<em>a</em>, <em>P</em><em>r</em>(<em>X</em> = <em>a</em>)),  <em>a</em> ∈ 𝒜}</span><br /></p></li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>so-called because you could represent the decision boundary as a set of vectors pointing to the hyperplane.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Notation: <span class="math inline">(<em>z</em>)<sub>+</sub> = <em>m</em><em>a</em><em>x</em>(<em>z</em>, 0)</span>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Regular GD is linear in <span class="math inline"><em>n</em></span><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Wanna see my posterior<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>fucking magnets how do they work?<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Oh, it is just the fact that Tr(AB) = Tr(BA). Moving on<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Remember that we are dealing with matrices now, so keep the order of <span class="math inline"><strong>H</strong></span> before <span class="math inline">(<em>w</em> − <em>w</em><sub><em>k</em></sub>)</span> even if you don’t like it.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Not sure why he says this. See pg 396 of ESL. Forward Pass: the current weights are fixed and the predicted values <span class="math inline">$\hat f_k(x_i)$</span>.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Note: he really screws this up.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p><span class="math inline"><em>x</em></span> transforms into a hyperplane in <span class="math inline"><em>w</em></span> space defined as all <span class="math inline"><em>w</em></span> that satisfy <span class="math inline"><em>x</em> ⋅ <em>w</em> = 0</span>.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Recall that the gradient points in direction of steepest <em>ascent</em>.<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Before this, looks like our objective function was just <span class="math inline">|<em>w</em>|<sup>2</sup></span> since that is what we wanted to minimize (subject to constraints).<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>TIL I had no idea what a random variable really was.<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Oh my god yes, this is what I came here for.<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>The symbol <span class="math inline">≜</span> means equal by definition (hnnggg). In continuous case, <span class="math inline"><em>F</em><sub><em>X</em></sub>(<em>x</em>)=∫<sub>−∞</sub><sup><em>x</em></sup><em>p</em><sub><em>X</em></sub>(<em>u</em>)<em>d</em><em>u</em></span>.<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Discrete case shown only. Should be obvious how it would look for continuous.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>MAP also known as Bayesian Density Estimation<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Based off Andrew Ng’s CS 229 Notes.<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Possible insight relating to regularization: Notice how perceptron classification <span class="math inline"><em>g</em>(<em>x</em>)</span> only depends on the sign of it’s argument, and not on the <em>magnitude</em>. However, performing <span class="math inline"><em>x</em> → 2<em>x</em></span> causes our functional margin to double <span class="math inline">$\hat{\gamma}^{(i)} \rightarrow 2 \hat{\gamma}^{(i)}$</span> and so it seems “<em>we can make the functional margin arbitrarily large without really changing anything meaningful.</em> This leads to, perhaps, defining a normalization condition that <span class="math inline">||<em>w</em>||<sub>2</sub> = 1</span>. Hmmm<a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Alright retard, time to settle this once and for all. The plane containing point <span class="math inline"><em>P</em><sub>0</sub></span> and the vector <span class="math inline">$\bm{n} =(a, b, c)$</span> consists of all points <span class="math inline"><em>P</em></span> with corresponding position vector <span class="math inline">$\bm{r}$</span> such that the vector drawn from <span class="math inline"><em>P</em><sub>0</sub></span> to <span class="math inline"><em>P</em></span> is perpendicular to <span class="math inline">$\bm{n}$</span>, i.e. the plane contains all points <span class="math inline">$\bm{r}$</span> such that <span class="math inline">$\bm{n} \cdot (\bm{r} - \bm{r_0}) = 0$</span><a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Recall that the functional margin alone does NOT tell you a distance.<a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Also remember that <span class="math inline">$\hat{\gamma}$</span> is over the WHOLE training set, and evaluates to the smallest <span class="math inline">$\hat{\gamma}^{(i)}$</span><a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>NOTE HOW I SAID PLANE AND NOT ANY VECTOR POINTING TO SOME POINT IN THE PLANE<a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Also in<a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Disclaimer: The following were based on an example with <span class="math inline"><em>n</em> = 2</span> and diagonal <span class="math inline"><em>Σ</em></span>. I’ve done my best to generalize the arguments they made here. I’m like, pretty sure I’m right, but...you know how things can go.<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>or reasonably approximated as linear<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>and/or if <span class="math inline"><em>y</em><sub><em>i</em></sub></span>’s conditionally indep given the <span class="math inline"><em>x</em><sub><em>i</em></sub></span>’s.<a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>A matrix is positive definite if it’s symmetric and all its eigenvalues are positive. . <span class="math inline"><strong>X</strong></span> columns may not be linearly independent if, e.g., two inputs were perfectly correlated <span class="math inline"><strong>x</strong><sub>2</sub> = 3<strong>x</strong><sub><strong>1</strong></sub></span>. The fitted <span class="math inline">${\hat{\mathbf{y}}}$</span> will still be projection onto <span class="math inline"><em>C</em>(<strong>X</strong>)</span>, but there will be more than 1 way (not unique) to express that projection. Occurs most often when one or more (qualitative) inputs are coded in a redundant fashion.<a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>This is the <span class="math inline"><em>C</em>(<strong>X</strong>)</span> of <span class="math inline"><strong>X</strong></span>. It is the space of <span class="math inline"><strong>X</strong><em>v</em> ∀<em>v</em> ∈ ℝ<sup><em>N</em></sup></span>, since the produce <span class="math inline"><em>X</em><em>v</em></span> is just a linear combination of the columns in <span class="math inline"><em>X</em></span> with coefficients <span class="math inline"><em>v</em><sub><em>i</em></sub></span>.<a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Interpret: <span class="math inline"><em>X</em><em>β</em></span> will always lie <em>somewhere</em> in this subspace, but we want <span class="math inline"><em>β</em></span> such that, when we subtract each component (WOAH JUST CLICKED) from the prediction, they cancel exactly,i.e. <span class="math inline"><em>y</em><sub><em>i</em></sub> − (<strong>X</strong><em>β</em>)<sub><em>i</em></sub> = 0</span> for all dimensions <span class="math inline"><em>i</em></span> in <span class="math inline"><em>C</em>(<em>X</em>)</span>. The resultant vector <span class="math inline">${\mathbf{y}}-\hat{y}$</span> will only contain components outside this subspace, hence it is orthogonal to it by definition.<a href="#fnref30">↩</a></p></li>
<li id="fn31"><p>At the same time, don’t forget that least-squared error assumption was built-in to this derivation.<a href="#fnref31">↩</a></p></li>
<li id="fn32"><p>Also, <span class="math inline">∀<em>a</em> ∈ ℝ : <em>V</em><em>a</em><em>r</em>(<em>a</em> + <em>X</em>)=<em>V</em><em>a</em><em>r</em>(<em>X</em>)</span><a href="#fnref32">↩</a></p></li>
<li id="fn33"><p>another way of stating this is that we took the variance <em>given</em> (or conditioned on) each <span class="math inline"><em>X</em></span><a href="#fnref33">↩</a></p></li>
<li id="fn34"><p>Translation: objects are clumps of stuff that are usually found clumped together, and such that these clumps tend not to clump with other clumps.<a href="#fnref34">↩</a></p></li>
<li id="fn35"><p>which discourages their joint activity<a href="#fnref35">↩</a></p></li>
<li id="fn36"><p>This is exactly what is meant by eq [corr], Pearson’s correlation coefficient. <em>Linear</em> because “it is a measure of the linear dependence between two variables X and Y.”<a href="#fnref36">↩</a></p></li>
<li id="fn37"><p>TODO: Come back and explain why this is true, because current Brandon thought otherwise.<a href="#fnref37">↩</a></p></li>
<li id="fn38"><p>Confusingly, here <span class="math inline"><em>N</em></span> refers to the dimension of space that each input vector lives in (usually denoted by <span class="math inline"><em>d</em></span>.)<a href="#fnref38">↩</a></p></li>
<li id="fn39"><p>Come back and explain why we would want a network to do this. Biological relevance/analog? : You need to view it in the context of the grandmother-cell. That’s what this is all about. If a given neuron has a large linear output, then we have a good idea of what type of input went in; it was an input really similar to the weight vector. This begs the question, though: how does one determine a reasonable initialization for a given connected layer of weights to a single output? I suppose the answer is that this is the wrong question. Rather, we should interpret the outcome as resulting from a stream of particular inputs and, based on its future responses to inputs, we can determine what type of input went in. With the brain, this is like the jennifer aniston neuron: if that neuron fires, we can assume the person just saw something that resembled Jennifer Aniston.<a href="#fnref39">↩</a></p></li>
<li id="fn40"><p>Minor TODO: Analyze case of non-binary (i.e. continuous both pos/neg) inputs/outputs.<a href="#fnref40">↩</a></p></li>
<li id="fn41"><p>Say ’back-propagated output’ because we are subtracting what was put into the network by the resultant output <em>times</em> the connection (weight) between the input and said output. Dwelling on this <em>would</em> be overly pedantic, so move on.<a href="#fnref41">↩</a></p></li>
<li id="fn42"><p>TODO:wtf does this mean.<a href="#fnref42">↩</a></p></li>
<li id="fn43"><p>M &gt; N.<a href="#fnref43">↩</a></p></li>
<li id="fn44"><p>Looks like <span class="math inline"><em>a</em><sub><em>i</em></sub> ∉ <strong>Φ</strong></span><a href="#fnref44">↩</a></p></li>
<li id="fn45"><p>A.k.a sparsity constraints a.k.a limit activations.<a href="#fnref45">↩</a></p></li>
<li id="fn46"><p>Okay well what the fuck is it?<a href="#fnref46">↩</a></p></li>
<li id="fn47"><p>what the fuck is this<a href="#fnref47">↩</a></p></li>
<li id="fn48"><p>what. the. fuck.<a href="#fnref48">↩</a></p></li>
<li id="fn49"><p>Multidimensional scaling<a href="#fnref49">↩</a></p></li>
<li id="fn50"><p>In other words, since the weights just characterize the local patch of the given data point, that patch shouldn’t change if we shift the data, rotate it, or scale it. The neighboring points should remain the same.<a href="#fnref50">↩</a></p></li>
<li id="fn51"><p>In particular, the same weights <span class="math inline"><em>W</em><sub><em>i</em><em>j</em></sub></span> that reconstruct the <span class="math inline"><em>i</em></span>th data point in D dimensions should also reconstruct its embedded manifold coordinates in d dimensions<a href="#fnref51">↩</a></p></li>
<li id="fn52"><p>Literally referring to direction of [e.g. some animal’s] head<a href="#fnref52">↩</a></p></li>
<li id="fn53"><p>Analogy to hopfield: H is like hopfield B. X is like external I in hopfield.<a href="#fnref53">↩</a></p></li>
<li id="fn54"><p>If it is -1, change to +1, else just keep where it is.<a href="#fnref54">↩</a></p></li>
<li id="fn55"><p>Assuming the stored patterns are relatively dissimilar.<a href="#fnref55">↩</a></p></li>
<li id="fn56"><p>See Discussion 5B<a href="#fnref56">↩</a></p></li>
<li id="fn57"><p>Think Fermat’s little theorem.<a href="#fnref57">↩</a></p></li>
<li id="fn58"><p>Ctr-f: Fermat’s Little Theorem fermat Fermats little theorem<a href="#fnref58">↩</a></p></li>
<li id="fn59"><p>To prove: use [Poly]<a href="#fnref59">↩</a></p></li>
<li id="fn60"><p>To prove: induction on number of roots. Take advantage of Lemma 1.<a href="#fnref60">↩</a></p></li>
<li id="fn61"><p>Certainty: 95 percent.<a href="#fnref61">↩</a></p></li>
<li id="fn62"><p>Certainty: 90 percent<a href="#fnref62">↩</a></p></li>
<li id="fn63"><p>Certainty: <del>95 percent</del> <del>More like 40 percent</del> 0 Percent because I know I was wrong now.<a href="#fnref63">↩</a></p></li>
<li id="fn64"><p>Certainty:90 percent only because algrebra errors.<a href="#fnref64">↩</a></p></li>
<li id="fn65"><p>Certainty: 70 percent. Question seems open-ended and the wording is shit<a href="#fnref65">↩</a></p></li>
<li id="fn66"><p>Check Piazza for followup on my question regarding this<a href="#fnref66">↩</a></p></li>
<li id="fn67"><p>Claim 2 <span class="math inline">⟹</span> Property 1<a href="#fnref67">↩</a></p></li>
<li id="fn68"><p>so you can share any secret you want. Good to choose p = <span class="math inline">2<sup><em>b</em></sup> + 1</span>.<a href="#fnref68">↩</a></p></li>
<li id="fn69"><p><span class="math inline"><em>n</em> + <em>k</em></span> because, since we know <span class="math inline"><em>k</em></span> packets out of the <span class="math inline"><em>n</em></span> will be lost, we should send <span class="math inline"><em>n</em> + <em>k</em></span> packets if we want a total of <span class="math inline"><em>n</em></span> packets to be received.<a href="#fnref69">↩</a></p></li>
<li id="fn70"><p>Think polynomial secret sharing.<a href="#fnref70">↩</a></p></li>
<li id="fn71"><p>Form is always the same: Plug in values for <span class="math inline"><em>x</em></span> into <span class="math inline"><em>a</em><sub><em>k</em> − 1</sub><em>x</em><sup><em>k</em> − 1</sup> + ⋯ + <em>a</em><sub>1</sub><em>x</em> + <em>a</em><sub>0</sub>mod<em>p</em></span>. Don’t forget to take mod on all coefficients!<a href="#fnref71">↩</a></p></li>
<li id="fn72"><p>only twice as many as in the erasure case<a href="#fnref72">↩</a></p></li>
<li id="fn73"><p>Goal is still for receiver to determine the unique polynomial <span class="math inline"><em>P</em>(<em>j</em>)</span>.<a href="#fnref73">↩</a></p></li>
<li id="fn74"><p>Fact: For any polynomials <span class="math inline"><em>P</em></span> and <span class="math inline"><em>Q</em></span>, it is true that deg(PQ) = deg(P) + deg(Q).<a href="#fnref74">↩</a></p></li>
<li id="fn75"><p>Paused lec at 24:20<a href="#fnref75">↩</a></p></li>
<li id="fn76"><p>This technique, i guess, <em>uses</em> reed-solomon code. Whatever.<a href="#fnref76">↩</a></p></li>
<li id="fn77"><p>Note: seems to suggest that <span class="math inline">ℕ × ℕ</span> is undefined. But countable... Check.<a href="#fnref77">↩</a></p></li>
<li id="fn78"><p>If it were, say, the <span class="math inline"><em>j</em></span>th element of the list, then by definition its <span class="math inline"><em>j</em></span>th element could not be its <span class="math inline"><em>j</em></span>th element. Don’t hurt yourself, it’s simple.<a href="#fnref78">↩</a></p></li>
<li id="fn79"><p>Calls this “second rule of counting.” The first rule is the produce rule.<a href="#fnref79">↩</a></p></li>
<li id="fn80"><p>Notice that all such subsets do not include <em>any</em> of the subsets counted in the previous bullet point.<a href="#fnref80">↩</a></p></li>
<li id="fn81"><p>Does it matter if one number is bigger than the other? <strong>A: No it does not matter.</strong><a href="#fnref81">↩</a></p></li>
<li id="fn82"><p>I’m predicting yes they are, <del>because having the sum be seven doesn’t tell us any information about which colored die was what.</del> You were right but <em>for the wrong reason.</em> The sum does actually give us some info in general, but the only reason it doesn’t here is because it is 7, which is a possibility regardless of what the first die says. See the next example, which shows a case where they are not independent.<a href="#fnref82">↩</a></p></li>
<li id="fn83"><p>Note: The of A with respect to B, denoted as <span class="math inline"><em>A</em> \ <em>B</em></span>, is defined as all objects that belong to <span class="math inline"><em>A</em></span> and not to <span class="math inline"><em>B</em></span>.<a href="#fnref83">↩</a></p></li>
<li id="fn84"><p>Similar to having <span class="math inline"><em>m</em></span> people in room and wanting probability that no two people have same birthday (<span class="math inline"><em>n</em> = 365</span>)<a href="#fnref84">↩</a></p></li>
</ol>
</div>
</body>
</html>
